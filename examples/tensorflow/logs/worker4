2017-10-17 23:03:55.667017: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 23:03:55.667042: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 23:03:55.667051: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-17 23:03:55.694132: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_UNKNOWN
2017-10-17 23:03:55.694165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:145] kernel driver does not appear to be running on this host (ip-10-0-1-46): /proc/driver/nvidia/version does not exist
2017-10-17 23:03:55.701711: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> deeplearning-worker1:2222, 1 -> deeplearning-worker2:2222, 2 -> deeplearning-worker3:2222, 3 -> deeplearning-worker4:2222, 4 -> deeplearning-worker5:2222}
2017-10-17 23:03:55.701738: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> deeplearning-worker1:2230, 1 -> deeplearning-worker2:2230, 2 -> deeplearning-worker3:2230, 3 -> deeplearning-worker4:2230, 4 -> localhost:2230}
2017-10-17 23:03:55.702879: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2230
2017-10-17 23:04:20.106824: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 00a0775ff35f4e13 with config: 

2017-10-17 23:04:51.018131: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 19c5880dd135c918 with config: 

Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-10-17 23:04:54.443266: step 0, loss = 4.18 (38.2 examples/sec; 3.350 sec/batch)
2017-10-17 23:04:57.834848: step 10, loss = 4.28 (376.9 examples/sec; 0.340 sec/batch)
2017-10-17 23:05:01.221388: step 20, loss = 4.08 (378.6 examples/sec; 0.338 sec/batch)
2017-10-17 23:05:04.583257: step 30, loss = 4.06 (382.7 examples/sec; 0.334 sec/batch)
2017-10-17 23:05:07.963315: step 40, loss = 4.05 (372.5 examples/sec; 0.344 sec/batch)
2017-10-17 23:05:11.328990: step 50, loss = 3.82 (384.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:05:14.689902: step 60, loss = 3.81 (383.2 examples/sec; 0.334 sec/batch)
2017-10-17 23:05:18.051478: step 70, loss = 4.18 (381.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:05:21.414583: step 80, loss = 3.83 (382.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:05:24.768491: step 90, loss = 3.57 (386.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:05:28.123960: step 100, loss = 3.43 (388.7 examples/sec; 0.329 sec/batch)
2017-10-17 23:05:31.475904: step 110, loss = 3.28 (381.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:05:34.839488: step 120, loss = 3.32 (381.7 examples/sec; 0.335 sec/batch)
2017-10-17 23:05:38.335743: step 130, loss = 3.07 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:05:41.671658: step 140, loss = 2.94 (386.5 examples/sec; 0.331 sec/batch)
2017-10-17 23:05:45.021965: step 150, loss = 3.45 (384.3 examples/sec; 0.333 sec/batch)
2017-10-17 23:05:48.363078: step 160, loss = 3.29 (386.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:05:51.727215: step 170, loss = 2.84 (385.2 examples/sec; 0.332 sec/batch)
2017-10-17 23:05:55.083483: step 180, loss = 2.88 (381.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:05:58.444513: step 190, loss = 2.77 (385.4 examples/sec; 0.332 sec/batch)
2017-10-17 23:06:01.803999: step 200, loss = 2.79 (383.1 examples/sec; 0.334 sec/batch)
2017-10-17 23:06:05.158721: step 210, loss = 2.95 (380.2 examples/sec; 0.337 sec/batch)
2017-10-17 23:06:08.490990: step 220, loss = 2.86 (382.2 examples/sec; 0.335 sec/batch)
2017-10-17 23:06:11.836619: step 230, loss = 2.45 (381.2 examples/sec; 0.336 sec/batch)
2017-10-17 23:06:15.181740: step 240, loss = 2.82 (385.7 examples/sec; 0.332 sec/batch)
2017-10-17 23:06:18.534075: step 250, loss = 2.49 (386.8 examples/sec; 0.331 sec/batch)
2017-10-17 23:06:21.872033: step 260, loss = 2.28 (382.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:06:25.207978: step 270, loss = 2.86 (385.9 examples/sec; 0.332 sec/batch)
2017-10-17 23:06:28.531504: step 280, loss = 2.40 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:06:31.860921: step 290, loss = 2.95 (384.4 examples/sec; 0.333 sec/batch)
2017-10-17 23:06:35.176439: step 300, loss = 2.46 (385.9 examples/sec; 0.332 sec/batch)
2017-10-17 23:06:38.505115: step 310, loss = 2.19 (386.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:06:41.845440: step 320, loss = 2.32 (382.7 examples/sec; 0.334 sec/batch)
2017-10-17 23:06:45.183705: step 330, loss = 2.04 (386.6 examples/sec; 0.331 sec/batch)
2017-10-17 23:06:48.507120: step 340, loss = 2.11 (381.9 examples/sec; 0.335 sec/batch)
2017-10-17 23:06:51.865552: step 350, loss = 2.01 (380.5 examples/sec; 0.336 sec/batch)
2017-10-17 23:06:55.204392: step 360, loss = 2.34 (384.4 examples/sec; 0.333 sec/batch)
2017-10-17 23:06:58.528767: step 370, loss = 2.03 (384.1 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:01.864196: step 380, loss = 2.07 (379.7 examples/sec; 0.337 sec/batch)
2017-10-17 23:07:05.186889: step 390, loss = 2.30 (379.5 examples/sec; 0.337 sec/batch)
2017-10-17 23:07:08.503052: step 400, loss = 2.07 (385.6 examples/sec; 0.332 sec/batch)
2017-10-17 23:07:11.815712: step 410, loss = 2.02 (388.6 examples/sec; 0.329 sec/batch)
2017-10-17 23:07:15.137617: step 420, loss = 1.97 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:18.464848: step 430, loss = 2.22 (380.2 examples/sec; 0.337 sec/batch)
2017-10-17 23:07:21.794968: step 440, loss = 1.77 (386.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:07:25.125015: step 450, loss = 1.89 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:07:28.447122: step 460, loss = 1.69 (384.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:31.760833: step 470, loss = 1.71 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:35.092117: step 480, loss = 1.93 (383.2 examples/sec; 0.334 sec/batch)
2017-10-17 23:07:38.421636: step 490, loss = 1.75 (384.0 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:41.753308: step 500, loss = 1.72 (384.2 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:45.073406: step 510, loss = 1.87 (389.0 examples/sec; 0.329 sec/batch)
2017-10-17 23:07:48.409744: step 520, loss = 1.57 (384.1 examples/sec; 0.333 sec/batch)
2017-10-17 23:07:51.740752: step 530, loss = 1.69 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:07:55.062428: step 540, loss = 1.68 (385.3 examples/sec; 0.332 sec/batch)
2017-10-17 23:07:58.382162: step 550, loss = 1.46 (387.4 examples/sec; 0.330 sec/batch)
2017-10-17 23:08:01.722455: step 560, loss = 1.81 (382.4 examples/sec; 0.335 sec/batch)
2017-10-17 23:08:05.055522: step 570, loss = 1.80 (380.0 examples/sec; 0.337 sec/batch)
2017-10-17 23:08:08.382751: step 580, loss = 1.79 (382.4 examples/sec; 0.335 sec/batch)
2017-10-17 23:08:11.691381: step 590, loss = 1.44 (386.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:08:15.026374: step 600, loss = 1.63 (386.1 examples/sec; 0.332 sec/batch)
2017-10-17 23:08:18.346326: step 610, loss = 1.78 (387.8 examples/sec; 0.330 sec/batch)
2017-10-17 23:08:21.671343: step 620, loss = 1.47 (383.0 examples/sec; 0.334 sec/batch)
2017-10-17 23:08:25.005802: step 630, loss = 2.00 (382.9 examples/sec; 0.334 sec/batch)
2017-10-17 23:08:28.326536: step 640, loss = 1.54 (385.3 examples/sec; 0.332 sec/batch)
2017-10-17 23:08:31.652827: step 650, loss = 1.55 (384.9 examples/sec; 0.333 sec/batch)
2017-10-17 23:08:34.973715: step 660, loss = 1.77 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:08:38.278152: step 670, loss = 1.42 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:08:41.595696: step 680, loss = 1.92 (386.6 examples/sec; 0.331 sec/batch)
2017-10-17 23:08:44.906417: step 690, loss = 1.64 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:08:48.228862: step 700, loss = 1.34 (383.1 examples/sec; 0.334 sec/batch)
2017-10-17 23:08:51.540402: step 710, loss = 1.40 (381.8 examples/sec; 0.335 sec/batch)
2017-10-17 23:08:54.847898: step 720, loss = 1.27 (389.8 examples/sec; 0.328 sec/batch)
2017-10-17 23:08:58.166758: step 730, loss = 1.44 (389.4 examples/sec; 0.329 sec/batch)
2017-10-17 23:09:01.498675: step 740, loss = 2.03 (377.8 examples/sec; 0.339 sec/batch)
2017-10-17 23:09:04.810691: step 750, loss = 1.72 (384.2 examples/sec; 0.333 sec/batch)
2017-10-17 23:09:08.121590: step 760, loss = 1.38 (381.5 examples/sec; 0.335 sec/batch)
2017-10-17 23:09:11.458415: step 770, loss = 1.29 (382.5 examples/sec; 0.335 sec/batch)
2017-10-17 23:09:14.801091: step 780, loss = 1.29 (382.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:09:18.114854: step 790, loss = 1.38 (386.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:09:21.420663: step 800, loss = 1.20 (385.2 examples/sec; 0.332 sec/batch)
2017-10-17 23:09:24.757354: step 810, loss = 1.20 (382.4 examples/sec; 0.335 sec/batch)
2017-10-17 23:09:28.277672: step 820, loss = 1.58 (389.7 examples/sec; 0.328 sec/batch)
2017-10-17 23:09:31.609421: step 830, loss = 1.59 (388.1 examples/sec; 0.330 sec/batch)
2017-10-17 23:09:34.956868: step 840, loss = 1.37 (375.9 examples/sec; 0.341 sec/batch)
2017-10-17 23:09:38.276388: step 850, loss = 1.23 (386.9 examples/sec; 0.331 sec/batch)
2017-10-17 23:09:41.595616: step 860, loss = 1.24 (389.1 examples/sec; 0.329 sec/batch)
2017-10-17 23:09:44.910109: step 870, loss = 1.41 (384.5 examples/sec; 0.333 sec/batch)
2017-10-17 23:09:48.226326: step 880, loss = 1.44 (384.1 examples/sec; 0.333 sec/batch)
2017-10-17 23:09:51.547770: step 890, loss = 1.20 (378.4 examples/sec; 0.338 sec/batch)
2017-10-17 23:09:54.880589: step 900, loss = 1.19 (386.1 examples/sec; 0.332 sec/batch)
2017-10-17 23:09:58.208246: step 910, loss = 1.23 (381.4 examples/sec; 0.336 sec/batch)
2017-10-17 23:10:01.527601: step 920, loss = 1.26 (379.9 examples/sec; 0.337 sec/batch)
2017-10-17 23:10:04.872652: step 930, loss = 1.19 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:10:08.229747: step 940, loss = 1.14 (378.7 examples/sec; 0.338 sec/batch)
2017-10-17 23:10:11.660888: step 950, loss = 1.40 (387.6 examples/sec; 0.330 sec/batch)
2017-10-17 23:10:14.961185: step 960, loss = 1.26 (384.7 examples/sec; 0.333 sec/batch)
2017-10-17 23:10:18.278625: step 970, loss = 1.04 (380.4 examples/sec; 0.337 sec/batch)
2017-10-17 23:10:21.591685: step 980, loss = 1.19 (386.7 examples/sec; 0.331 sec/batch)
2017-10-17 23:10:24.920239: step 990, loss = 1.19 (383.1 examples/sec; 0.334 sec/batch)
2017-10-17 23:10:28.273572: step 1000, loss = 1.29 (389.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:10:31.595636: step 1010, loss = 2.26 (387.6 examples/sec; 0.330 sec/batch)
2017-10-17 23:10:34.907278: step 1020, loss = 1.56 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:10:38.212380: step 1030, loss = 1.38 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:10:41.519261: step 1040, loss = 1.40 (385.3 examples/sec; 0.332 sec/batch)
2017-10-17 23:10:44.928738: step 1050, loss = 1.23 (292.1 examples/sec; 0.438 sec/batch)
2017-10-17 23:10:48.254190: step 1060, loss = 1.20 (387.5 examples/sec; 0.330 sec/batch)
2017-10-17 23:10:51.563608: step 1070, loss = 1.19 (387.7 examples/sec; 0.330 sec/batch)
2017-10-17 23:10:54.868008: step 1080, loss = 1.16 (390.0 examples/sec; 0.328 sec/batch)
2017-10-17 23:10:58.173344: step 1090, loss = 1.28 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:11:01.491979: step 1100, loss = 1.30 (386.1 examples/sec; 0.331 sec/batch)
2017-10-17 23:11:04.793212: step 1110, loss = 1.25 (391.3 examples/sec; 0.327 sec/batch)
2017-10-17 23:11:08.098891: step 1120, loss = 1.15 (386.8 examples/sec; 0.331 sec/batch)
2017-10-17 23:11:11.422047: step 1130, loss = 1.05 (384.0 examples/sec; 0.333 sec/batch)
2017-10-17 23:11:14.753420: step 1140, loss = 1.11 (388.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:11:18.174631: step 1150, loss = 1.19 (386.9 examples/sec; 0.331 sec/batch)
2017-10-17 23:11:21.476492: step 1160, loss = 1.37 (389.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:11:24.916103: step 1170, loss = 1.14 (381.2 examples/sec; 0.336 sec/batch)
2017-10-17 23:11:28.228671: step 1180, loss = 1.33 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:11:31.559705: step 1190, loss = 1.07 (383.6 examples/sec; 0.334 sec/batch)
2017-10-17 23:11:34.870067: step 1200, loss = 1.08 (385.2 examples/sec; 0.332 sec/batch)
2017-10-17 23:11:38.170295: step 1210, loss = 1.13 (391.3 examples/sec; 0.327 sec/batch)
2017-10-17 23:11:41.488833: step 1220, loss = 1.08 (389.6 examples/sec; 0.329 sec/batch)
2017-10-17 23:11:44.806469: step 1230, loss = 1.07 (383.6 examples/sec; 0.334 sec/batch)
2017-10-17 23:11:48.140489: step 1240, loss = 1.22 (378.4 examples/sec; 0.338 sec/batch)
2017-10-17 23:11:51.469453: step 1250, loss = 1.04 (389.1 examples/sec; 0.329 sec/batch)
2017-10-17 23:11:54.782679: step 1260, loss = 1.51 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:11:58.112227: step 1270, loss = 1.29 (386.8 examples/sec; 0.331 sec/batch)
2017-10-17 23:12:01.436520: step 1280, loss = 1.42 (382.5 examples/sec; 0.335 sec/batch)
2017-10-17 23:12:04.745048: step 1290, loss = 1.18 (382.7 examples/sec; 0.334 sec/batch)
2017-10-17 23:12:08.070885: step 1300, loss = 0.94 (389.9 examples/sec; 0.328 sec/batch)
2017-10-17 23:12:11.377570: step 1310, loss = 1.04 (388.1 examples/sec; 0.330 sec/batch)
2017-10-17 23:12:14.701806: step 1320, loss = 1.08 (385.6 examples/sec; 0.332 sec/batch)
2017-10-17 23:12:18.031948: step 1330, loss = 1.14 (384.6 examples/sec; 0.333 sec/batch)
2017-10-17 23:12:21.349282: step 1340, loss = 1.01 (384.3 examples/sec; 0.333 sec/batch)
2017-10-17 23:12:24.655196: step 1350, loss = 1.23 (388.0 examples/sec; 0.330 sec/batch)
2017-10-17 23:12:27.984624: step 1360, loss = 1.05 (383.7 examples/sec; 0.334 sec/batch)
2017-10-17 23:12:31.293465: step 1370, loss = 1.11 (388.7 examples/sec; 0.329 sec/batch)
2017-10-17 23:12:34.629385: step 1380, loss = 1.23 (388.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:12:37.933952: step 1390, loss = 1.06 (383.3 examples/sec; 0.334 sec/batch)
2017-10-17 23:12:41.245963: step 1400, loss = 0.95 (387.1 examples/sec; 0.331 sec/batch)
2017-10-17 23:12:44.565890: step 1410, loss = 1.23 (388.6 examples/sec; 0.329 sec/batch)
2017-10-17 23:12:47.878007: step 1420, loss = 1.06 (390.0 examples/sec; 0.328 sec/batch)
2017-10-17 23:12:51.196370: step 1430, loss = 0.83 (385.2 examples/sec; 0.332 sec/batch)
2017-10-17 23:12:54.532864: step 1440, loss = 1.41 (387.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:12:57.866844: step 1450, loss = 1.15 (378.3 examples/sec; 0.338 sec/batch)
2017-10-17 23:13:01.211573: step 1460, loss = 0.99 (378.4 examples/sec; 0.338 sec/batch)
2017-10-17 23:13:04.545998: step 1470, loss = 1.12 (382.9 examples/sec; 0.334 sec/batch)
2017-10-17 23:13:07.887488: step 1480, loss = 1.07 (384.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:13:11.200863: step 1490, loss = 0.93 (388.9 examples/sec; 0.329 sec/batch)
2017-10-17 23:13:14.512905: step 1500, loss = 1.04 (393.5 examples/sec; 0.325 sec/batch)
2017-10-17 23:13:17.836245: step 1510, loss = 1.02 (386.1 examples/sec; 0.332 sec/batch)
2017-10-17 23:13:21.146391: step 1520, loss = 0.97 (391.3 examples/sec; 0.327 sec/batch)
2017-10-17 23:13:24.462003: step 1530, loss = 1.23 (388.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:13:27.789526: step 1540, loss = 1.09 (384.3 examples/sec; 0.333 sec/batch)
2017-10-17 23:13:31.100080: step 1550, loss = 0.97 (382.0 examples/sec; 0.335 sec/batch)
2017-10-17 23:13:34.428616: step 1560, loss = 0.96 (386.7 examples/sec; 0.331 sec/batch)
2017-10-17 23:13:37.761970: step 1570, loss = 1.28 (381.6 examples/sec; 0.335 sec/batch)
2017-10-17 23:13:41.078045: step 1580, loss = 1.24 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:13:44.384242: step 1590, loss = 1.26 (387.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:13:47.689987: step 1600, loss = 1.07 (385.4 examples/sec; 0.332 sec/batch)
2017-10-17 23:13:50.996427: step 1610, loss = 1.29 (387.1 examples/sec; 0.331 sec/batch)
2017-10-17 23:13:54.302422: step 1620, loss = 0.96 (388.4 examples/sec; 0.330 sec/batch)
2017-10-17 23:13:57.611720: step 1630, loss = 0.98 (387.3 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:00.941723: step 1640, loss = 1.13 (387.4 examples/sec; 0.330 sec/batch)
2017-10-17 23:14:04.264168: step 1650, loss = 0.86 (384.3 examples/sec; 0.333 sec/batch)
2017-10-17 23:14:07.580378: step 1660, loss = 1.08 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:14:10.881130: step 1670, loss = 1.32 (389.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:14:14.188859: step 1680, loss = 1.08 (382.9 examples/sec; 0.334 sec/batch)
2017-10-17 23:14:17.501209: step 1690, loss = 0.83 (386.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:20.797711: step 1700, loss = 0.94 (391.1 examples/sec; 0.327 sec/batch)
2017-10-17 23:14:24.114628: step 1710, loss = 1.25 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:14:27.410283: step 1720, loss = 1.44 (391.5 examples/sec; 0.327 sec/batch)
2017-10-17 23:14:30.714352: step 1730, loss = 0.99 (387.3 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:34.018510: step 1740, loss = 1.09 (389.3 examples/sec; 0.329 sec/batch)
2017-10-17 23:14:37.326722: step 1750, loss = 1.16 (384.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:14:40.633122: step 1760, loss = 0.94 (387.1 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:43.945559: step 1770, loss = 1.08 (386.9 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:47.247172: step 1780, loss = 1.29 (389.0 examples/sec; 0.329 sec/batch)
2017-10-17 23:14:50.556829: step 1790, loss = 0.90 (387.0 examples/sec; 0.331 sec/batch)
2017-10-17 23:14:53.872464: step 1800, loss = 0.99 (391.0 examples/sec; 0.327 sec/batch)
2017-10-17 23:14:57.201492: step 1810, loss = 0.97 (377.3 examples/sec; 0.339 sec/batch)
2017-10-17 23:15:00.630886: step 1820, loss = 1.30 (386.5 examples/sec; 0.331 sec/batch)
2017-10-17 23:15:03.933235: step 1830, loss = 1.11 (383.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:15:07.249541: step 1840, loss = 1.06 (391.8 examples/sec; 0.327 sec/batch)
2017-10-17 23:15:10.556975: step 1850, loss = 0.91 (390.6 examples/sec; 0.328 sec/batch)
2017-10-17 23:15:13.885770: step 1860, loss = 0.92 (389.2 examples/sec; 0.329 sec/batch)
2017-10-17 23:15:17.189938: step 1870, loss = 0.99 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:15:20.503841: step 1880, loss = 1.13 (388.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:15:23.819366: step 1890, loss = 1.24 (383.6 examples/sec; 0.334 sec/batch)
2017-10-17 23:15:27.168410: step 1900, loss = 0.88 (388.1 examples/sec; 0.330 sec/batch)
2017-10-17 23:15:30.471317: step 1910, loss = 0.87 (390.9 examples/sec; 0.327 sec/batch)
2017-10-17 23:15:33.799264: step 1920, loss = 1.14 (386.8 examples/sec; 0.331 sec/batch)
2017-10-17 23:15:37.121129: step 1930, loss = 1.06 (386.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:15:40.443577: step 1940, loss = 0.93 (389.4 examples/sec; 0.329 sec/batch)
2017-10-17 23:15:43.767923: step 1950, loss = 0.93 (381.5 examples/sec; 0.335 sec/batch)
2017-10-17 23:15:47.081938: step 1960, loss = 1.02 (392.3 examples/sec; 0.326 sec/batch)
2017-10-17 23:15:50.403483: step 1970, loss = 1.07 (383.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:15:53.735702: step 1980, loss = 1.11 (378.7 examples/sec; 0.338 sec/batch)
2017-10-17 23:15:57.054063: step 1990, loss = 1.03 (383.2 examples/sec; 0.334 sec/batch)
2017-10-17 23:16:00.365740: step 2000, loss = 1.18 (388.0 examples/sec; 0.330 sec/batch)
2017-10-17 23:16:03.845986: step 2010, loss = 1.62 (250.0 examples/sec; 0.512 sec/batch)
2017-10-17 23:16:07.128446: step 2020, loss = 0.85 (389.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:16:10.443243: step 2030, loss = 1.01 (388.7 examples/sec; 0.329 sec/batch)
2017-10-17 23:16:13.752421: step 2040, loss = 1.12 (387.6 examples/sec; 0.330 sec/batch)
2017-10-17 23:16:17.077498: step 2050, loss = 1.03 (391.4 examples/sec; 0.327 sec/batch)
2017-10-17 23:16:20.382912: step 2060, loss = 0.98 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:16:23.693568: step 2070, loss = 1.11 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:16:27.095582: step 2080, loss = 0.90 (290.6 examples/sec; 0.440 sec/batch)
2017-10-17 23:16:30.397336: step 2090, loss = 0.99 (391.9 examples/sec; 0.327 sec/batch)
2017-10-17 23:16:33.714802: step 2100, loss = 1.14 (383.2 examples/sec; 0.334 sec/batch)
2017-10-17 23:16:36.990567: step 2110, loss = 0.82 (392.8 examples/sec; 0.326 sec/batch)
2017-10-17 23:16:40.290162: step 2120, loss = 0.91 (386.6 examples/sec; 0.331 sec/batch)
2017-10-17 23:16:43.596702: step 2130, loss = 0.85 (378.0 examples/sec; 0.339 sec/batch)
2017-10-17 23:16:46.898091: step 2140, loss = 0.97 (387.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:16:50.204534: step 2150, loss = 0.89 (389.0 examples/sec; 0.329 sec/batch)
2017-10-17 23:16:53.516921: step 2160, loss = 1.02 (390.1 examples/sec; 0.328 sec/batch)
2017-10-17 23:16:56.818443: step 2170, loss = 0.98 (388.9 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:00.222165: step 2180, loss = 1.06 (389.2 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:03.540317: step 2190, loss = 1.03 (391.9 examples/sec; 0.327 sec/batch)
2017-10-17 23:17:06.863680: step 2200, loss = 1.08 (389.4 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:10.167296: step 2210, loss = 0.97 (389.0 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:13.465046: step 2220, loss = 0.87 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:17:16.780970: step 2230, loss = 1.10 (378.8 examples/sec; 0.338 sec/batch)
2017-10-17 23:17:20.079558: step 2240, loss = 0.87 (389.2 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:23.385241: step 2250, loss = 1.21 (385.0 examples/sec; 0.332 sec/batch)
2017-10-17 23:17:26.685655: step 2260, loss = 0.93 (389.2 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:29.999461: step 2270, loss = 1.17 (389.4 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:33.301214: step 2280, loss = 0.99 (388.6 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:36.605513: step 2290, loss = 1.22 (387.2 examples/sec; 0.331 sec/batch)
2017-10-17 23:17:39.906275: step 2300, loss = 1.05 (389.5 examples/sec; 0.329 sec/batch)
2017-10-17 23:17:43.202867: step 2310, loss = 1.02 (395.0 examples/sec; 0.324 sec/batch)
2017-10-17 23:17:46.498134: step 2320, loss = 1.04 (387.4 examples/sec; 0.330 sec/batch)
2017-10-17 23:17:49.812838: step 2330, loss = 0.93 (386.5 examples/sec; 0.331 sec/batch)
2017-10-17 23:17:53.127000: step 2340, loss = 0.89 (389.7 examples/sec; 0.328 sec/batch)
2017-10-17 23:17:56.434802: step 2350, loss = 1.13 (383.6 examples/sec; 0.334 sec/batch)
2017-10-17 23:17:59.756510: step 2360, loss = 1.29 (386.7 examples/sec; 0.331 sec/batch)
2017-10-17 23:18:03.071342: step 2370, loss = 0.91 (387.8 examples/sec; 0.330 sec/batch)
2017-10-17 23:18:06.392881: step 2380, loss = 0.75 (387.0 examples/sec; 0.331 sec/batch)
2017-10-17 23:18:09.813226: step 2390, loss = 1.04 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:18:13.121426: step 2400, loss = 0.87 (378.1 examples/sec; 0.339 sec/batch)
2017-10-17 23:18:16.447201: step 2410, loss = 1.00 (386.7 examples/sec; 0.331 sec/batch)
2017-10-17 23:18:19.748038: step 2420, loss = 0.80 (389.4 examples/sec; 0.329 sec/batch)
2017-10-17 23:18:23.068816: step 2430, loss = 0.86 (386.7 examples/sec; 0.331 sec/batch)
2017-10-17 23:18:26.390926: step 2440, loss = 1.08 (386.4 examples/sec; 0.331 sec/batch)
2017-10-17 23:18:29.697891: step 2450, loss = 0.86 (390.1 examples/sec; 0.328 sec/batch)
2017-10-17 23:18:33.001311: step 2460, loss = 1.49 (389.9 examples/sec; 0.328 sec/batch)
2017-10-17 23:18:36.289458: step 2470, loss = 1.14 (393.0 examples/sec; 0.326 sec/batch)
2017-10-17 23:18:39.586736: step 2480, loss = 0.96 (391.8 examples/sec; 0.327 sec/batch)
2017-10-17 23:18:42.873935: step 2490, loss = 1.08 (392.1 examples/sec; 0.326 sec/batch)
2017-10-17 23:18:46.164836: step 2500, loss = 1.26 (391.9 examples/sec; 0.327 sec/batch)
2017-10-17 23:18:49.467509: step 2510, loss = 1.05 (392.3 examples/sec; 0.326 sec/batch)
2017-10-17 23:18:52.755510: step 2520, loss = 1.11 (392.3 examples/sec; 0.326 sec/batch)
2017-10-17 23:18:56.072097: step 2530, loss = 0.93 (388.1 examples/sec; 0.330 sec/batch)
2017-10-17 23:18:59.373938: step 2540, loss = 0.96 (392.1 examples/sec; 0.326 sec/batch)
2017-10-17 23:19:02.694839: step 2550, loss = 0.95 (387.1 examples/sec; 0.331 sec/batch)
2017-10-17 23:19:06.011015: step 2560, loss = 0.93 (388.2 examples/sec; 0.330 sec/batch)
2017-10-17 23:19:09.306102: step 2570, loss = 0.85 (385.8 examples/sec; 0.332 sec/batch)
2017-10-17 23:19:12.603152: step 2580, loss = 0.98 (384.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:19:15.912815: step 2590, loss = 0.95 (381.9 examples/sec; 0.335 sec/batch)
2017-10-17 23:19:19.209328: step 2600, loss = 1.06 (392.0 examples/sec; 0.327 sec/batch)
2017-10-17 23:19:22.517325: step 2610, loss = 0.98 (387.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:19:25.831967: step 2620, loss = 0.94 (383.6 examples/sec; 0.334 sec/batch)
2017-10-17 23:19:29.131988: step 2630, loss = 1.13 (389.1 examples/sec; 0.329 sec/batch)
2017-10-17 23:19:32.436782: step 2640, loss = 0.83 (388.7 examples/sec; 0.329 sec/batch)
2017-10-17 23:19:35.740418: step 2650, loss = 2.27 (388.3 examples/sec; 0.330 sec/batch)
2017-10-17 23:19:39.026611: step 2660, loss = 1.57 (389.0 examples/sec; 0.329 sec/batch)
2017-10-17 23:19:42.304720: step 2670, loss = 1.34 (390.6 examples/sec; 0.328 sec/batch)
2017-10-17 23:19:45.581825: step 2680, loss = 1.06 (390.0 examples/sec; 0.328 sec/batch)
2017-10-17 23:19:48.877971: step 2690, loss = 1.35 (386.9 examples/sec; 0.331 sec/batch)
2017-10-17 23:19:52.162140: step 2700, loss = 1.18 (392.5 examples/sec; 0.326 sec/batch)
2017-10-17 23:19:55.445925: step 2710, loss = 0.99 (390.8 examples/sec; 0.328 sec/batch)
2017-10-17 23:19:58.747191: step 2720, loss = 1.31 (394.5 examples/sec; 0.324 sec/batch)
2017-10-17 23:20:02.041034: step 2730, loss = 1.26 (383.5 examples/sec; 0.334 sec/batch)
2017-10-17 23:20:05.336190: step 2740, loss = 1.63 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:20:08.621049: step 2750, loss = 0.95 (393.8 examples/sec; 0.325 sec/batch)
2017-10-17 23:20:11.913040: step 2760, loss = 1.20 (391.6 examples/sec; 0.327 sec/batch)
2017-10-17 23:20:15.217880: step 2770, loss = 1.15 (385.1 examples/sec; 0.332 sec/batch)
2017-10-17 23:20:18.522029: step 2780, loss = 1.01 (388.7 examples/sec; 0.329 sec/batch)
2017-10-17 23:20:21.835244: step 2790, loss = 0.86 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:20:25.145219: step 2800, loss = 1.27 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:20:28.439715: step 2810, loss = 0.96 (390.0 examples/sec; 0.328 sec/batch)
2017-10-17 23:20:31.739023: step 2820, loss = 1.30 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:20:35.041046: step 2830, loss = 0.97 (390.2 examples/sec; 0.328 sec/batch)
2017-10-17 23:20:38.343489: step 2840, loss = 1.32 (380.2 examples/sec; 0.337 sec/batch)
2017-10-17 23:20:41.638043: step 2850, loss = 1.03 (392.2 examples/sec; 0.326 sec/batch)
2017-10-17 23:20:44.932945: step 2860, loss = 1.38 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:20:48.226927: step 2870, loss = 1.04 (390.9 examples/sec; 0.327 sec/batch)
2017-10-17 23:20:51.528298: step 2880, loss = 0.83 (385.6 examples/sec; 0.332 sec/batch)
2017-10-17 23:20:54.837581: step 2890, loss = 1.03 (388.6 examples/sec; 0.329 sec/batch)
2017-10-17 23:20:58.145865: step 2900, loss = 1.11 (390.3 examples/sec; 0.328 sec/batch)
2017-10-17 23:21:01.455629: step 2910, loss = 0.95 (383.0 examples/sec; 0.334 sec/batch)
2017-10-17 23:21:04.785452: step 2920, loss = 1.22 (387.9 examples/sec; 0.330 sec/batch)
2017-10-17 23:21:08.101096: step 2930, loss = 0.96 (386.9 examples/sec; 0.331 sec/batch)
2017-10-17 23:21:11.425613: step 2940, loss = 0.95 (385.3 examples/sec; 0.332 sec/batch)
2017-10-17 23:21:14.737659: step 2950, loss = 1.16 (386.6 examples/sec; 0.331 sec/batch)
2017-10-17 23:21:18.034650: step 2960, loss = 1.02 (387.4 examples/sec; 0.330 sec/batch)
2017-10-17 23:21:21.331672: step 2970, loss = 1.03 (383.8 examples/sec; 0.333 sec/batch)
2017-10-17 23:21:24.631842: step 2980, loss = 1.10 (384.5 examples/sec; 0.333 sec/batch)
2017-10-17 23:21:27.948155: step 2990, loss = 0.91 (382.7 examples/sec; 0.334 sec/batch)
2017-10-17 23:21:31.256370: step 3000, loss = 0.86 (382.0 examples/sec; 0.335 sec/batch)
2017-10-17 23:21:34.544254: step 3010, loss = 28.64 (386.1 examples/sec; 0.332 sec/batch)
2017-10-17 23:21:37.920802: step 3020, loss = nan (394.4 examples/sec; 0.325 sec/batch)
2017-10-17 23:21:41.009415: step 3030, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:21:44.103069: step 3040, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-17 23:21:47.186311: step 3050, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:21:50.260230: step 3060, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-17 23:21:53.347421: step 3070, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-17 23:21:56.427075: step 3080, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-17 23:21:59.503928: step 3090, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:22:02.595810: step 3100, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:22:05.699285: step 3110, loss = nan (406.8 examples/sec; 0.315 sec/batch)
2017-10-17 23:22:08.804967: step 3120, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:22:11.885275: step 3130, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:22:14.985726: step 3140, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:22:18.060301: step 3150, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-17 23:22:21.131690: step 3160, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:22:24.209667: step 3170, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:22:27.356938: step 3180, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:22:30.430485: step 3190, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:22:33.505201: step 3200, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:22:36.576318: step 3210, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-17 23:22:39.651038: step 3220, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:22:42.738759: step 3230, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:22:45.831016: step 3240, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:22:48.915277: step 3250, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:22:51.982495: step 3260, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-17 23:22:55.076376: step 3270, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-17 23:22:58.160594: step 3280, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:01.245888: step 3290, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:04.358217: step 3300, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:07.450134: step 3310, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:23:10.547422: step 3320, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:23:13.650124: step 3330, loss = nan (416.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:16.734351: step 3340, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:23:19.807991: step 3350, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:23:22.904002: step 3360, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:25.974566: step 3370, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:23:29.061123: step 3380, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:32.149777: step 3390, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:23:35.229808: step 3400, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:23:38.306698: step 3410, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:23:41.494168: step 3420, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-17 23:23:44.576434: step 3430, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-17 23:23:47.668613: step 3440, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-17 23:23:50.782401: step 3450, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-17 23:23:53.863699: step 3460, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:23:56.940793: step 3470, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:24:00.028555: step 3480, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:24:03.111298: step 3490, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:24:06.189916: step 3500, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:24:09.280277: step 3510, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:24:12.357727: step 3520, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:24:15.440076: step 3530, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:24:18.507340: step 3540, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-17 23:24:21.602727: step 3550, loss = nan (402.7 examples/sec; 0.318 sec/batch)
2017-10-17 23:24:24.692845: step 3560, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:24:27.762163: step 3570, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:24:30.852850: step 3580, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:24:33.926978: step 3590, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-17 23:24:37.011455: step 3600, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:24:40.087610: step 3610, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:24:43.169174: step 3620, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:24:46.252242: step 3630, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:24:49.338742: step 3640, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:24:52.430570: step 3650, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-17 23:24:55.492945: step 3660, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:24:58.590396: step 3670, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:25:01.670319: step 3680, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:25:04.751101: step 3690, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:25:07.842664: step 3700, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:25:10.938160: step 3710, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:25:14.026961: step 3720, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:25:17.124176: step 3730, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:25:20.222325: step 3740, loss = nan (402.0 examples/sec; 0.318 sec/batch)
2017-10-17 23:25:23.317811: step 3750, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:25:26.424474: step 3760, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:25:29.502496: step 3770, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:25:32.613028: step 3780, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:25:35.714254: step 3790, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:25:38.809167: step 3800, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:25:41.897463: step 3810, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:25:44.981648: step 3820, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-17 23:25:48.071674: step 3830, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-17 23:25:51.167356: step 3840, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-17 23:25:54.246044: step 3850, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:25:57.366168: step 3860, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:00.461019: step 3870, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:03.547342: step 3880, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:26:06.635718: step 3890, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:26:09.734571: step 3900, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-17 23:26:12.827400: step 3910, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:26:15.922320: step 3920, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:26:19.008600: step 3930, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-17 23:26:22.092630: step 3940, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:26:25.165340: step 3950, loss = nan (422.8 examples/sec; 0.303 sec/batch)
2017-10-17 23:26:28.271031: step 3960, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:31.366691: step 3970, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:34.472822: step 3980, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:26:37.579757: step 3990, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:40.665947: step 4000, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-17 23:26:43.747889: step 4010, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:26:46.824475: step 4020, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:26:49.922484: step 4030, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:26:52.995852: step 4040, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:26:56.068938: step 4050, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:26:59.151268: step 4060, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:27:02.240555: step 4070, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:27:05.343855: step 4080, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-17 23:27:08.445647: step 4090, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:27:11.541894: step 4100, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:27:14.735500: step 4110, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:27:17.827908: step 4120, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:27:20.898935: step 4130, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:27:23.997168: step 4140, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:27:27.083216: step 4150, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-17 23:27:30.156212: step 4160, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:27:33.243331: step 4170, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:27:36.335565: step 4180, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:27:39.420050: step 4190, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-17 23:27:42.609236: step 4200, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:27:45.704389: step 4210, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-17 23:27:48.804022: step 4220, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:27:51.892945: step 4230, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:27:54.994278: step 4240, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:27:58.110253: step 4250, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:28:01.190772: step 4260, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:28:04.290115: step 4270, loss = nan (407.0 examples/sec; 0.314 sec/batch)
2017-10-17 23:28:07.389595: step 4280, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-17 23:28:10.457809: step 4290, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:28:13.530805: step 4300, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-17 23:28:16.606765: step 4310, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-17 23:28:19.685408: step 4320, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:28:22.765810: step 4330, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-17 23:28:25.831282: step 4340, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:28:28.927817: step 4350, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:28:32.011545: step 4360, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:28:35.087283: step 4370, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:28:38.290458: step 4380, loss = nan (406.7 examples/sec; 0.315 sec/batch)
2017-10-17 23:28:41.378876: step 4390, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-17 23:28:44.471867: step 4400, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-17 23:28:47.546933: step 4410, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:28:50.622456: step 4420, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:28:53.712691: step 4430, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-17 23:28:56.831125: step 4440, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-17 23:28:59.904660: step 4450, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:29:03.006256: step 4460, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:29:06.096156: step 4470, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-17 23:29:09.181147: step 4480, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:29:12.268859: step 4490, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:29:15.350375: step 4500, loss = nan (405.7 examples/sec; 0.315 sec/batch)
2017-10-17 23:29:18.436622: step 4510, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:29:21.521709: step 4520, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:29:24.708060: step 4530, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:29:27.799263: step 4540, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:29:30.889566: step 4550, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:29:33.971438: step 4560, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:29:37.072654: step 4570, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-17 23:29:40.173739: step 4580, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:29:43.259405: step 4590, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:29:46.332701: step 4600, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:29:49.423227: step 4610, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:29:52.531941: step 4620, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:29:55.604999: step 4630, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:29:58.704755: step 4640, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:30:01.804248: step 4650, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:30:04.887699: step 4660, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-17 23:30:07.957596: step 4670, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-17 23:30:11.042363: step 4680, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:30:14.112834: step 4690, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-17 23:30:17.190273: step 4700, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:30:20.275726: step 4710, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:30:23.383016: step 4720, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-17 23:30:26.474693: step 4730, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:30:29.568318: step 4740, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-17 23:30:32.647925: step 4750, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-17 23:30:35.730775: step 4760, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:30:38.826480: step 4770, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:30:41.921020: step 4780, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:30:45.008385: step 4790, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-17 23:30:48.092442: step 4800, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-17 23:30:51.177101: step 4810, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:30:54.263372: step 4820, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:30:57.349689: step 4830, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:31:00.561933: step 4840, loss = nan (306.3 examples/sec; 0.418 sec/batch)
2017-10-17 23:31:03.642533: step 4850, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:31:06.738775: step 4860, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:31:09.841982: step 4870, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:31:12.929527: step 4880, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:31:16.018170: step 4890, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:31:19.084023: step 4900, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:31:22.171320: step 4910, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:31:25.248983: step 4920, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:31:28.328695: step 4930, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:31:31.406532: step 4940, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:31:34.500656: step 4950, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-17 23:31:37.586857: step 4960, loss = nan (408.3 examples/sec; 0.313 sec/batch)
2017-10-17 23:31:40.663832: step 4970, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:31:43.748503: step 4980, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:31:46.839253: step 4990, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:31:49.919917: step 5000, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-17 23:31:53.026901: step 5010, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:31:56.138519: step 5020, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:31:59.245452: step 5030, loss = nan (406.6 examples/sec; 0.315 sec/batch)
2017-10-17 23:32:02.335942: step 5040, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-17 23:32:05.449724: step 5050, loss = nan (401.5 examples/sec; 0.319 sec/batch)
2017-10-17 23:32:08.559897: step 5060, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:32:11.784420: step 5070, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:32:14.886846: step 5080, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-17 23:32:17.970156: step 5090, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:32:21.048147: step 5100, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:32:24.137026: step 5110, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:32:27.201438: step 5120, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:32:30.291513: step 5130, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:32:33.373407: step 5140, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:32:36.472737: step 5150, loss = nan (407.0 examples/sec; 0.314 sec/batch)
2017-10-17 23:32:39.568368: step 5160, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:32:42.662469: step 5170, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:32:45.739317: step 5180, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-17 23:32:48.814369: step 5190, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:32:51.896755: step 5200, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:32:54.996732: step 5210, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:32:58.076018: step 5220, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-17 23:33:01.157094: step 5230, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:04.257248: step 5240, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-17 23:33:07.354784: step 5250, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-17 23:33:10.426467: step 5260, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:33:13.502662: step 5270, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:33:16.606690: step 5280, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:19.683981: step 5290, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-17 23:33:22.776152: step 5300, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-17 23:33:25.867003: step 5310, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:33:28.950175: step 5320, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:32.033390: step 5330, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:33:35.119655: step 5340, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-17 23:33:38.216468: step 5350, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:33:41.287593: step 5360, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:44.364778: step 5370, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-17 23:33:47.436799: step 5380, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:50.524759: step 5390, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:33:53.611082: step 5400, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:33:56.690137: step 5410, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:33:59.763782: step 5420, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:02.833961: step 5430, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-17 23:34:05.922540: step 5440, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:34:08.989025: step 5450, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:12.072374: step 5460, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:15.152508: step 5470, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:34:18.247957: step 5480, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:34:21.324160: step 5490, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:24.390964: step 5500, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:34:27.471723: step 5510, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:34:30.542545: step 5520, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:34:33.632721: step 5530, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:34:36.748911: step 5540, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-17 23:34:39.864632: step 5550, loss = nan (401.9 examples/sec; 0.319 sec/batch)
2017-10-17 23:34:42.957127: step 5560, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:46.052879: step 5570, loss = nan (406.6 examples/sec; 0.315 sec/batch)
2017-10-17 23:34:49.131800: step 5580, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:34:52.318127: step 5590, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:34:55.421167: step 5600, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:34:58.509935: step 5610, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:35:01.596970: step 5620, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-17 23:35:04.699282: step 5630, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:35:07.783792: step 5640, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:35:10.864473: step 5650, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:35:13.969044: step 5660, loss = nan (407.3 examples/sec; 0.314 sec/batch)
2017-10-17 23:35:17.151823: step 5670, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-17 23:35:20.339430: step 5680, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:35:23.430789: step 5690, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:35:26.510335: step 5700, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-17 23:35:29.613726: step 5710, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:35:32.699718: step 5720, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:35:35.769561: step 5730, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-17 23:35:38.864054: step 5740, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:35:41.965701: step 5750, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:35:45.153804: step 5760, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-17 23:35:48.223540: step 5770, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:35:51.311794: step 5780, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-17 23:35:54.403551: step 5790, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:35:57.582860: step 5800, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:36:00.668088: step 5810, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:36:03.763416: step 5820, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:36:06.859854: step 5830, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:36:09.936511: step 5840, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:36:13.038846: step 5850, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-17 23:36:16.158356: step 5860, loss = nan (401.1 examples/sec; 0.319 sec/batch)
2017-10-17 23:36:19.238532: step 5870, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:36:22.326836: step 5880, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-17 23:36:25.520595: step 5890, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:36:28.613770: step 5900, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-17 23:36:31.699485: step 5910, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-17 23:36:34.787244: step 5920, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-17 23:36:37.866391: step 5930, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:36:40.942126: step 5940, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:36:44.018766: step 5950, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:36:47.086431: step 5960, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:36:50.167598: step 5970, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:36:53.251120: step 5980, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:36:56.327709: step 5990, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-17 23:36:59.432627: step 6000, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:37:02.537247: step 6010, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:37:05.661278: step 6020, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-17 23:37:08.758761: step 6030, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:37:11.844078: step 6040, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:37:15.126044: step 6050, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-17 23:37:18.227038: step 6060, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-17 23:37:21.307858: step 6070, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:37:24.425924: step 6080, loss = nan (404.2 examples/sec; 0.317 sec/batch)
2017-10-17 23:37:27.508000: step 6090, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:37:30.592658: step 6100, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:37:33.675799: step 6110, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:37:36.769407: step 6120, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:37:39.874739: step 6130, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:37:42.962896: step 6140, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:37:46.071094: step 6150, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-17 23:37:49.174672: step 6160, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-17 23:37:52.247586: step 6170, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:37:55.336946: step 6180, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:37:58.514658: step 6190, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:01.599652: step 6200, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-17 23:38:04.668219: step 6210, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:07.756115: step 6220, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:38:10.840134: step 6230, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:38:13.923310: step 6240, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:17.129607: step 6250, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:38:20.234171: step 6260, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:38:23.329235: step 6270, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:38:26.398538: step 6280, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:38:29.471687: step 6290, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:38:32.555563: step 6300, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-17 23:38:35.647280: step 6310, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:38.722617: step 6320, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:38:41.822248: step 6330, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:38:44.910693: step 6340, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:47.984287: step 6350, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:38:51.086493: step 6360, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-17 23:38:54.174280: step 6370, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-17 23:38:57.253166: step 6380, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:39:00.348874: step 6390, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:39:03.437020: step 6400, loss = nan (422.8 examples/sec; 0.303 sec/batch)
2017-10-17 23:39:06.514819: step 6410, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:39:09.606941: step 6420, loss = nan (423.0 examples/sec; 0.303 sec/batch)
2017-10-17 23:39:12.707090: step 6430, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:39:15.792641: step 6440, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:39:18.868023: step 6450, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:39:21.939830: step 6460, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-17 23:39:25.016335: step 6470, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-17 23:39:28.106484: step 6480, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:39:31.187207: step 6490, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:39:34.273566: step 6500, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:39:37.365267: step 6510, loss = nan (404.8 examples/sec; 0.316 sec/batch)
2017-10-17 23:39:40.450032: step 6520, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:39:43.526223: step 6530, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:39:46.607410: step 6540, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:39:49.692106: step 6550, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:39:52.782269: step 6560, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:39:55.874840: step 6570, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:39:58.964011: step 6580, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:02.072672: step 6590, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:40:05.160496: step 6600, loss = nan (402.9 examples/sec; 0.318 sec/batch)
2017-10-17 23:40:08.250701: step 6610, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:11.350229: step 6620, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:14.439657: step 6630, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:40:17.538484: step 6640, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-17 23:40:20.618985: step 6650, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:40:23.710706: step 6660, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-17 23:40:26.803732: step 6670, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:40:29.887899: step 6680, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:32.997223: step 6690, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:40:36.082899: step 6700, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:40:39.183791: step 6710, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:42.278714: step 6720, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:40:45.357348: step 6730, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-17 23:40:48.438290: step 6740, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:40:51.537779: step 6750, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:40:54.632294: step 6760, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:40:57.756734: step 6770, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:41:00.876595: step 6780, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:41:03.970785: step 6790, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-17 23:41:07.060966: step 6800, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-17 23:41:10.149024: step 6810, loss = nan (423.5 examples/sec; 0.302 sec/batch)
2017-10-17 23:41:13.228725: step 6820, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-17 23:41:16.416322: step 6830, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:41:19.491296: step 6840, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:41:22.562250: step 6850, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:41:25.645261: step 6860, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:41:28.732397: step 6870, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:41:31.818754: step 6880, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:41:34.924804: step 6890, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:41:38.000521: step 6900, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:41:41.096212: step 6910, loss = nan (403.9 examples/sec; 0.317 sec/batch)
2017-10-17 23:41:44.169069: step 6920, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:41:47.265259: step 6930, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:41:50.360743: step 6940, loss = nan (390.0 examples/sec; 0.328 sec/batch)
2017-10-17 23:41:53.459285: step 6950, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:41:56.572950: step 6960, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:41:59.650025: step 6970, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:42:02.755576: step 6980, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:42:05.855763: step 6990, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:42:08.955206: step 7000, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:42:12.045559: step 7010, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:42:15.121188: step 7020, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:42:18.198004: step 7030, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:42:21.270069: step 7040, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:42:24.465091: step 7050, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:42:27.542782: step 7060, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:42:30.621638: step 7070, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-17 23:42:33.718150: step 7080, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:42:36.792815: step 7090, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:42:39.873790: step 7100, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:42:42.937817: step 7110, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:42:46.021359: step 7120, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:42:49.079603: step 7130, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:42:52.154484: step 7140, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-17 23:42:55.237662: step 7150, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-17 23:42:58.307475: step 7160, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:43:01.409883: step 7170, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:43:04.492969: step 7180, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:43:07.570435: step 7190, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:43:10.717523: step 7200, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-17 23:43:13.806764: step 7210, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-17 23:43:16.891425: step 7220, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:43:19.971576: step 7230, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-17 23:43:23.042118: step 7240, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:43:26.119417: step 7250, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:43:29.208558: step 7260, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:43:32.311670: step 7270, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:43:35.397441: step 7280, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:43:38.488621: step 7290, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:43:41.559769: step 7300, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:43:44.651301: step 7310, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-17 23:43:47.752718: step 7320, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:43:50.846274: step 7330, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:43:53.953868: step 7340, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-17 23:43:57.032965: step 7350, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-17 23:44:00.140361: step 7360, loss = nan (400.2 examples/sec; 0.320 sec/batch)
2017-10-17 23:44:03.220743: step 7370, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:44:06.303918: step 7380, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:44:09.391631: step 7390, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:44:12.482176: step 7400, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:44:15.581243: step 7410, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:44:18.668745: step 7420, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:44:21.759274: step 7430, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:44:24.858698: step 7440, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:44:27.933580: step 7450, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-17 23:44:31.018917: step 7460, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:44:34.121456: step 7470, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:44:37.195343: step 7480, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:44:40.287287: step 7490, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:44:43.363585: step 7500, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:44:46.564127: step 7510, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:44:49.660796: step 7520, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:44:52.760618: step 7530, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-17 23:44:55.839091: step 7540, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:44:58.936024: step 7550, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:45:02.047407: step 7560, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:45:05.155942: step 7570, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-17 23:45:08.237611: step 7580, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-17 23:45:11.334661: step 7590, loss = nan (406.3 examples/sec; 0.315 sec/batch)
2017-10-17 23:45:14.434299: step 7600, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-17 23:45:17.516249: step 7610, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:45:20.591434: step 7620, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-17 23:45:23.685042: step 7630, loss = nan (409.6 examples/sec; 0.313 sec/batch)
2017-10-17 23:45:26.762259: step 7640, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-17 23:45:29.862961: step 7650, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:45:32.951687: step 7660, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:45:36.037363: step 7670, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-17 23:45:39.128165: step 7680, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:45:42.210704: step 7690, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:45:45.299285: step 7700, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:45:48.377421: step 7710, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:45:51.456204: step 7720, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:45:54.651968: step 7730, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:45:57.741408: step 7740, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:00.833355: step 7750, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:03.918361: step 7760, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-17 23:46:06.998305: step 7770, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:46:10.110147: step 7780, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:46:13.212571: step 7790, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:16.322140: step 7800, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:19.415912: step 7810, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:22.515110: step 7820, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:46:25.579507: step 7830, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:46:28.669827: step 7840, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:31.751373: step 7850, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:46:34.850418: step 7860, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-17 23:46:37.945289: step 7870, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:46:41.037670: step 7880, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-17 23:46:44.146660: step 7890, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:46:47.230435: step 7900, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:46:50.302204: step 7910, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:46:53.376080: step 7920, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-17 23:46:56.459268: step 7930, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:46:59.558144: step 7940, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:47:02.647862: step 7950, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-17 23:47:05.746933: step 7960, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:47:08.840857: step 7970, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:47:11.935291: step 7980, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:47:15.016747: step 7990, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:47:18.111984: step 8000, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:47:21.225375: step 8010, loss = nan (405.7 examples/sec; 0.315 sec/batch)
2017-10-17 23:47:24.305671: step 8020, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-17 23:47:27.401622: step 8030, loss = nan (401.1 examples/sec; 0.319 sec/batch)
2017-10-17 23:47:30.488059: step 8040, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:47:33.683820: step 8050, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:47:36.767467: step 8060, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:47:39.870755: step 8070, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-17 23:47:42.952515: step 8080, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-17 23:47:46.044396: step 8090, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:47:49.136954: step 8100, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:47:52.222022: step 8110, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:47:55.311818: step 8120, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:47:58.396186: step 8130, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:01.485087: step 8140, loss = nan (402.9 examples/sec; 0.318 sec/batch)
2017-10-17 23:48:04.565682: step 8150, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:07.657068: step 8160, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:10.770073: step 8170, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:48:13.858084: step 8180, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:48:17.073309: step 8190, loss = nan (307.1 examples/sec; 0.417 sec/batch)
2017-10-17 23:48:20.142095: step 8200, loss = nan (422.7 examples/sec; 0.303 sec/batch)
2017-10-17 23:48:23.213667: step 8210, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-17 23:48:26.311104: step 8220, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:29.409474: step 8230, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:48:32.495455: step 8240, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:35.590794: step 8250, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:48:38.688141: step 8260, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:41.767837: step 8270, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:48:44.843825: step 8280, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-17 23:48:47.937761: step 8290, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:48:51.021116: step 8300, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:48:54.099494: step 8310, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:48:57.179707: step 8320, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:49:00.267914: step 8330, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:49:03.362739: step 8340, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-17 23:49:06.456996: step 8350, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:49:09.667143: step 8360, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-17 23:49:12.853946: step 8370, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:49:15.939718: step 8380, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:49:19.081336: step 8390, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:49:22.166825: step 8400, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:49:25.260289: step 8410, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-17 23:49:28.339304: step 8420, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:49:31.413776: step 8430, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:49:34.504151: step 8440, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-17 23:49:37.582267: step 8450, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:49:40.667297: step 8460, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:49:43.758470: step 8470, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-17 23:49:46.843909: step 8480, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-17 23:49:49.933928: step 8490, loss = nan (402.4 examples/sec; 0.318 sec/batch)
2017-10-17 23:49:53.015576: step 8500, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-17 23:49:56.107471: step 8510, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-17 23:49:59.194561: step 8520, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:02.279797: step 8530, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-17 23:50:05.373246: step 8540, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:08.447887: step 8550, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:50:11.564700: step 8560, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-17 23:50:14.629766: step 8570, loss = nan (422.2 examples/sec; 0.303 sec/batch)
2017-10-17 23:50:17.705662: step 8580, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:50:20.798559: step 8590, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:23.873928: step 8600, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:26.967268: step 8610, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:30.069618: step 8620, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:50:33.167370: step 8630, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:50:36.254687: step 8640, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:50:39.363935: step 8650, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:50:42.460936: step 8660, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:50:45.564331: step 8670, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-17 23:50:48.643745: step 8680, loss = nan (422.4 examples/sec; 0.303 sec/batch)
2017-10-17 23:50:51.746601: step 8690, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-17 23:50:54.832265: step 8700, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-17 23:50:57.913129: step 8710, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:51:01.004096: step 8720, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:51:04.112012: step 8730, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-17 23:51:07.213187: step 8740, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-17 23:51:10.299443: step 8750, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-17 23:51:13.378013: step 8760, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:51:16.457217: step 8770, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:51:19.548953: step 8780, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:51:22.651742: step 8790, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:51:25.736163: step 8800, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:51:28.892085: step 8810, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:51:31.980596: step 8820, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:51:35.063042: step 8830, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-17 23:51:38.160099: step 8840, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:51:41.233947: step 8850, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:51:44.307411: step 8860, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:51:47.390353: step 8870, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:51:50.467153: step 8880, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:51:53.538789: step 8890, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:51:56.613278: step 8900, loss = nan (416.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:51:59.700859: step 8910, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:52:02.782147: step 8920, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-17 23:52:05.875895: step 8930, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:52:08.967668: step 8940, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-17 23:52:12.038512: step 8950, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-17 23:52:15.129309: step 8960, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-17 23:52:18.219541: step 8970, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-17 23:52:21.308848: step 8980, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:52:24.392404: step 8990, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:52:27.466059: step 9000, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-17 23:52:30.546381: step 9010, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:52:33.641082: step 9020, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-17 23:52:36.734860: step 9030, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-17 23:52:39.813819: step 9040, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:52:42.895215: step 9050, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:52:45.982858: step 9060, loss = nan (405.7 examples/sec; 0.315 sec/batch)
2017-10-17 23:52:49.058728: step 9070, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:52:52.151492: step 9080, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-17 23:52:55.244383: step 9090, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:52:58.332468: step 9100, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:53:01.415595: step 9110, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-17 23:53:04.507327: step 9120, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:53:07.604374: step 9130, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-17 23:53:10.795472: step 9140, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-17 23:53:13.870867: step 9150, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:53:16.969377: step 9160, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-17 23:53:20.053852: step 9170, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-17 23:53:23.127615: step 9180, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:53:26.197129: step 9190, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:53:29.299534: step 9200, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:53:32.397530: step 9210, loss = nan (407.0 examples/sec; 0.314 sec/batch)
2017-10-17 23:53:35.469399: step 9220, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:53:38.567444: step 9230, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-17 23:53:41.656382: step 9240, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-17 23:53:44.748146: step 9250, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:53:47.817384: step 9260, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-17 23:53:50.894571: step 9270, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:53:54.121480: step 9280, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:53:57.205276: step 9290, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:54:00.392813: step 9300, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:54:03.489778: step 9310, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:54:06.612803: step 9320, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-17 23:54:09.720253: step 9330, loss = nan (402.3 examples/sec; 0.318 sec/batch)
2017-10-17 23:54:12.810217: step 9340, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:54:15.888010: step 9350, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-17 23:54:18.988910: step 9360, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:54:22.063641: step 9370, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-17 23:54:25.155118: step 9380, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-17 23:54:28.253380: step 9390, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-17 23:54:31.450433: step 9400, loss = nan (422.8 examples/sec; 0.303 sec/batch)
2017-10-17 23:54:34.538988: step 9410, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:54:37.617584: step 9420, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:54:40.705551: step 9430, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:54:43.788548: step 9440, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-17 23:54:46.880929: step 9450, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:54:49.967322: step 9460, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:54:53.065427: step 9470, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:54:56.163381: step 9480, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:54:59.275792: step 9490, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-17 23:55:02.371569: step 9500, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:55:05.458351: step 9510, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-17 23:55:08.554196: step 9520, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-17 23:55:11.631169: step 9530, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-17 23:55:14.715617: step 9540, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:55:17.803569: step 9550, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-17 23:55:20.889965: step 9560, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-17 23:55:23.993023: step 9570, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-17 23:55:27.073834: step 9580, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:55:30.167654: step 9590, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-17 23:55:33.248745: step 9600, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-17 23:55:36.453497: step 9610, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-17 23:55:39.532922: step 9620, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:55:42.607748: step 9630, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-17 23:55:45.691625: step 9640, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:55:48.782309: step 9650, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-17 23:55:51.860513: step 9660, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:55:54.950970: step 9670, loss = nan (405.2 examples/sec; 0.316 sec/batch)
2017-10-17 23:55:58.056167: step 9680, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:56:01.144347: step 9690, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:56:04.231084: step 9700, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:56:07.324065: step 9710, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:56:10.404193: step 9720, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:56:13.477774: step 9730, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:56:16.556605: step 9740, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:56:19.632982: step 9750, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-17 23:56:22.716064: step 9760, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:56:25.798461: step 9770, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:56:28.887548: step 9780, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-17 23:56:31.965216: step 9790, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:56:35.055568: step 9800, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-17 23:56:38.135633: step 9810, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:56:41.215462: step 9820, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-17 23:56:44.302380: step 9830, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-17 23:56:47.387816: step 9840, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:56:50.490442: step 9850, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-17 23:56:53.566046: step 9860, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:56:56.647554: step 9870, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-17 23:56:59.747960: step 9880, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:57:02.840124: step 9890, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-17 23:57:05.920546: step 9900, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-17 23:57:08.991932: step 9910, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-17 23:57:12.091591: step 9920, loss = nan (403.7 examples/sec; 0.317 sec/batch)
2017-10-17 23:57:15.179158: step 9930, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:57:18.271492: step 9940, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:57:21.353213: step 9950, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:57:24.459837: step 9960, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-17 23:57:27.569842: step 9970, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:57:30.674836: step 9980, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:57:33.764970: step 9990, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-17 23:57:36.863219: step 10000, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-17 23:57:39.953267: step 10010, loss = nan (397.9 examples/sec; 0.322 sec/batch)
2017-10-17 23:57:43.050312: step 10020, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:57:46.138163: step 10030, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-17 23:57:49.224228: step 10040, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-17 23:57:52.308029: step 10050, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-17 23:57:55.389766: step 10060, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:57:58.480323: step 10070, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-17 23:58:01.566105: step 10080, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:58:04.661493: step 10090, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-17 23:58:07.749337: step 10100, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-17 23:58:10.844924: step 10110, loss = nan (405.3 examples/sec; 0.316 sec/batch)
2017-10-17 23:58:13.939888: step 10120, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-17 23:58:17.022849: step 10130, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-17 23:58:20.110267: step 10140, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-17 23:58:23.211698: step 10150, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-17 23:58:26.295687: step 10160, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:58:29.385019: step 10170, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-17 23:58:32.457712: step 10180, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:58:35.566598: step 10190, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-17 23:58:38.673287: step 10200, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-17 23:58:41.760979: step 10210, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-17 23:58:44.846882: step 10220, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-17 23:58:47.927171: step 10230, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-17 23:58:51.018197: step 10240, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-17 23:58:54.112022: step 10250, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-17 23:58:57.192971: step 10260, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-17 23:59:00.279414: step 10270, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:59:03.368248: step 10280, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-17 23:59:06.465339: step 10290, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-17 23:59:09.567099: step 10300, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-17 23:59:12.656343: step 10310, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-17 23:59:15.733361: step 10320, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-17 23:59:18.826855: step 10330, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-17 23:59:21.945504: step 10340, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-17 23:59:25.069144: step 10350, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-17 23:59:28.152551: step 10360, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-17 23:59:31.244310: step 10370, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:59:34.325067: step 10380, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-17 23:59:37.406700: step 10390, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-17 23:59:40.468113: step 10400, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-17 23:59:43.547022: step 10410, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-17 23:59:46.624624: step 10420, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-17 23:59:49.719394: step 10430, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-17 23:59:52.803053: step 10440, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-17 23:59:55.878432: step 10450, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-17 23:59:58.961598: step 10460, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:00:02.042569: step 10470, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:00:05.342143: step 10480, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:00:08.406611: step 10490, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:00:11.488695: step 10500, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:00:14.605625: step 10510, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:00:17.677189: step 10520, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 00:00:20.766057: step 10530, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:00:23.865100: step 10540, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:00:26.949088: step 10550, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:00:30.040301: step 10560, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:00:33.129418: step 10570, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:00:36.205568: step 10580, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:00:39.323108: step 10590, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:00:42.399835: step 10600, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:00:45.478536: step 10610, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:00:48.581026: step 10620, loss = nan (394.6 examples/sec; 0.324 sec/batch)
2017-10-18 00:00:51.685261: step 10630, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:00:54.774572: step 10640, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:00:57.855037: step 10650, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:01:00.946639: step 10660, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:01:04.046256: step 10670, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:01:07.138844: step 10680, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:01:10.213417: step 10690, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:01:13.303441: step 10700, loss = nan (406.3 examples/sec; 0.315 sec/batch)
2017-10-18 00:01:16.386822: step 10710, loss = nan (421.9 examples/sec; 0.303 sec/batch)
2017-10-18 00:01:19.456659: step 10720, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:01:22.534232: step 10730, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:01:25.629531: step 10740, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:01:28.696386: step 10750, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:01:31.787518: step 10760, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:01:34.864911: step 10770, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:01:37.930448: step 10780, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:01:41.027395: step 10790, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:01:44.112924: step 10800, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:01:47.290228: step 10810, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 00:01:50.357673: step 10820, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:01:53.449548: step 10830, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:01:56.524621: step 10840, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:01:59.598610: step 10850, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:02:02.670174: step 10860, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:02:05.866490: step 10870, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:02:08.964919: step 10880, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:02:12.063315: step 10890, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 00:02:15.155662: step 10900, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:02:18.244848: step 10910, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:02:21.324321: step 10920, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:02:24.386769: step 10930, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:02:27.471273: step 10940, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:02:30.560337: step 10950, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:02:33.628388: step 10960, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:02:36.726428: step 10970, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:02:39.805300: step 10980, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:02:42.888712: step 10990, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:02:45.958841: step 11000, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:02:49.041868: step 11010, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:02:52.128610: step 11020, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:02:55.312047: step 11030, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:02:58.392737: step 11040, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 00:03:01.477499: step 11050, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:03:04.588648: step 11060, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:03:07.676073: step 11070, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:03:10.765131: step 11080, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:03:13.872239: step 11090, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 00:03:16.982876: step 11100, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 00:03:20.093313: step 11110, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:03:23.180311: step 11120, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:03:26.267651: step 11130, loss = nan (422.4 examples/sec; 0.303 sec/batch)
2017-10-18 00:03:29.341284: step 11140, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:03:32.428744: step 11150, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:03:35.508781: step 11160, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:03:38.596772: step 11170, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:03:41.689937: step 11180, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:03:44.770483: step 11190, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:03:47.853127: step 11200, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:03:50.939012: step 11210, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:03:54.013768: step 11220, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 00:03:57.102670: step 11230, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:04:00.186122: step 11240, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:04:03.275491: step 11250, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:04:06.365540: step 11260, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:04:09.558172: step 11270, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:12.638876: step 11280, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:04:15.726161: step 11290, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:04:18.803383: step 11300, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:04:21.897908: step 11310, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:04:25.077392: step 11320, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:28.171497: step 11330, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:04:31.262868: step 11340, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:34.331825: step 11350, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:37.415028: step 11360, loss = nan (409.6 examples/sec; 0.313 sec/batch)
2017-10-18 00:04:40.499455: step 11370, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:43.587816: step 11380, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:04:46.684893: step 11390, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:49.755907: step 11400, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:04:52.835809: step 11410, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:04:55.921442: step 11420, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:04:59.015097: step 11430, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 00:05:02.099968: step 11440, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-18 00:05:05.299321: step 11450, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:05:08.391101: step 11460, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:05:11.490865: step 11470, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:05:14.693771: step 11480, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:05:17.782524: step 11490, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:05:20.922490: step 11500, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:05:24.010246: step 11510, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:05:27.100582: step 11520, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-18 00:05:30.197615: step 11530, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 00:05:33.298860: step 11540, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:05:36.387042: step 11550, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 00:05:39.474239: step 11560, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:05:42.541975: step 11570, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:05:45.633681: step 11580, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:05:48.737529: step 11590, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:05:51.831489: step 11600, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:05:54.914513: step 11610, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:05:57.987397: step 11620, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 00:06:01.062077: step 11630, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:06:04.281241: step 11640, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:06:07.368791: step 11650, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:06:10.457258: step 11660, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:06:13.548886: step 11670, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:06:16.623214: step 11680, loss = nan (423.2 examples/sec; 0.302 sec/batch)
2017-10-18 00:06:19.830464: step 11690, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:06:22.907335: step 11700, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:06:26.019320: step 11710, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:06:29.127341: step 11720, loss = nan (401.4 examples/sec; 0.319 sec/batch)
2017-10-18 00:06:32.230670: step 11730, loss = nan (404.4 examples/sec; 0.317 sec/batch)
2017-10-18 00:06:35.317146: step 11740, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:06:38.403749: step 11750, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:06:41.606290: step 11760, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:06:44.684461: step 11770, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:06:47.756138: step 11780, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:06:50.833743: step 11790, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:06:53.919800: step 11800, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 00:06:57.109804: step 11810, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:07:00.193037: step 11820, loss = nan (404.9 examples/sec; 0.316 sec/batch)
2017-10-18 00:07:03.276603: step 11830, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:07:06.387138: step 11840, loss = nan (409.6 examples/sec; 0.313 sec/batch)
2017-10-18 00:07:09.477500: step 11850, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:07:12.570232: step 11860, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 00:07:15.663481: step 11870, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:07:18.728160: step 11880, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:07:21.830476: step 11890, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 00:07:24.934074: step 11900, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:07:28.051928: step 11910, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 00:07:31.157083: step 11920, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:07:34.244199: step 11930, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:07:37.329081: step 11940, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:07:40.431495: step 11950, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:07:43.512961: step 11960, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:07:46.786283: step 11970, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 00:07:49.853249: step 11980, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:07:52.945116: step 11990, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:07:56.026163: step 12000, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:07:59.111048: step 12010, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:08:02.205495: step 12020, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 00:08:05.389923: step 12030, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 00:08:08.473465: step 12040, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 00:08:11.562050: step 12050, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 00:08:14.652553: step 12060, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:08:17.737600: step 12070, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:08:20.808999: step 12080, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 00:08:23.883908: step 12090, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:08:26.966472: step 12100, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 00:08:30.047993: step 12110, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:08:33.120652: step 12120, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:08:36.211793: step 12130, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:08:39.298001: step 12140, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:08:42.377499: step 12150, loss = nan (402.9 examples/sec; 0.318 sec/batch)
2017-10-18 00:08:45.459311: step 12160, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:08:48.536515: step 12170, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:08:51.634912: step 12180, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:08:54.713588: step 12190, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:08:57.801620: step 12200, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:09:00.874715: step 12210, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:09:03.943716: step 12220, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:09:07.024346: step 12230, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:09:10.116472: step 12240, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:09:13.207105: step 12250, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:09:16.285543: step 12260, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:09:19.367132: step 12270, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:09:22.454874: step 12280, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:09:25.546268: step 12290, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:09:28.636296: step 12300, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:09:31.729490: step 12310, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 00:09:34.919110: step 12320, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:09:38.011312: step 12330, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:09:41.082341: step 12340, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 00:09:44.162073: step 12350, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:09:47.345308: step 12360, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:09:50.417513: step 12370, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:09:53.490021: step 12380, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:09:56.586872: step 12390, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:09:59.665604: step 12400, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:10:02.760342: step 12410, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:10:05.830863: step 12420, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:10:08.914381: step 12430, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:10:12.002509: step 12440, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:10:15.139874: step 12450, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:10:18.245693: step 12460, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:10:21.327969: step 12470, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:10:24.422109: step 12480, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:10:27.506435: step 12490, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:10:30.590805: step 12500, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 00:10:33.678636: step 12510, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:10:36.785366: step 12520, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-18 00:10:39.889663: step 12530, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:10:42.972170: step 12540, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:10:46.056121: step 12550, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:10:49.137547: step 12560, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:10:52.236592: step 12570, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:10:55.321966: step 12580, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 00:10:58.402155: step 12590, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:11:01.516285: step 12600, loss = nan (393.7 examples/sec; 0.325 sec/batch)
2017-10-18 00:11:04.594864: step 12610, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:11:07.683607: step 12620, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 00:11:10.757917: step 12630, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:11:13.849201: step 12640, loss = nan (405.4 examples/sec; 0.316 sec/batch)
2017-10-18 00:11:16.926599: step 12650, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:11:20.012336: step 12660, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:11:23.091333: step 12670, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:11:26.172254: step 12680, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:11:29.257630: step 12690, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 00:11:32.328689: step 12700, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:11:35.413054: step 12710, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:11:38.486491: step 12720, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 00:11:41.576901: step 12730, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:11:44.650527: step 12740, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:11:47.740101: step 12750, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 00:11:50.821176: step 12760, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:11:53.899878: step 12770, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:11:56.997906: step 12780, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:12:00.079516: step 12790, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:12:03.152717: step 12800, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:12:06.265146: step 12810, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 00:12:09.358136: step 12820, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:12:12.438989: step 12830, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:12:15.527468: step 12840, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:12:18.598856: step 12850, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:12:21.690318: step 12860, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:12:24.778374: step 12870, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:12:27.862062: step 12880, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:12:30.982075: step 12890, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:12:34.066691: step 12900, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:12:37.158452: step 12910, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:12:40.272970: step 12920, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:12:43.397816: step 12930, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:12:46.493517: step 12940, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:12:49.592271: step 12950, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:12:52.694572: step 12960, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:12:55.780391: step 12970, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:12:58.869653: step 12980, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:13:01.973542: step 12990, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:13:05.062322: step 13000, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 00:13:08.154740: step 13010, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:13:11.243363: step 13020, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:13:14.319566: step 13030, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:13:17.399084: step 13040, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:13:20.487663: step 13050, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:13:23.575691: step 13060, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:13:26.663653: step 13070, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:13:29.740849: step 13080, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:13:32.846786: step 13090, loss = nan (406.2 examples/sec; 0.315 sec/batch)
2017-10-18 00:13:35.922943: step 13100, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:13:39.005735: step 13110, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:13:42.080732: step 13120, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:13:45.162856: step 13130, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 00:13:48.250540: step 13140, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:13:51.442414: step 13150, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:13:54.533254: step 13160, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:13:57.618476: step 13170, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:14:00.704224: step 13180, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:14:03.782317: step 13190, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 00:14:06.868483: step 13200, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:14:10.065833: step 13210, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:14:13.145211: step 13220, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:14:16.272704: step 13230, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:14:19.345153: step 13240, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:14:22.412399: step 13250, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:14:25.499509: step 13260, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:14:28.592043: step 13270, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:14:31.690024: step 13280, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:14:34.766133: step 13290, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:14:37.852590: step 13300, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:14:40.951260: step 13310, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:14:44.039155: step 13320, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:14:47.133613: step 13330, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:14:50.222201: step 13340, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:14:53.316528: step 13350, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:14:56.399637: step 13360, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:14:59.484531: step 13370, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:15:02.567301: step 13380, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:15:05.650801: step 13390, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:15:08.733942: step 13400, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:15:11.827514: step 13410, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:15:14.914974: step 13420, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:15:17.992644: step 13430, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:15:21.192350: step 13440, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:15:24.278302: step 13450, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:15:27.353673: step 13460, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:15:30.416812: step 13470, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 00:15:33.504210: step 13480, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:15:36.611109: step 13490, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:15:39.711174: step 13500, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:15:42.783848: step 13510, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:15:45.877734: step 13520, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:15:48.955555: step 13530, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:15:52.045639: step 13540, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:15:55.127660: step 13550, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 00:15:58.217345: step 13560, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:16:01.323093: step 13570, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 00:16:04.413368: step 13580, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-18 00:16:07.503975: step 13590, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:16:10.590220: step 13600, loss = nan (412.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:16:13.676313: step 13610, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:16:16.779455: step 13620, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:16:19.869140: step 13630, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:16:22.962959: step 13640, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:16:26.050628: step 13650, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 00:16:29.133707: step 13660, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:16:32.215196: step 13670, loss = nan (422.6 examples/sec; 0.303 sec/batch)
2017-10-18 00:16:35.291001: step 13680, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:16:38.383714: step 13690, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 00:16:41.462486: step 13700, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:16:44.551014: step 13710, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:16:47.635566: step 13720, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:16:50.731615: step 13730, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:16:53.925671: step 13740, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:16:57.030925: step 13750, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:17:00.107837: step 13760, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:17:03.205947: step 13770, loss = nan (406.8 examples/sec; 0.315 sec/batch)
2017-10-18 00:17:06.318006: step 13780, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:17:09.416330: step 13790, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:17:12.516662: step 13800, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:17:15.611068: step 13810, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:17:18.695354: step 13820, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:17:21.771679: step 13830, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 00:17:24.854857: step 13840, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 00:17:27.937637: step 13850, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 00:17:31.025134: step 13860, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:17:34.119089: step 13870, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:17:37.307255: step 13880, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:17:40.395492: step 13890, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:17:43.483976: step 13900, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:17:46.583381: step 13910, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:17:49.788935: step 13920, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:17:52.859772: step 13930, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:17:55.951076: step 13940, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:17:59.042982: step 13950, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 00:18:02.135062: step 13960, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:18:05.209561: step 13970, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:18:08.306625: step 13980, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:18:11.407736: step 13990, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:18:14.484349: step 14000, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:18:17.574422: step 14010, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:18:20.657289: step 14020, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:18:23.759851: step 14030, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:18:26.862078: step 14040, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:18:29.942104: step 14050, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:18:33.021118: step 14060, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:18:36.367406: step 14070, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:18:39.442753: step 14080, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:18:42.531708: step 14090, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:18:45.603422: step 14100, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:18:48.662417: step 14110, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-18 00:18:51.736884: step 14120, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:18:54.832493: step 14130, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:18:57.938112: step 14140, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 00:19:01.020247: step 14150, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:19:04.112871: step 14160, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:19:07.189999: step 14170, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 00:19:10.300669: step 14180, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:19:13.375430: step 14190, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:19:16.473285: step 14200, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 00:19:19.556483: step 14210, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:19:22.625614: step 14220, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:19:25.713652: step 14230, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:19:28.795554: step 14240, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:19:31.890839: step 14250, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:19:34.989721: step 14260, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:19:38.073206: step 14270, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:19:41.147042: step 14280, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:19:44.227054: step 14290, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:19:47.297208: step 14300, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:19:50.385006: step 14310, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:19:53.491863: step 14320, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:19:56.581110: step 14330, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 00:19:59.667728: step 14340, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:20:02.749484: step 14350, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:20:05.838620: step 14360, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:20:08.912262: step 14370, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:20:12.009126: step 14380, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:20:15.095004: step 14390, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:20:18.170280: step 14400, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:20:21.243334: step 14410, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:20:24.335666: step 14420, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:20:27.436559: step 14430, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:20:30.539672: step 14440, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:20:33.744306: step 14450, loss = nan (307.8 examples/sec; 0.416 sec/batch)
2017-10-18 00:20:36.846013: step 14460, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:20:39.961932: step 14470, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:20:43.046212: step 14480, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:20:46.113738: step 14490, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:20:49.184179: step 14500, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:20:52.261189: step 14510, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 00:20:55.342497: step 14520, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:20:58.443804: step 14530, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:21:01.525568: step 14540, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:21:04.622524: step 14550, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:21:07.695266: step 14560, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:21:10.783838: step 14570, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:21:13.874682: step 14580, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:21:16.951298: step 14590, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:21:20.024856: step 14600, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:21:23.104764: step 14610, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:21:26.164396: step 14620, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:21:29.241371: step 14630, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:21:32.316902: step 14640, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:21:35.396359: step 14650, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:21:38.479455: step 14660, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:21:41.570744: step 14670, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:21:44.669113: step 14680, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:21:47.758483: step 14690, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:21:50.854340: step 14700, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:21:53.933851: step 14710, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:21:57.008048: step 14720, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:22:00.113958: step 14730, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:22:03.312096: step 14740, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:22:06.408969: step 14750, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:22:09.491499: step 14760, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:22:12.591654: step 14770, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:22:15.678496: step 14780, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:22:18.766915: step 14790, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:22:21.841047: step 14800, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:22:24.935001: step 14810, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:22:28.010204: step 14820, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:22:31.075049: step 14830, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 00:22:34.160848: step 14840, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:22:37.259686: step 14850, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:22:40.442089: step 14860, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:22:43.536800: step 14870, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 00:22:46.630848: step 14880, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 00:22:49.715510: step 14890, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:22:52.821091: step 14900, loss = nan (408.3 examples/sec; 0.314 sec/batch)
2017-10-18 00:22:55.908298: step 14910, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:22:58.988151: step 14920, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:23:02.064701: step 14930, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:05.152088: step 14940, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:23:08.230253: step 14950, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:23:11.313668: step 14960, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:14.379699: step 14970, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:17.484852: step 14980, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:23:20.566124: step 14990, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:23:23.650008: step 15000, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:23:26.703839: step 15010, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:23:29.777575: step 15020, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 00:23:32.865943: step 15030, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:23:35.945880: step 15040, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:23:39.030563: step 15050, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:23:42.122925: step 15060, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:23:45.212418: step 15070, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:48.297743: step 15080, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:51.377557: step 15090, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:23:54.453024: step 15100, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:23:57.545986: step 15110, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:24:00.625682: step 15120, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:24:03.705628: step 15130, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:24:06.792330: step 15140, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:24:09.880598: step 15150, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 00:24:12.961096: step 15160, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:24:16.052670: step 15170, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 00:24:19.143050: step 15180, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:24:22.221714: step 15190, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:24:25.302029: step 15200, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:24:28.507199: step 15210, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:24:31.604606: step 15220, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:24:34.702248: step 15230, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:24:37.809337: step 15240, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:24:40.900348: step 15250, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 00:24:44.014319: step 15260, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 00:24:47.076771: step 15270, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:24:50.165023: step 15280, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:24:53.261779: step 15290, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:24:56.344273: step 15300, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:24:59.419137: step 15310, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:25:02.509729: step 15320, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:25:05.601963: step 15330, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:25:08.684842: step 15340, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:25:11.782955: step 15350, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:25:14.860288: step 15360, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:25:17.948594: step 15370, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 00:25:21.025469: step 15380, loss = nan (422.6 examples/sec; 0.303 sec/batch)
2017-10-18 00:25:24.100810: step 15390, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:25:27.195361: step 15400, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:25:30.298297: step 15410, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:25:33.389273: step 15420, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:25:36.510861: step 15430, loss = nan (397.5 examples/sec; 0.322 sec/batch)
2017-10-18 00:25:39.598115: step 15440, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:25:42.679293: step 15450, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:25:45.780713: step 15460, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:25:48.868832: step 15470, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:25:51.933249: step 15480, loss = nan (422.4 examples/sec; 0.303 sec/batch)
2017-10-18 00:25:55.030747: step 15490, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:25:58.131963: step 15500, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:26:01.231737: step 15510, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:26:04.326621: step 15520, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:26:07.433257: step 15530, loss = nan (401.3 examples/sec; 0.319 sec/batch)
2017-10-18 00:26:10.514285: step 15540, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:26:13.605403: step 15550, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 00:26:16.693490: step 15560, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:26:19.752295: step 15570, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:26:22.834527: step 15580, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:26:25.923756: step 15590, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:26:28.997570: step 15600, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:26:32.077355: step 15610, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:26:35.168393: step 15620, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:26:38.260467: step 15630, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:26:41.336705: step 15640, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:26:44.587392: step 15650, loss = nan (278.6 examples/sec; 0.459 sec/batch)
2017-10-18 00:26:47.675892: step 15660, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:26:50.772190: step 15670, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:26:53.842713: step 15680, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:26:56.925269: step 15690, loss = nan (422.7 examples/sec; 0.303 sec/batch)
2017-10-18 00:27:00.009331: step 15700, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:27:03.124838: step 15710, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 00:27:06.205941: step 15720, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:27:09.291198: step 15730, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:27:12.385144: step 15740, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 00:27:15.477092: step 15750, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:27:18.565465: step 15760, loss = nan (406.8 examples/sec; 0.315 sec/batch)
2017-10-18 00:27:21.645883: step 15770, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:27:24.731678: step 15780, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:27:27.825862: step 15790, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:27:30.917241: step 15800, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 00:27:34.012608: step 15810, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:27:37.113527: step 15820, loss = nan (404.8 examples/sec; 0.316 sec/batch)
2017-10-18 00:27:40.212596: step 15830, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:27:43.308986: step 15840, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:27:46.385147: step 15850, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:27:49.624249: step 15860, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:27:52.714028: step 15870, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:27:55.793656: step 15880, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:27:58.864810: step 15890, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:28:01.950154: step 15900, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:28:05.036139: step 15910, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:28:08.125783: step 15920, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:28:11.218187: step 15930, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:28:14.324494: step 15940, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:28:17.397573: step 15950, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:28:20.485776: step 15960, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:28:23.593639: step 15970, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:28:26.683474: step 15980, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:28:29.770629: step 15990, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:28:32.854531: step 16000, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:28:35.953036: step 16010, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:28:39.055448: step 16020, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:28:42.149528: step 16030, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:28:45.222475: step 16040, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:28:48.314246: step 16050, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:28:51.543098: step 16060, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:28:54.633454: step 16070, loss = nan (422.5 examples/sec; 0.303 sec/batch)
2017-10-18 00:28:57.719389: step 16080, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:29:00.815466: step 16090, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:29:04.045972: step 16100, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:29:07.135385: step 16110, loss = nan (421.9 examples/sec; 0.303 sec/batch)
2017-10-18 00:29:10.327176: step 16120, loss = nan (309.1 examples/sec; 0.414 sec/batch)
2017-10-18 00:29:13.390521: step 16130, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:29:16.459569: step 16140, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:29:19.547896: step 16150, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:29:22.635027: step 16160, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:29:25.715781: step 16170, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 00:29:28.791726: step 16180, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:29:31.873285: step 16190, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:29:34.958630: step 16200, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:29:38.051483: step 16210, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 00:29:41.128361: step 16220, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:29:44.214423: step 16230, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-18 00:29:47.290299: step 16240, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:29:50.363227: step 16250, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:29:53.468398: step 16260, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:29:56.552561: step 16270, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:29:59.628480: step 16280, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:30:02.728784: step 16290, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:30:05.802045: step 16300, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:30:08.884385: step 16310, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:30:11.950582: step 16320, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 00:30:15.028109: step 16330, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:30:18.115506: step 16340, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:30:21.332059: step 16350, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:30:24.418543: step 16360, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:30:27.499745: step 16370, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:30:30.582566: step 16380, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:30:33.668439: step 16390, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:30:36.742713: step 16400, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:30:39.825223: step 16410, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 00:30:42.897967: step 16420, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:30:45.973289: step 16430, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:30:49.053652: step 16440, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:30:52.122443: step 16450, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:30:55.203863: step 16460, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:30:58.340819: step 16470, loss = nan (359.5 examples/sec; 0.356 sec/batch)
2017-10-18 00:31:01.422517: step 16480, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:31:04.519911: step 16490, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:31:07.621470: step 16500, loss = nan (405.5 examples/sec; 0.316 sec/batch)
2017-10-18 00:31:10.720258: step 16510, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:31:13.805732: step 16520, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:31:16.912269: step 16530, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:31:20.010830: step 16540, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 00:31:23.211294: step 16550, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:31:26.281255: step 16560, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:31:29.375649: step 16570, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:31:32.490228: step 16580, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:31:35.562773: step 16590, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:31:38.652910: step 16600, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:31:41.751336: step 16610, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:31:44.842838: step 16620, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:31:47.936093: step 16630, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:31:51.031547: step 16640, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:31:54.098895: step 16650, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:31:57.177412: step 16660, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:32:00.261474: step 16670, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 00:32:03.366310: step 16680, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:32:06.463843: step 16690, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:09.561836: step 16700, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:32:12.643376: step 16710, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:32:15.748278: step 16720, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 00:32:18.836713: step 16730, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:21.911022: step 16740, loss = nan (403.4 examples/sec; 0.317 sec/batch)
2017-10-18 00:32:24.988030: step 16750, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:28.057616: step 16760, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:31.145534: step 16770, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:32:34.227004: step 16780, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:32:37.320033: step 16790, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:40.399117: step 16800, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:43.481576: step 16810, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:32:46.560798: step 16820, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:32:49.666772: step 16830, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:32:52.758949: step 16840, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:32:55.856390: step 16850, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:32:58.956454: step 16860, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:33:02.059295: step 16870, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:33:05.181353: step 16880, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:33:08.271067: step 16890, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:33:11.350131: step 16900, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:33:14.437757: step 16910, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:33:17.521372: step 16920, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 00:33:20.588187: step 16930, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:33:23.662716: step 16940, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:33:26.757982: step 16950, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:33:29.836158: step 16960, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:33:32.931443: step 16970, loss = nan (416.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:33:36.020640: step 16980, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 00:33:39.115493: step 16990, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:33:42.202285: step 17000, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:33:45.285523: step 17010, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:33:48.364707: step 17020, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:33:51.449730: step 17030, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:33:54.594367: step 17040, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 00:33:57.678286: step 17050, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:34:00.761018: step 17060, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:34:03.850620: step 17070, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:34:07.065070: step 17080, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:34:10.147155: step 17090, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:34:13.245522: step 17100, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:34:16.330069: step 17110, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 00:34:19.396062: step 17120, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:34:22.480110: step 17130, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 00:34:25.677989: step 17140, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 00:34:28.754201: step 17150, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:34:31.833132: step 17160, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:34:34.935982: step 17170, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 00:34:38.034154: step 17180, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:34:41.115067: step 17190, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:34:44.311902: step 17200, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 00:34:47.378991: step 17210, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:34:50.473697: step 17220, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:34:53.562442: step 17230, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:34:56.642211: step 17240, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:34:59.720770: step 17250, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:35:02.815576: step 17260, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:35:06.023481: step 17270, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-18 00:35:09.106374: step 17280, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:35:12.179147: step 17290, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:35:15.256202: step 17300, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:35:18.345376: step 17310, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-18 00:35:21.426824: step 17320, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:35:24.515139: step 17330, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:35:27.584253: step 17340, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:35:30.688629: step 17350, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:35:33.797158: step 17360, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:35:36.887788: step 17370, loss = nan (403.9 examples/sec; 0.317 sec/batch)
2017-10-18 00:35:39.973293: step 17380, loss = nan (408.3 examples/sec; 0.314 sec/batch)
2017-10-18 00:35:43.069746: step 17390, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:35:46.138990: step 17400, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:35:49.230520: step 17410, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:35:52.309391: step 17420, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:35:55.384216: step 17430, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 00:35:58.468341: step 17440, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:36:01.551088: step 17450, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:36:04.652716: step 17460, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:36:07.745687: step 17470, loss = nan (406.3 examples/sec; 0.315 sec/batch)
2017-10-18 00:36:10.831051: step 17480, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:36:13.913982: step 17490, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:36:17.004687: step 17500, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:36:20.079537: step 17510, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:36:23.158547: step 17520, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:36:26.242964: step 17530, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:36:29.314673: step 17540, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:36:32.399953: step 17550, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:36:35.511168: step 17560, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 00:36:38.583210: step 17570, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:36:41.674906: step 17580, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:36:44.755133: step 17590, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:36:47.838623: step 17600, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:36:50.911152: step 17610, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:36:53.995590: step 17620, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:36:57.068812: step 17630, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:37:00.162904: step 17640, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:37:03.253416: step 17650, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 00:37:06.347745: step 17660, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:37:09.448985: step 17670, loss = nan (405.4 examples/sec; 0.316 sec/batch)
2017-10-18 00:37:12.516606: step 17680, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:37:15.607992: step 17690, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:37:18.708767: step 17700, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:37:21.808519: step 17710, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:37:24.892201: step 17720, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:37:27.964251: step 17730, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:37:31.053932: step 17740, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:37:34.146972: step 17750, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:37:37.240494: step 17760, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:37:40.320927: step 17770, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:37:43.405859: step 17780, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:37:46.513774: step 17790, loss = nan (404.1 examples/sec; 0.317 sec/batch)
2017-10-18 00:37:49.617095: step 17800, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 00:37:52.716798: step 17810, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:37:55.785691: step 17820, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:37:58.891645: step 17830, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:38:02.008185: step 17840, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:38:05.106910: step 17850, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:38:08.180296: step 17860, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:38:11.260537: step 17870, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:38:14.355710: step 17880, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:38:17.466386: step 17890, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:38:20.546559: step 17900, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:38:23.636405: step 17910, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:38:26.712556: step 17920, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:38:29.791176: step 17930, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:38:32.869122: step 17940, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-18 00:38:35.961121: step 17950, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:38:39.064586: step 17960, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:38:42.154858: step 17970, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:38:45.253493: step 17980, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:38:48.334696: step 17990, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 00:38:51.427251: step 18000, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:38:54.494909: step 18010, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:38:57.570471: step 18020, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:39:00.651826: step 18030, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:39:03.736800: step 18040, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 00:39:06.832813: step 18050, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:39:10.016441: step 18060, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:39:13.102732: step 18070, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:39:16.174602: step 18080, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 00:39:19.247595: step 18090, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:39:22.350334: step 18100, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:39:25.430055: step 18110, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:39:28.537467: step 18120, loss = nan (403.3 examples/sec; 0.317 sec/batch)
2017-10-18 00:39:31.626475: step 18130, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:39:34.710554: step 18140, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 00:39:37.773086: step 18150, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:39:40.853536: step 18160, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:39:43.951236: step 18170, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:39:47.030365: step 18180, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:39:50.095353: step 18190, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:39:53.181343: step 18200, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:39:56.267246: step 18210, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:39:59.366065: step 18220, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:40:02.471560: step 18230, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:40:05.549694: step 18240, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:40:08.632868: step 18250, loss = nan (422.5 examples/sec; 0.303 sec/batch)
2017-10-18 00:40:11.733027: step 18260, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:40:14.820814: step 18270, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:40:17.908746: step 18280, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:40:20.991432: step 18290, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:40:24.060245: step 18300, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:40:27.144158: step 18310, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:40:30.221496: step 18320, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:40:33.309938: step 18330, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:40:36.390800: step 18340, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:40:39.481634: step 18350, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:40:42.580067: step 18360, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:40:45.761558: step 18370, loss = nan (306.3 examples/sec; 0.418 sec/batch)
2017-10-18 00:40:48.832016: step 18380, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:40:51.915986: step 18390, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:40:54.991862: step 18400, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:40:58.219893: step 18410, loss = nan (384.1 examples/sec; 0.333 sec/batch)
2017-10-18 00:41:01.304643: step 18420, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:41:04.378049: step 18430, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:41:07.492878: step 18440, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:41:10.568528: step 18450, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:41:13.642784: step 18460, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:41:16.737938: step 18470, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:41:19.816221: step 18480, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:41:22.893616: step 18490, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:41:26.003370: step 18500, loss = nan (392.8 examples/sec; 0.326 sec/batch)
2017-10-18 00:41:29.084070: step 18510, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:41:32.161320: step 18520, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:41:35.243054: step 18530, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:41:38.308235: step 18540, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:41:41.403275: step 18550, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:41:44.472838: step 18560, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:41:47.563796: step 18570, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:41:50.630055: step 18580, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:41:53.718361: step 18590, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:41:56.812797: step 18600, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:41:59.888053: step 18610, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:42:02.985809: step 18620, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:42:06.083632: step 18630, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-18 00:42:09.184703: step 18640, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:42:12.292869: step 18650, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:42:15.384646: step 18660, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:42:18.475878: step 18670, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:42:21.561191: step 18680, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:42:24.660192: step 18690, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:42:27.755116: step 18700, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:42:30.851810: step 18710, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:42:33.955489: step 18720, loss = nan (405.7 examples/sec; 0.316 sec/batch)
2017-10-18 00:42:37.038621: step 18730, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:42:40.115629: step 18740, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:42:43.226472: step 18750, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:42:46.320706: step 18760, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:42:49.408869: step 18770, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:42:52.506038: step 18780, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:42:55.610162: step 18790, loss = nan (399.1 examples/sec; 0.321 sec/batch)
2017-10-18 00:42:58.685691: step 18800, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:43:01.780657: step 18810, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:43:04.897478: step 18820, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:43:07.982969: step 18830, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:43:11.066132: step 18840, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:43:14.187384: step 18850, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:43:17.263871: step 18860, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:43:20.354975: step 18870, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:43:23.451892: step 18880, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:43:26.584542: step 18890, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:43:29.685468: step 18900, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:43:32.777885: step 18910, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:43:35.852191: step 18920, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:43:38.939423: step 18930, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:43:42.155847: step 18940, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:43:45.255043: step 18950, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 00:43:48.353569: step 18960, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:43:51.425883: step 18970, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:43:54.508787: step 18980, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:43:57.615296: step 18990, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:44:00.711148: step 19000, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:03.821313: step 19010, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:44:06.915475: step 19020, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:10.095465: step 19030, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:13.281675: step 19040, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:44:16.487280: step 19050, loss = nan (306.4 examples/sec; 0.418 sec/batch)
2017-10-18 00:44:19.568656: step 19060, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:22.650021: step 19070, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:25.741244: step 19080, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:44:28.824762: step 19090, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:44:32.008013: step 19100, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:44:35.090343: step 19110, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 00:44:38.189401: step 19120, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 00:44:41.259571: step 19130, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 00:44:44.342269: step 19140, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:44:47.420590: step 19150, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:44:50.513185: step 19160, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:44:53.598168: step 19170, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:44:56.690028: step 19180, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 00:44:59.763249: step 19190, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:45:02.850362: step 19200, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:45:05.928961: step 19210, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:45:09.016713: step 19220, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:45:12.107355: step 19230, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:45:15.191238: step 19240, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:45:18.387030: step 19250, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:45:21.473744: step 19260, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 00:45:24.566307: step 19270, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:45:27.652729: step 19280, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:45:30.747530: step 19290, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:45:33.835254: step 19300, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:45:36.909404: step 19310, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:45:40.007519: step 19320, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:45:43.101505: step 19330, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 00:45:46.186123: step 19340, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:45:49.272762: step 19350, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:45:52.358044: step 19360, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:45:55.430747: step 19370, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:45:58.492758: step 19380, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:46:01.584127: step 19390, loss = nan (406.1 examples/sec; 0.315 sec/batch)
2017-10-18 00:46:04.701010: step 19400, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:46:07.775540: step 19410, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:10.864410: step 19420, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:46:13.962877: step 19430, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:17.047273: step 19440, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:46:20.138972: step 19450, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:23.216194: step 19460, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:46:26.308353: step 19470, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:46:29.402657: step 19480, loss = nan (403.7 examples/sec; 0.317 sec/batch)
2017-10-18 00:46:32.489264: step 19490, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:35.585724: step 19500, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:46:38.683371: step 19510, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:46:41.767535: step 19520, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:46:44.860527: step 19530, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:47.943992: step 19540, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:51.035095: step 19550, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:46:54.137973: step 19560, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 00:46:57.238032: step 19570, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:47:00.384262: step 19580, loss = nan (381.7 examples/sec; 0.335 sec/batch)
2017-10-18 00:47:03.481421: step 19590, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 00:47:06.599010: step 19600, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 00:47:09.698585: step 19610, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:47:12.849477: step 19620, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:47:15.947984: step 19630, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:47:19.073269: step 19640, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:47:22.186464: step 19650, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:47:25.289227: step 19660, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:47:28.374993: step 19670, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:47:31.481558: step 19680, loss = nan (406.7 examples/sec; 0.315 sec/batch)
2017-10-18 00:47:34.563302: step 19690, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:47:37.641995: step 19700, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:47:40.716591: step 19710, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 00:47:43.795808: step 19720, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:47:46.905548: step 19730, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:47:50.003538: step 19740, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:47:53.108999: step 19750, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:47:56.191205: step 19760, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:47:59.378768: step 19770, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:48:02.496162: step 19780, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:48:05.570860: step 19790, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:48:08.657450: step 19800, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 00:48:11.746369: step 19810, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 00:48:14.859294: step 19820, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 00:48:17.958310: step 19830, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:48:21.025096: step 19840, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:48:24.110783: step 19850, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:48:27.190614: step 19860, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:48:30.285515: step 19870, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 00:48:33.366150: step 19880, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 00:48:36.444204: step 19890, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:48:39.538880: step 19900, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:48:42.619793: step 19910, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:48:45.715020: step 19920, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:48:48.808630: step 19930, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 00:48:51.900806: step 19940, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:48:54.978758: step 19950, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:48:58.082304: step 19960, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:49:01.161555: step 19970, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:49:04.249170: step 19980, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:49:07.343791: step 19990, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:49:10.430928: step 20000, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:49:13.511810: step 20010, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:49:16.613161: step 20020, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:49:19.688774: step 20030, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:49:22.775872: step 20040, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:49:25.866998: step 20050, loss = nan (408.3 examples/sec; 0.313 sec/batch)
2017-10-18 00:49:28.950446: step 20060, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:49:32.044373: step 20070, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:49:35.125770: step 20080, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:49:38.195073: step 20090, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:49:41.274983: step 20100, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:49:44.364437: step 20110, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 00:49:47.463097: step 20120, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:49:50.552751: step 20130, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:49:53.637845: step 20140, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-18 00:49:56.722710: step 20150, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 00:49:59.796347: step 20160, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:50:02.864873: step 20170, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 00:50:05.946479: step 20180, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:50:09.154315: step 20190, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:50:12.243718: step 20200, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:50:15.327890: step 20210, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 00:50:18.411365: step 20220, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:50:21.498141: step 20230, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:50:24.586637: step 20240, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:50:27.690243: step 20250, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 00:50:30.779583: step 20260, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 00:50:33.856063: step 20270, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:50:36.963925: step 20280, loss = nan (404.6 examples/sec; 0.316 sec/batch)
2017-10-18 00:50:40.064435: step 20290, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 00:50:43.166289: step 20300, loss = nan (406.3 examples/sec; 0.315 sec/batch)
2017-10-18 00:50:46.246995: step 20310, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 00:50:49.347136: step 20320, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:50:52.440404: step 20330, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 00:50:55.535112: step 20340, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-18 00:50:58.612160: step 20350, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:01.707944: step 20360, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:04.786691: step 20370, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:51:07.873528: step 20380, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:10.957250: step 20390, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:14.214775: step 20400, loss = nan (278.9 examples/sec; 0.459 sec/batch)
2017-10-18 00:51:17.305055: step 20410, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:20.389776: step 20420, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:51:23.457618: step 20430, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:51:26.549734: step 20440, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 00:51:29.633101: step 20450, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:51:32.710028: step 20460, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:51:35.792297: step 20470, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:51:38.869614: step 20480, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:51:41.957750: step 20490, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:51:45.043105: step 20500, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:51:48.124213: step 20510, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 00:51:51.216959: step 20520, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:51:54.307664: step 20530, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:51:57.410314: step 20540, loss = nan (396.8 examples/sec; 0.323 sec/batch)
2017-10-18 00:52:00.483186: step 20550, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:03.596378: step 20560, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:52:06.712645: step 20570, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:52:09.807985: step 20580, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:52:12.885155: step 20590, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:15.966782: step 20600, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:52:19.045939: step 20610, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:52:22.286322: step 20620, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:52:25.365617: step 20630, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:28.442338: step 20640, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:52:31.526933: step 20650, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 00:52:34.610721: step 20660, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:37.699284: step 20670, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:52:40.806431: step 20680, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 00:52:43.897359: step 20690, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:52:46.986109: step 20700, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:50.069517: step 20710, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:52:53.252335: step 20720, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:52:56.323419: step 20730, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 00:52:59.411957: step 20740, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:53:02.522735: step 20750, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:53:05.602022: step 20760, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:53:08.693814: step 20770, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:53:11.783935: step 20780, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:53:14.898195: step 20790, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:53:17.985776: step 20800, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:53:21.196514: step 20810, loss = nan (300.3 examples/sec; 0.426 sec/batch)
2017-10-18 00:53:24.293545: step 20820, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 00:53:27.376293: step 20830, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:53:30.463354: step 20840, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 00:53:33.661713: step 20850, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 00:53:36.749334: step 20860, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 00:53:39.827703: step 20870, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:53:42.917383: step 20880, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:53:46.019420: step 20890, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 00:53:49.119582: step 20900, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 00:53:52.204411: step 20910, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 00:53:55.287770: step 20920, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 00:53:58.369334: step 20930, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:54:01.434240: step 20940, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:54:04.514086: step 20950, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:54:07.596356: step 20960, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:54:10.693208: step 20970, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:54:13.780390: step 20980, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:54:16.868397: step 20990, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:54:19.990292: step 21000, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 00:54:23.060870: step 21010, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:54:26.147489: step 21020, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 00:54:29.253276: step 21030, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:54:32.316126: step 21040, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:54:35.399854: step 21050, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:54:38.502656: step 21060, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 00:54:41.576025: step 21070, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:54:44.671225: step 21080, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:54:47.774686: step 21090, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:54:50.868920: step 21100, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 00:54:53.952069: step 21110, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:54:57.037183: step 21120, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:55:00.131986: step 21130, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:55:03.220340: step 21140, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:55:06.315329: step 21150, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:55:09.769516: step 21160, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 00:55:12.922666: step 21170, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:55:16.020668: step 21180, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 00:55:19.115072: step 21190, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:55:22.186804: step 21200, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 00:55:25.296030: step 21210, loss = nan (393.7 examples/sec; 0.325 sec/batch)
2017-10-18 00:55:28.487874: step 21220, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 00:55:31.571116: step 21230, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 00:55:34.662197: step 21240, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 00:55:37.757904: step 21250, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:55:40.837708: step 21260, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:55:43.902775: step 21270, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:55:47.002807: step 21280, loss = nan (405.7 examples/sec; 0.315 sec/batch)
2017-10-18 00:55:50.095213: step 21290, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 00:55:53.303968: step 21300, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 00:55:56.378288: step 21310, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:55:59.470305: step 21320, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:56:02.561320: step 21330, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:56:05.649438: step 21340, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 00:56:08.724853: step 21350, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:56:11.804800: step 21360, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 00:56:14.909286: step 21370, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:56:18.091306: step 21380, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:56:21.165955: step 21390, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:56:24.238726: step 21400, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 00:56:27.319934: step 21410, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 00:56:30.395629: step 21420, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:56:33.491112: step 21430, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:56:36.562852: step 21440, loss = nan (421.1 examples/sec; 0.304 sec/batch)
2017-10-18 00:56:39.633902: step 21450, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 00:56:42.716367: step 21460, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:56:45.795192: step 21470, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 00:56:48.874731: step 21480, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:56:51.945114: step 21490, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 00:56:55.025888: step 21500, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:56:58.105152: step 21510, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 00:57:01.181629: step 21520, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 00:57:04.276700: step 21530, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 00:57:07.377059: step 21540, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 00:57:10.465464: step 21550, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 00:57:13.772220: step 21560, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 00:57:16.852141: step 21570, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:57:19.936615: step 21580, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 00:57:23.010346: step 21590, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:57:26.098136: step 21600, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 00:57:29.185933: step 21610, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 00:57:32.261364: step 21620, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 00:57:35.367193: step 21630, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 00:57:38.432143: step 21640, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 00:57:41.519404: step 21650, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 00:57:44.598045: step 21660, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 00:57:47.683864: step 21670, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 00:57:50.776284: step 21680, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 00:57:53.864154: step 21690, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 00:57:56.949147: step 21700, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 00:58:00.029002: step 21710, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 00:58:03.116352: step 21720, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 00:58:06.200247: step 21730, loss = nan (422.1 examples/sec; 0.303 sec/batch)
2017-10-18 00:58:09.399029: step 21740, loss = nan (303.9 examples/sec; 0.421 sec/batch)
2017-10-18 00:58:12.495487: step 21750, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 00:58:15.600886: step 21760, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 00:58:18.684794: step 21770, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 00:58:21.808971: step 21780, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 00:58:24.902026: step 21790, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 00:58:27.974663: step 21800, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 00:58:31.065611: step 21810, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 00:58:34.157961: step 21820, loss = nan (405.5 examples/sec; 0.316 sec/batch)
2017-10-18 00:58:37.239510: step 21830, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 00:58:40.386582: step 21840, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-18 00:58:43.460872: step 21850, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 00:58:46.646097: step 21860, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 00:58:49.717654: step 21870, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 00:58:52.782361: step 21880, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 00:58:55.972312: step 21890, loss = nan (308.4 examples/sec; 0.415 sec/batch)
2017-10-18 00:58:59.045074: step 21900, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:59:02.168490: step 21910, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 00:59:05.268778: step 21920, loss = nan (390.8 examples/sec; 0.328 sec/batch)
2017-10-18 00:59:08.333652: step 21930, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 00:59:11.412264: step 21940, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:59:14.487833: step 21950, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 00:59:17.568520: step 21960, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 00:59:20.643408: step 21970, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 00:59:23.723201: step 21980, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 00:59:26.804649: step 21990, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 00:59:29.876687: step 22000, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 00:59:32.966528: step 22010, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 00:59:36.043634: step 22020, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 00:59:39.134604: step 22030, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 00:59:42.226205: step 22040, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 00:59:45.306733: step 22050, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 00:59:48.403155: step 22060, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 00:59:51.490977: step 22070, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 00:59:54.579963: step 22080, loss = nan (400.7 examples/sec; 0.319 sec/batch)
2017-10-18 00:59:57.654129: step 22090, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:00:00.739079: step 22100, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:00:03.818629: step 22110, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:00:06.905836: step 22120, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:00:09.991761: step 22130, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:00:13.093951: step 22140, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:00:16.181385: step 22150, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:00:19.265733: step 22160, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:00:22.352222: step 22170, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:00:25.435663: step 22180, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:00:28.640872: step 22190, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:00:31.840307: step 22200, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:00:34.912157: step 22210, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:00:37.989616: step 22220, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:00:41.076011: step 22230, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:00:44.165276: step 22240, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:00:47.248164: step 22250, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:00:50.346266: step 22260, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:00:53.423610: step 22270, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:00:56.487819: step 22280, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:00:59.587645: step 22290, loss = nan (404.9 examples/sec; 0.316 sec/batch)
2017-10-18 01:01:02.674098: step 22300, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 01:01:05.779584: step 22310, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:01:08.860539: step 22320, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:01:11.939551: step 22330, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:01:15.031860: step 22340, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 01:01:18.110626: step 22350, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:01:21.204088: step 22360, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 01:01:24.288032: step 22370, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:01:27.392775: step 22380, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:01:30.472681: step 22390, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:01:33.573692: step 22400, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:01:36.652669: step 22410, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:01:39.734874: step 22420, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:01:42.824029: step 22430, loss = nan (400.0 examples/sec; 0.320 sec/batch)
2017-10-18 01:01:45.905804: step 22440, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:01:49.001584: step 22450, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:01:52.089172: step 22460, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:01:55.179691: step 22470, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:01:58.261333: step 22480, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:02:01.555669: step 22490, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:02:04.638423: step 22500, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:02:07.712246: step 22510, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:10.794591: step 22520, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:02:13.886501: step 22530, loss = nan (416.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:02:16.961556: step 22540, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:02:20.068158: step 22550, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:23.145154: step 22560, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:02:26.237094: step 22570, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:02:29.359157: step 22580, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:32.465554: step 22590, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:35.534556: step 22600, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 01:02:38.622202: step 22610, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:02:41.703157: step 22620, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:44.792393: step 22630, loss = nan (423.8 examples/sec; 0.302 sec/batch)
2017-10-18 01:02:47.863313: step 22640, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:02:50.937844: step 22650, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:02:54.044002: step 22660, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:02:57.106368: step 22670, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:03:00.193553: step 22680, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:03:03.289671: step 22690, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:03:06.511169: step 22700, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:03:09.605974: step 22710, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:03:12.686333: step 22720, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:03:15.791257: step 22730, loss = nan (402.3 examples/sec; 0.318 sec/batch)
2017-10-18 01:03:18.865770: step 22740, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:03:21.935112: step 22750, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:03:25.003627: step 22760, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 01:03:28.119760: step 22770, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:03:31.213902: step 22780, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 01:03:34.304147: step 22790, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:03:37.384909: step 22800, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:03:40.464165: step 22810, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:03:43.546343: step 22820, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:03:46.619860: step 22830, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:03:49.692462: step 22840, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:03:52.791626: step 22850, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:03:55.879442: step 22860, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:03:58.951358: step 22870, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 01:04:02.061159: step 22880, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:04:05.145083: step 22890, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:04:08.222763: step 22900, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:04:11.296430: step 22910, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:04:14.377761: step 22920, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:04:17.460800: step 22930, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:04:20.543642: step 22940, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:04:23.617030: step 22950, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:04:26.695813: step 22960, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:04:29.767756: step 22970, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:04:32.851314: step 22980, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:04:35.929181: step 22990, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:04:39.029442: step 23000, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:04:42.119965: step 23010, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:04:45.199092: step 23020, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 01:04:48.281153: step 23030, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:04:51.365019: step 23040, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:04:54.465242: step 23050, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:04:57.598047: step 23060, loss = nan (423.2 examples/sec; 0.302 sec/batch)
2017-10-18 01:05:00.684759: step 23070, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 01:05:03.761857: step 23080, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:05:06.884457: step 23090, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 01:05:10.073217: step 23100, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:05:13.194813: step 23110, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:05:16.278190: step 23120, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:05:19.366784: step 23130, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:05:22.484416: step 23140, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:05:25.575687: step 23150, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 01:05:28.652496: step 23160, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:05:31.723947: step 23170, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:05:34.811596: step 23180, loss = nan (422.7 examples/sec; 0.303 sec/batch)
2017-10-18 01:05:37.886682: step 23190, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:05:40.970947: step 23200, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 01:05:44.047386: step 23210, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:05:47.126840: step 23220, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:05:50.210947: step 23230, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:05:53.298382: step 23240, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:05:56.381942: step 23250, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:05:59.461853: step 23260, loss = nan (405.5 examples/sec; 0.316 sec/batch)
2017-10-18 01:06:02.536987: step 23270, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:06:05.612400: step 23280, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:06:08.702631: step 23290, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:06:11.808999: step 23300, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:06:14.908739: step 23310, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:06:17.996282: step 23320, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:06:21.215734: step 23330, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:06:24.302040: step 23340, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:06:27.374271: step 23350, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:06:30.486464: step 23360, loss = nan (402.0 examples/sec; 0.318 sec/batch)
2017-10-18 01:06:33.559098: step 23370, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:06:36.639890: step 23380, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:06:39.710627: step 23390, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:06:42.802076: step 23400, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:06:45.888772: step 23410, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:06:49.007988: step 23420, loss = nan (400.7 examples/sec; 0.319 sec/batch)
2017-10-18 01:06:52.089829: step 23430, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 01:06:55.170271: step 23440, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:06:58.271379: step 23450, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:07:01.380435: step 23460, loss = nan (397.0 examples/sec; 0.322 sec/batch)
2017-10-18 01:07:04.469498: step 23470, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:07:07.551159: step 23480, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:07:10.676507: step 23490, loss = nan (402.2 examples/sec; 0.318 sec/batch)
2017-10-18 01:07:13.745065: step 23500, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:07:16.830084: step 23510, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:07:19.907377: step 23520, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:07:23.000751: step 23530, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:07:26.089064: step 23540, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:07:29.156711: step 23550, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:07:32.237878: step 23560, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:07:35.327100: step 23570, loss = nan (401.3 examples/sec; 0.319 sec/batch)
2017-10-18 01:07:38.403203: step 23580, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:07:41.523636: step 23590, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:07:44.614292: step 23600, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:07:47.702627: step 23610, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:07:50.792064: step 23620, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:07:53.892725: step 23630, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:07:56.987995: step 23640, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:08:00.077141: step 23650, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 01:08:03.153927: step 23660, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:08:06.234841: step 23670, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:08:09.328385: step 23680, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:08:12.417067: step 23690, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:08:15.506518: step 23700, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:08:18.602735: step 23710, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:08:21.698151: step 23720, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:08:24.778287: step 23730, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 01:08:27.851374: step 23740, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:08:30.927546: step 23750, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 01:08:34.015125: step 23760, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:08:37.094038: step 23770, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:08:40.171557: step 23780, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:08:43.261908: step 23790, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:08:46.339994: step 23800, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:08:49.414830: step 23810, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:08:52.487456: step 23820, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 01:08:55.592621: step 23830, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 01:08:58.696631: step 23840, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:09:01.799787: step 23850, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:09:04.886395: step 23860, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:09:07.982777: step 23870, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:09:11.062499: step 23880, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:09:14.142862: step 23890, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:09:17.236935: step 23900, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:09:20.323670: step 23910, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:09:23.401155: step 23920, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:09:26.481082: step 23930, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:09:29.569693: step 23940, loss = nan (395.8 examples/sec; 0.323 sec/batch)
2017-10-18 01:09:32.655695: step 23950, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 01:09:35.733980: step 23960, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:09:38.927884: step 23970, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:09:42.005553: step 23980, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:09:45.091066: step 23990, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:09:48.161488: step 24000, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-18 01:09:51.239402: step 24010, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:09:54.313346: step 24020, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:09:57.406143: step 24030, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:10:00.521464: step 24040, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:10:03.612933: step 24050, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:10:06.702881: step 24060, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:10:09.805938: step 24070, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:10:12.890571: step 24080, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:10:16.021670: step 24090, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:10:19.119529: step 24100, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 01:10:22.197338: step 24110, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:10:25.279814: step 24120, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:10:28.346412: step 24130, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:10:31.450300: step 24140, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:10:34.555364: step 24150, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:10:37.639856: step 24160, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:10:40.710499: step 24170, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:10:43.805154: step 24180, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:10:46.881049: step 24190, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:10:49.964826: step 24200, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:10:53.079596: step 24210, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 01:10:56.169931: step 24220, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:10:59.318794: step 24230, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:11:02.415597: step 24240, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:11:05.499635: step 24250, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:11:08.586379: step 24260, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:11:11.667385: step 24270, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:11:14.750535: step 24280, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:11:17.822350: step 24290, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:11:20.922664: step 24300, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:11:24.021095: step 24310, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:11:27.237966: step 24320, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:11:30.312788: step 24330, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:11:33.400580: step 24340, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:11:36.489052: step 24350, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:11:39.579112: step 24360, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:11:42.658966: step 24370, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:11:45.740713: step 24380, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:11:48.823920: step 24390, loss = nan (396.8 examples/sec; 0.323 sec/batch)
2017-10-18 01:11:51.911712: step 24400, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:11:54.995412: step 24410, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:11:58.295710: step 24420, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 01:12:01.393100: step 24430, loss = nan (407.2 examples/sec; 0.314 sec/batch)
2017-10-18 01:12:04.480317: step 24440, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:12:07.572550: step 24450, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:12:10.661744: step 24460, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:12:13.747643: step 24470, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:12:16.849098: step 24480, loss = nan (404.1 examples/sec; 0.317 sec/batch)
2017-10-18 01:12:19.925095: step 24490, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:12:23.007398: step 24500, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 01:12:26.192520: step 24510, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:12:29.272718: step 24520, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:12:32.363230: step 24530, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:12:35.439944: step 24540, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:12:38.519568: step 24550, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:12:41.598195: step 24560, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:12:44.677375: step 24570, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:12:47.761627: step 24580, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:12:50.938519: step 24590, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:12:54.019714: step 24600, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:12:57.107608: step 24610, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:13:00.182144: step 24620, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:13:03.268512: step 24630, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:13:06.348622: step 24640, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:13:09.432202: step 24650, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:12.518315: step 24660, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:15.622631: step 24670, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:13:18.699842: step 24680, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:13:21.799169: step 24690, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:13:24.887032: step 24700, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:13:27.976520: step 24710, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:31.064645: step 24720, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:13:34.140909: step 24730, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:13:37.215668: step 24740, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:13:40.297074: step 24750, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:13:43.392804: step 24760, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:13:46.463649: step 24770, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:13:49.551413: step 24780, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:52.645100: step 24790, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:55.722072: step 24800, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:13:58.796422: step 24810, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:14:01.895652: step 24820, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:14:04.966685: step 24830, loss = nan (423.0 examples/sec; 0.303 sec/batch)
2017-10-18 01:14:08.037459: step 24840, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:14:11.116355: step 24850, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:14:14.195642: step 24860, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:14:17.292701: step 24870, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:14:20.365748: step 24880, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:14:23.442903: step 24890, loss = nan (405.2 examples/sec; 0.316 sec/batch)
2017-10-18 01:14:26.523341: step 24900, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 01:14:29.597503: step 24910, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:14:32.681144: step 24920, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:14:35.763665: step 24930, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 01:14:38.859823: step 24940, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:14:41.938916: step 24950, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:14:45.021608: step 24960, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:14:48.093618: step 24970, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:14:51.183673: step 24980, loss = nan (401.6 examples/sec; 0.319 sec/batch)
2017-10-18 01:14:54.372366: step 24990, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:14:57.446640: step 25000, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:15:00.524885: step 25010, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:15:03.617907: step 25020, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:15:06.707876: step 25030, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:15:09.785338: step 25040, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:15:12.860011: step 25050, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:15:15.946961: step 25060, loss = nan (403.1 examples/sec; 0.318 sec/batch)
2017-10-18 01:15:19.019150: step 25070, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:15:22.096014: step 25080, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:15:25.169831: step 25090, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:15:28.238336: step 25100, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:15:31.324472: step 25110, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:15:34.412614: step 25120, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:15:37.497484: step 25130, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:15:40.559388: step 25140, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:15:43.637501: step 25150, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:15:46.711135: step 25160, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:15:49.795271: step 25170, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:15:52.880644: step 25180, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:15:55.973253: step 25190, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:15:59.059326: step 25200, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:16:02.142692: step 25210, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:16:05.239097: step 25220, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 01:16:08.316842: step 25230, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:11.405540: step 25240, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:14.514370: step 25250, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:17.591217: step 25260, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:16:20.675297: step 25270, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:16:23.758269: step 25280, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:26.840202: step 25290, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 01:16:29.920076: step 25300, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:33.008173: step 25310, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:36.148996: step 25320, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:16:39.234017: step 25330, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 01:16:42.330096: step 25340, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:45.411167: step 25350, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:16:48.488267: step 25360, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:16:51.594727: step 25370, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:16:54.690286: step 25380, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:16:57.774301: step 25390, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:17:00.846334: step 25400, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:17:03.960025: step 25410, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:17:07.033368: step 25420, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:17:10.120691: step 25430, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:17:13.207381: step 25440, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:17:16.285854: step 25450, loss = nan (406.2 examples/sec; 0.315 sec/batch)
2017-10-18 01:17:19.375256: step 25460, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:17:22.458399: step 25470, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:17:25.541290: step 25480, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:17:28.632597: step 25490, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:17:31.711466: step 25500, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:17:34.793892: step 25510, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:17:37.892558: step 25520, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:17:40.969366: step 25530, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:17:44.049526: step 25540, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:17:47.117621: step 25550, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:17:50.193544: step 25560, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:17:53.254894: step 25570, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:17:56.342118: step 25580, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:17:59.536504: step 25590, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:18:02.627108: step 25600, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:18:05.719378: step 25610, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:18:08.924336: step 25620, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:18:12.031550: step 25630, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:18:15.108535: step 25640, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:18:18.290795: step 25650, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 01:18:21.361062: step 25660, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:18:24.437324: step 25670, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:18:27.633565: step 25680, loss = nan (304.8 examples/sec; 0.420 sec/batch)
2017-10-18 01:18:30.717682: step 25690, loss = nan (403.2 examples/sec; 0.317 sec/batch)
2017-10-18 01:18:33.797388: step 25700, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:18:36.990923: step 25710, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:18:40.072744: step 25720, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 01:18:43.161344: step 25730, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:18:46.250078: step 25740, loss = nan (403.1 examples/sec; 0.318 sec/batch)
2017-10-18 01:18:49.326742: step 25750, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:18:52.404051: step 25760, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:18:55.497242: step 25770, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:18:58.564668: step 25780, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 01:19:01.657324: step 25790, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:19:04.726409: step 25800, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:19:07.819608: step 25810, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:19:10.897372: step 25820, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:19:13.980676: step 25830, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:19:17.054452: step 25840, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 01:19:20.138894: step 25850, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 01:19:23.217561: step 25860, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:19:26.287874: step 25870, loss = nan (422.1 examples/sec; 0.303 sec/batch)
2017-10-18 01:19:29.366291: step 25880, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:19:32.447963: step 25890, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:19:35.528905: step 25900, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:19:38.613565: step 25910, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:19:41.923381: step 25920, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 01:19:45.015855: step 25930, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:19:48.107414: step 25940, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 01:19:51.190816: step 25950, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:19:54.286757: step 25960, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:19:57.357546: step 25970, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:20:00.433167: step 25980, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:20:03.521297: step 25990, loss = nan (404.6 examples/sec; 0.316 sec/batch)
2017-10-18 01:20:06.620533: step 26000, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:20:09.695445: step 26010, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:20:12.796310: step 26020, loss = nan (393.1 examples/sec; 0.326 sec/batch)
2017-10-18 01:20:15.905602: step 26030, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:20:18.981956: step 26040, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:20:22.067920: step 26050, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:20:25.161945: step 26060, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:20:28.272406: step 26070, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:20:31.358944: step 26080, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:20:34.429241: step 26090, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:20:37.507702: step 26100, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:20:40.604951: step 26110, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:20:43.689658: step 26120, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:20:46.889315: step 26130, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:20:49.970530: step 26140, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-18 01:20:53.065200: step 26150, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:20:56.156453: step 26160, loss = nan (393.2 examples/sec; 0.326 sec/batch)
2017-10-18 01:20:59.239295: step 26170, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 01:21:02.336451: step 26180, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:21:05.416101: step 26190, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:21:08.516221: step 26200, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:21:11.589602: step 26210, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:21:14.668710: step 26220, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:21:17.766824: step 26230, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:21:20.831782: step 26240, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:21:23.915952: step 26250, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:21:26.985216: step 26260, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:21:30.093474: step 26270, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:21:33.170660: step 26280, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:21:36.250995: step 26290, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:21:39.325182: step 26300, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 01:21:42.412103: step 26310, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:21:45.504493: step 26320, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:21:48.575404: step 26330, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:21:51.650518: step 26340, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:21:54.735010: step 26350, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:21:57.825378: step 26360, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:22:00.921591: step 26370, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:22:04.002547: step 26380, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:22:07.113751: step 26390, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:22:10.201686: step 26400, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:22:13.278491: step 26410, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:22:16.378045: step 26420, loss = nan (406.6 examples/sec; 0.315 sec/batch)
2017-10-18 01:22:19.472092: step 26430, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:22:22.563800: step 26440, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:22:25.631770: step 26450, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:22:28.709713: step 26460, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:22:31.788549: step 26470, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:22:34.851139: step 26480, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:22:37.928710: step 26490, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:22:41.020795: step 26500, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:22:44.090952: step 26510, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:22:47.180151: step 26520, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:22:50.258922: step 26530, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 01:22:53.345135: step 26540, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:22:56.407116: step 26550, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:22:59.532735: step 26560, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-18 01:23:02.633876: step 26570, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:23:05.711295: step 26580, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:23:08.816623: step 26590, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 01:23:11.901170: step 26600, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-18 01:23:14.969351: step 26610, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:23:18.072588: step 26620, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:23:21.156767: step 26630, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:23:24.255618: step 26640, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:23:27.341674: step 26650, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:23:30.408803: step 26660, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:23:33.497640: step 26670, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:23:36.575250: step 26680, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:23:39.646059: step 26690, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:23:42.729026: step 26700, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:23:45.802062: step 26710, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:23:48.893875: step 26720, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 01:23:51.984780: step 26730, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:23:55.056648: step 26740, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 01:23:58.148238: step 26750, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:24:01.358570: step 26760, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:24:04.466049: step 26770, loss = nan (404.8 examples/sec; 0.316 sec/batch)
2017-10-18 01:24:07.565145: step 26780, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:24:10.670253: step 26790, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:24:13.748116: step 26800, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:24:16.854359: step 26810, loss = nan (402.1 examples/sec; 0.318 sec/batch)
2017-10-18 01:24:19.955123: step 26820, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:24:23.042016: step 26830, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:24:26.120347: step 26840, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:24:29.213519: step 26850, loss = nan (392.3 examples/sec; 0.326 sec/batch)
2017-10-18 01:24:32.308386: step 26860, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:24:35.402725: step 26870, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:24:38.504000: step 26880, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:24:41.581702: step 26890, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:24:44.673570: step 26900, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:24:47.868195: step 26910, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:24:50.954789: step 26920, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:24:54.024878: step 26930, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:24:57.109695: step 26940, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 01:25:00.305095: step 26950, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:25:03.406487: step 26960, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:25:06.487069: step 26970, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:25:09.573965: step 26980, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:25:12.649774: step 26990, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:25:15.749777: step 27000, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:25:18.830255: step 27010, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:25:21.901721: step 27020, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:25:24.985891: step 27030, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:25:28.079353: step 27040, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:25:31.167879: step 27050, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:25:34.247036: step 27060, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 01:25:37.322502: step 27070, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:25:40.414063: step 27080, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:25:43.515810: step 27090, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:25:46.594007: step 27100, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:25:49.687537: step 27110, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:25:52.789530: step 27120, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:25:55.863253: step 27130, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-18 01:25:58.939755: step 27140, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:26:02.028799: step 27150, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 01:26:05.116505: step 27160, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:26:08.183748: step 27170, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:26:11.289144: step 27180, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:26:14.382635: step 27190, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:26:17.484983: step 27200, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:26:20.583883: step 27210, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:26:23.663472: step 27220, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 01:26:26.738909: step 27230, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:26:29.832254: step 27240, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:26:32.918317: step 27250, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:26:35.981484: step 27260, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:26:39.050844: step 27270, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:26:42.134990: step 27280, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:26:45.204709: step 27290, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:26:48.294057: step 27300, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:26:51.379089: step 27310, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:26:54.465844: step 27320, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:26:57.564643: step 27330, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:27:00.628986: step 27340, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:27:03.728105: step 27350, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 01:27:06.822738: step 27360, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:27:09.910776: step 27370, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 01:27:13.002026: step 27380, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:27:16.081474: step 27390, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:27:19.155925: step 27400, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:27:22.232516: step 27410, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:27:25.302507: step 27420, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:27:28.382158: step 27430, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:27:31.465664: step 27440, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:27:34.546105: step 27450, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:27:37.750040: step 27460, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:27:40.839017: step 27470, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:27:43.931462: step 27480, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:27:47.034192: step 27490, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:27:50.117414: step 27500, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:27:53.218335: step 27510, loss = nan (404.6 examples/sec; 0.316 sec/batch)
2017-10-18 01:27:56.305127: step 27520, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:27:59.400386: step 27530, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:28:02.483750: step 27540, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:28:05.570946: step 27550, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:28:08.667963: step 27560, loss = nan (396.0 examples/sec; 0.323 sec/batch)
2017-10-18 01:28:11.777849: step 27570, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:28:14.855592: step 27580, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:28:17.937577: step 27590, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:28:21.024401: step 27600, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:28:24.129868: step 27610, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:28:27.217290: step 27620, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:28:30.308324: step 27630, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:28:33.402549: step 27640, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:28:36.497054: step 27650, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:28:39.604655: step 27660, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:28:42.688806: step 27670, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:28:45.776653: step 27680, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:28:48.918942: step 27690, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:28:51.990860: step 27700, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:28:55.279912: step 27710, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:28:58.367699: step 27720, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:29:01.442069: step 27730, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:29:04.534385: step 27740, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 01:29:07.606005: step 27750, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:29:10.703834: step 27760, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:29:13.795702: step 27770, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:29:16.884341: step 27780, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:29:19.966565: step 27790, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:29:23.060496: step 27800, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:29:26.158056: step 27810, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:29:29.255747: step 27820, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:29:32.346270: step 27830, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:29:35.429498: step 27840, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:29:38.620621: step 27850, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:29:41.699766: step 27860, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:29:44.792008: step 27870, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:29:47.882480: step 27880, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:29:50.983093: step 27890, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 01:29:54.075921: step 27900, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:29:57.154248: step 27910, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:30:00.238979: step 27920, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:30:03.330790: step 27930, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 01:30:06.403304: step 27940, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:30:09.475202: step 27950, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:30:12.552785: step 27960, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:30:15.617117: step 27970, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:30:18.717244: step 27980, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:30:21.800653: step 27990, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:30:24.888275: step 28000, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:30:27.965109: step 28010, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:30:31.056015: step 28020, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:30:34.156885: step 28030, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 01:30:37.251639: step 28040, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:30:40.330725: step 28050, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:30:43.425617: step 28060, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:30:46.524433: step 28070, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:30:49.614065: step 28080, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:30:52.701561: step 28090, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:30:55.781920: step 28100, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:30:58.869925: step 28110, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:31:01.951775: step 28120, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:31:05.027391: step 28130, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:31:08.113900: step 28140, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:31:11.216919: step 28150, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-18 01:31:14.301680: step 28160, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:31:17.386609: step 28170, loss = nan (407.3 examples/sec; 0.314 sec/batch)
2017-10-18 01:31:20.514364: step 28180, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-18 01:31:23.603946: step 28190, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:31:26.783113: step 28200, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 01:31:29.877144: step 28210, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:31:32.970184: step 28220, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:31:36.053243: step 28230, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:31:39.128021: step 28240, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:31:42.213812: step 28250, loss = nan (407.4 examples/sec; 0.314 sec/batch)
2017-10-18 01:31:45.420290: step 28260, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:31:48.516087: step 28270, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 01:31:51.588535: step 28280, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:31:54.694077: step 28290, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:31:57.767845: step 28300, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 01:32:00.850931: step 28310, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:32:03.942791: step 28320, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 01:32:07.046111: step 28330, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:32:10.167625: step 28340, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:32:13.253108: step 28350, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:32:16.353362: step 28360, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:32:19.441430: step 28370, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:32:22.524164: step 28380, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:32:25.632322: step 28390, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:32:28.712284: step 28400, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:32:31.841498: step 28410, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 01:32:34.943429: step 28420, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:32:38.035155: step 28430, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:32:41.118972: step 28440, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:32:44.213179: step 28450, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:32:47.311126: step 28460, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:32:50.394874: step 28470, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:32:53.491612: step 28480, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:32:56.577616: step 28490, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:32:59.670516: step 28500, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 01:33:02.895061: step 28510, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:33:05.974563: step 28520, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:33:09.064024: step 28530, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:33:12.141856: step 28540, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:33:15.214612: step 28550, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:33:18.286263: step 28560, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 01:33:21.379411: step 28570, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:33:24.462846: step 28580, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:33:27.536463: step 28590, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:33:30.601029: step 28600, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:33:33.694655: step 28610, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:33:36.795351: step 28620, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:33:39.885173: step 28630, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:33:42.980978: step 28640, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:33:46.056459: step 28650, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:33:49.157447: step 28660, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 01:33:52.248956: step 28670, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:33:55.342618: step 28680, loss = nan (404.1 examples/sec; 0.317 sec/batch)
2017-10-18 01:33:58.438750: step 28690, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:34:01.532639: step 28700, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:34:04.624729: step 28710, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:34:07.727127: step 28720, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:34:10.926219: step 28730, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:34:14.009643: step 28740, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:34:17.120662: step 28750, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:34:20.199206: step 28760, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:23.285506: step 28770, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:34:26.351887: step 28780, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:29.442218: step 28790, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:32.525547: step 28800, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:34:35.609387: step 28810, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:34:38.698686: step 28820, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:34:41.791892: step 28830, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:34:44.871778: step 28840, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:47.961689: step 28850, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:51.041444: step 28860, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:34:54.125513: step 28870, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:34:57.207062: step 28880, loss = nan (403.1 examples/sec; 0.318 sec/batch)
2017-10-18 01:35:00.421982: step 28890, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:35:03.514281: step 28900, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:35:06.626135: step 28910, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:35:09.722777: step 28920, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:35:12.812110: step 28930, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:35:15.896039: step 28940, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 01:35:18.969357: step 28950, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:35:22.045538: step 28960, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:35:25.131042: step 28970, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 01:35:28.203212: step 28980, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 01:35:31.286727: step 28990, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:35:34.357065: step 29000, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:35:37.431163: step 29010, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:35:40.515763: step 29020, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 01:35:43.596396: step 29030, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:35:46.697814: step 29040, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:35:49.782562: step 29050, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:35:52.988691: step 29060, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 01:35:56.069730: step 29070, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:35:59.141227: step 29080, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:36:02.247396: step 29090, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:36:05.333537: step 29100, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:36:08.442497: step 29110, loss = nan (393.8 examples/sec; 0.325 sec/batch)
2017-10-18 01:36:11.535086: step 29120, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:36:14.620964: step 29130, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:36:17.693187: step 29140, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:36:20.776433: step 29150, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:36:23.847131: step 29160, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:36:26.922139: step 29170, loss = nan (423.5 examples/sec; 0.302 sec/batch)
2017-10-18 01:36:29.995674: step 29180, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:36:33.074060: step 29190, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:36:36.170693: step 29200, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:36:39.271260: step 29210, loss = nan (403.3 examples/sec; 0.317 sec/batch)
2017-10-18 01:36:42.365666: step 29220, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:36:45.467448: step 29230, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:36:48.556061: step 29240, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:36:51.649056: step 29250, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 01:36:54.730359: step 29260, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 01:36:57.812819: step 29270, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:37:00.912845: step 29280, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 01:37:04.113849: step 29290, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:37:07.215647: step 29300, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:37:10.311662: step 29310, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 01:37:13.378842: step 29320, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:37:16.454649: step 29330, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:37:19.544245: step 29340, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:37:22.640691: step 29350, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:37:25.733137: step 29360, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:37:28.810518: step 29370, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:37:31.902470: step 29380, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:37:34.988575: step 29390, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:37:38.183540: step 29400, loss = nan (309.5 examples/sec; 0.414 sec/batch)
2017-10-18 01:37:41.267644: step 29410, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 01:37:44.352477: step 29420, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:37:47.462321: step 29430, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:37:50.545209: step 29440, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:37:53.636100: step 29450, loss = nan (404.1 examples/sec; 0.317 sec/batch)
2017-10-18 01:37:56.711903: step 29460, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:37:59.780603: step 29470, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:38:02.873275: step 29480, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-18 01:38:05.944634: step 29490, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:38:09.039609: step 29500, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:38:12.140579: step 29510, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:38:15.243785: step 29520, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:38:18.330334: step 29530, loss = nan (406.1 examples/sec; 0.315 sec/batch)
2017-10-18 01:38:21.410859: step 29540, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:38:24.508591: step 29550, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:38:27.627972: step 29560, loss = nan (383.7 examples/sec; 0.334 sec/batch)
2017-10-18 01:38:30.732926: step 29570, loss = nan (408.3 examples/sec; 0.313 sec/batch)
2017-10-18 01:38:33.813533: step 29580, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:38:36.912861: step 29590, loss = nan (406.4 examples/sec; 0.315 sec/batch)
2017-10-18 01:38:40.014820: step 29600, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:38:43.115507: step 29610, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:38:46.221476: step 29620, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:38:49.297049: step 29630, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:38:52.374105: step 29640, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:38:55.454110: step 29650, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:38:58.536897: step 29660, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 01:39:01.610484: step 29670, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:39:04.696938: step 29680, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 01:39:07.798337: step 29690, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:39:10.875884: step 29700, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:39:13.954697: step 29710, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:39:17.028840: step 29720, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:39:20.095810: step 29730, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:39:23.175663: step 29740, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:39:26.252739: step 29750, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:39:29.330143: step 29760, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:39:32.547889: step 29770, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:39:35.683828: step 29780, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:39:38.768388: step 29790, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:39:41.856567: step 29800, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:39:44.939178: step 29810, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 01:39:48.016940: step 29820, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:39:51.095833: step 29830, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:39:54.183371: step 29840, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 01:39:57.263477: step 29850, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:40:00.454536: step 29860, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:40:03.569801: step 29870, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:40:06.642472: step 29880, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:40:09.734254: step 29890, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:40:12.815633: step 29900, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 01:40:15.923172: step 29910, loss = nan (402.5 examples/sec; 0.318 sec/batch)
2017-10-18 01:40:19.013842: step 29920, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:40:22.097562: step 29930, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:40:25.187821: step 29940, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:40:28.297998: step 29950, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:40:31.392710: step 29960, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:40:34.504498: step 29970, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:40:37.613573: step 29980, loss = nan (404.6 examples/sec; 0.316 sec/batch)
2017-10-18 01:40:40.720402: step 29990, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:40:43.803395: step 30000, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:40:46.875770: step 30010, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:40:49.962431: step 30020, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 01:40:53.059678: step 30030, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:40:56.154346: step 30040, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:40:59.251136: step 30050, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:41:02.341707: step 30060, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:41:05.433942: step 30070, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:41:08.509969: step 30080, loss = nan (424.5 examples/sec; 0.302 sec/batch)
2017-10-18 01:41:11.597534: step 30090, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:14.694405: step 30100, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:41:17.776280: step 30110, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:41:20.846652: step 30120, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:23.930495: step 30130, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:41:27.023096: step 30140, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:41:30.096580: step 30150, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:33.169460: step 30160, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:41:36.269246: step 30170, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:41:39.355890: step 30180, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:41:42.439816: step 30190, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:41:45.515619: step 30200, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:48.596513: step 30210, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:41:51.693395: step 30220, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:54.774963: step 30230, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:41:57.861948: step 30240, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:42:00.963185: step 30250, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:42:04.059952: step 30260, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:42:07.155819: step 30270, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 01:42:10.245076: step 30280, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:42:13.334942: step 30290, loss = nan (422.6 examples/sec; 0.303 sec/batch)
2017-10-18 01:42:16.445686: step 30300, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:42:19.528955: step 30310, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:42:22.617547: step 30320, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:42:25.737554: step 30330, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:42:28.825631: step 30340, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:42:31.912426: step 30350, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:42:35.007220: step 30360, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:42:38.094987: step 30370, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:42:41.193099: step 30380, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-18 01:42:44.291216: step 30390, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:42:47.378965: step 30400, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:42:50.476609: step 30410, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:42:53.587147: step 30420, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:42:56.706552: step 30430, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 01:42:59.786588: step 30440, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:43:02.920486: step 30450, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:43:06.019799: step 30460, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-18 01:43:09.104146: step 30470, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:43:12.184425: step 30480, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 01:43:15.266749: step 30490, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:43:18.350780: step 30500, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 01:43:21.435560: step 30510, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:43:24.511745: step 30520, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:43:27.615619: step 30530, loss = nan (395.2 examples/sec; 0.324 sec/batch)
2017-10-18 01:43:30.713348: step 30540, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:43:33.822540: step 30550, loss = nan (397.7 examples/sec; 0.322 sec/batch)
2017-10-18 01:43:36.915534: step 30560, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:43:40.006295: step 30570, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 01:43:43.081266: step 30580, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:43:46.186873: step 30590, loss = nan (407.0 examples/sec; 0.315 sec/batch)
2017-10-18 01:43:49.268846: step 30600, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:43:52.347132: step 30610, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:43:55.436165: step 30620, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:43:58.515251: step 30630, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 01:44:01.600109: step 30640, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:44:04.678045: step 30650, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:44:07.755728: step 30660, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:44:10.839037: step 30670, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:44:13.924360: step 30680, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:44:16.999368: step 30690, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:44:20.201070: step 30700, loss = nan (303.1 examples/sec; 0.422 sec/batch)
2017-10-18 01:44:23.283295: step 30710, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:44:26.363490: step 30720, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:44:29.456890: step 30730, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:44:32.534691: step 30740, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:44:35.607895: step 30750, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:44:38.695396: step 30760, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:44:41.782997: step 30770, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:44:44.870057: step 30780, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:44:47.932899: step 30790, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:44:51.014054: step 30800, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:44:54.088285: step 30810, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:44:57.179768: step 30820, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:00.246802: step 30830, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 01:45:03.444861: step 30840, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 01:45:06.533261: step 30850, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 01:45:09.609045: step 30860, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:45:12.703260: step 30870, loss = nan (406.4 examples/sec; 0.315 sec/batch)
2017-10-18 01:45:15.773758: step 30880, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:45:18.986935: step 30890, loss = nan (396.1 examples/sec; 0.323 sec/batch)
2017-10-18 01:45:22.073675: step 30900, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:45:25.163415: step 30910, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:28.246498: step 30920, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:45:31.318745: step 30930, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:34.410745: step 30940, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:37.482216: step 30950, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:40.578583: step 30960, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:45:43.669692: step 30970, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:45:46.758413: step 30980, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:45:49.850481: step 30990, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:45:52.936501: step 31000, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:45:56.028987: step 31010, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 01:45:59.099754: step 31020, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:46:02.189689: step 31030, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:46:05.265665: step 31040, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:46:08.358002: step 31050, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:46:11.462255: step 31060, loss = nan (401.9 examples/sec; 0.319 sec/batch)
2017-10-18 01:46:14.552659: step 31070, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-18 01:46:17.626401: step 31080, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:46:20.706620: step 31090, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:46:23.791533: step 31100, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 01:46:26.872879: step 31110, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:46:29.961618: step 31120, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 01:46:33.069782: step 31130, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:46:36.138829: step 31140, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:46:39.220584: step 31150, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:46:42.304552: step 31160, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:46:45.383397: step 31170, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:46:48.455342: step 31180, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:46:51.544850: step 31190, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:46:54.635613: step 31200, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:46:57.736516: step 31210, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 01:47:00.813865: step 31220, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 01:47:03.926681: step 31230, loss = nan (404.6 examples/sec; 0.316 sec/batch)
2017-10-18 01:47:07.025229: step 31240, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:10.109625: step 31250, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:13.181547: step 31260, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:47:16.264613: step 31270, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:47:19.355956: step 31280, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:47:22.434500: step 31290, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:25.521507: step 31300, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:47:28.606396: step 31310, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:31.687796: step 31320, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:47:34.769313: step 31330, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:47:37.852682: step 31340, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:40.944037: step 31350, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:44.038640: step 31360, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:47:47.244193: step 31370, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:47:50.332503: step 31380, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:47:53.422996: step 31390, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:47:56.614588: step 31400, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 01:47:59.698982: step 31410, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:48:02.796636: step 31420, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:48:05.912049: step 31430, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:48:09.032967: step 31440, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:48:12.113541: step 31450, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:48:15.212049: step 31460, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:48:18.316917: step 31470, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:48:21.461429: step 31480, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 01:48:24.555196: step 31490, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:48:27.625695: step 31500, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:48:30.749174: step 31510, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:48:33.824421: step 31520, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:48:36.901223: step 31530, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:48:40.110933: step 31540, loss = nan (407.3 examples/sec; 0.314 sec/batch)
2017-10-18 01:48:43.204356: step 31550, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 01:48:46.295240: step 31560, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:48:49.372143: step 31570, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 01:48:52.446943: step 31580, loss = nan (422.1 examples/sec; 0.303 sec/batch)
2017-10-18 01:48:55.535512: step 31590, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:48:58.627516: step 31600, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:49:01.738695: step 31610, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:49:04.850912: step 31620, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 01:49:08.028034: step 31630, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:49:11.117110: step 31640, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:49:14.213318: step 31650, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:49:17.300867: step 31660, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 01:49:20.384643: step 31670, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:49:23.465205: step 31680, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:49:26.537523: step 31690, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:49:29.629812: step 31700, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 01:49:32.741572: step 31710, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 01:49:35.836196: step 31720, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 01:49:38.922855: step 31730, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:49:42.018230: step 31740, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:49:45.120556: step 31750, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:49:48.233513: step 31760, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 01:49:51.337869: step 31770, loss = nan (407.3 examples/sec; 0.314 sec/batch)
2017-10-18 01:49:54.418691: step 31780, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:49:57.497450: step 31790, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:50:00.599166: step 31800, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 01:50:03.685952: step 31810, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:50:06.797440: step 31820, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:50:09.923068: step 31830, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:50:13.016658: step 31840, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 01:50:16.091478: step 31850, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 01:50:19.177929: step 31860, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:50:22.252094: step 31870, loss = nan (422.1 examples/sec; 0.303 sec/batch)
2017-10-18 01:50:25.347485: step 31880, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 01:50:28.442382: step 31890, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:50:31.526224: step 31900, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:50:34.620550: step 31910, loss = nan (400.9 examples/sec; 0.319 sec/batch)
2017-10-18 01:50:37.714051: step 31920, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 01:50:40.829476: step 31930, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:50:43.922255: step 31940, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:50:47.017623: step 31950, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:50:50.108452: step 31960, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:50:53.189698: step 31970, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:50:56.280232: step 31980, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:50:59.383082: step 31990, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:51:02.466302: step 32000, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:51:05.568049: step 32010, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:51:08.649339: step 32020, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:51:11.747945: step 32030, loss = nan (398.2 examples/sec; 0.321 sec/batch)
2017-10-18 01:51:14.832478: step 32040, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:51:17.912775: step 32050, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 01:51:20.983554: step 32060, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:51:24.058626: step 32070, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 01:51:27.238927: step 32080, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:51:30.309005: step 32090, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:51:33.386517: step 32100, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:51:36.451534: step 32110, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:51:39.531411: step 32120, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:51:42.631539: step 32130, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:51:45.726060: step 32140, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:51:48.811792: step 32150, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:51:51.889150: step 32160, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 01:51:54.967271: step 32170, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:51:58.042019: step 32180, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:52:01.135034: step 32190, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:52:04.247620: step 32200, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:52:07.351087: step 32210, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:52:10.453943: step 32220, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 01:52:13.542927: step 32230, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:52:16.620453: step 32240, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 01:52:19.699838: step 32250, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:52:22.774483: step 32260, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 01:52:25.874865: step 32270, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:52:28.964191: step 32280, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:52:32.050145: step 32290, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:52:35.267745: step 32300, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:52:38.453207: step 32310, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 01:52:41.539775: step 32320, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 01:52:44.614848: step 32330, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:52:47.695053: step 32340, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:52:50.756780: step 32350, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 01:52:53.836228: step 32360, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:52:56.916026: step 32370, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 01:52:59.997938: step 32380, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 01:53:03.073246: step 32390, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:53:06.172972: step 32400, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:53:09.261339: step 32410, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:53:12.336514: step 32420, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:53:15.414009: step 32430, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:53:18.493505: step 32440, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:53:21.584211: step 32450, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:53:24.662466: step 32460, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:53:27.734719: step 32470, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 01:53:30.803641: step 32480, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:53:33.912194: step 32490, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 01:53:36.996270: step 32500, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:53:40.076175: step 32510, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:53:43.157966: step 32520, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 01:53:46.245542: step 32530, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 01:53:49.329543: step 32540, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 01:53:52.399951: step 32550, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:53:55.478733: step 32560, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 01:53:58.558735: step 32570, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:54:01.651232: step 32580, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:54:04.746032: step 32590, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 01:54:07.814384: step 32600, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:54:10.998993: step 32610, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:54:14.082322: step 32620, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 01:54:17.173506: step 32630, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:54:20.256436: step 32640, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:54:23.347185: step 32650, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:54:26.414285: step 32660, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 01:54:29.484750: step 32670, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:54:32.567896: step 32680, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:54:35.641708: step 32690, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:54:38.739893: step 32700, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:54:41.830375: step 32710, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:54:44.918199: step 32720, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-18 01:54:48.002849: step 32730, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 01:54:51.089977: step 32740, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:54:54.158922: step 32750, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:54:57.230489: step 32760, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:55:00.302751: step 32770, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 01:55:03.393931: step 32780, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:55:06.496144: step 32790, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:55:09.590648: step 32800, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 01:55:12.663332: step 32810, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 01:55:15.740984: step 32820, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:55:18.852868: step 32830, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:55:21.955647: step 32840, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:55:25.036257: step 32850, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:55:28.133598: step 32860, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:55:31.226704: step 32870, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:55:34.323609: step 32880, loss = nan (401.2 examples/sec; 0.319 sec/batch)
2017-10-18 01:55:37.397443: step 32890, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 01:55:40.471961: step 32900, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:55:43.548814: step 32910, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 01:55:46.647577: step 32920, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 01:55:49.747184: step 32930, loss = nan (394.2 examples/sec; 0.325 sec/batch)
2017-10-18 01:55:52.830529: step 32940, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 01:55:55.890819: step 32950, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 01:55:58.970126: step 32960, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 01:56:02.064871: step 32970, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 01:56:05.147343: step 32980, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:56:08.237865: step 32990, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:56:11.333672: step 33000, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 01:56:14.414533: step 33010, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 01:56:17.504618: step 33020, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:56:20.582427: step 33030, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 01:56:23.658352: step 33040, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:56:26.751848: step 33050, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:56:29.832240: step 33060, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:56:32.904703: step 33070, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 01:56:36.003784: step 33080, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 01:56:39.085605: step 33090, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 01:56:42.181273: step 33100, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 01:56:45.245969: step 33110, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 01:56:48.345275: step 33120, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:56:51.425098: step 33130, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 01:56:54.503252: step 33140, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 01:56:57.596593: step 33150, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:57:00.686427: step 33160, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 01:57:03.808616: step 33170, loss = nan (404.0 examples/sec; 0.317 sec/batch)
2017-10-18 01:57:06.928082: step 33180, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 01:57:10.062487: step 33190, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:57:13.146149: step 33200, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 01:57:16.215871: step 33210, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 01:57:19.319564: step 33220, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 01:57:22.403933: step 33230, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:57:25.498126: step 33240, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 01:57:28.603463: step 33250, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 01:57:31.695812: step 33260, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 01:57:34.778370: step 33270, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 01:57:37.849228: step 33280, loss = nan (422.4 examples/sec; 0.303 sec/batch)
2017-10-18 01:57:40.922760: step 33290, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 01:57:44.011531: step 33300, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 01:57:47.089091: step 33310, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 01:57:50.173492: step 33320, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:57:53.416096: step 33330, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 01:57:56.535568: step 33340, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 01:57:59.618560: step 33350, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:58:02.702391: step 33360, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 01:58:05.804340: step 33370, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:58:09.002943: step 33380, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 01:58:12.102970: step 33390, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 01:58:15.192456: step 33400, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 01:58:18.272704: step 33410, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-18 01:58:21.363024: step 33420, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:58:24.439621: step 33430, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:58:27.535643: step 33440, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 01:58:30.628451: step 33450, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:58:33.717516: step 33460, loss = nan (422.4 examples/sec; 0.303 sec/batch)
2017-10-18 01:58:36.796585: step 33470, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 01:58:39.898202: step 33480, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-18 01:58:42.976634: step 33490, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 01:58:46.041231: step 33500, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:58:49.117433: step 33510, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 01:58:52.221087: step 33520, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 01:58:55.296476: step 33530, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 01:58:58.385221: step 33540, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 01:59:01.491833: step 33550, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 01:59:04.630883: step 33560, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 01:59:07.711679: step 33570, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 01:59:10.818871: step 33580, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 01:59:13.894840: step 33590, loss = nan (422.8 examples/sec; 0.303 sec/batch)
2017-10-18 01:59:16.998902: step 33600, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 01:59:20.081710: step 33610, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 01:59:23.158029: step 33620, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 01:59:26.272375: step 33630, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 01:59:29.390199: step 33640, loss = nan (400.9 examples/sec; 0.319 sec/batch)
2017-10-18 01:59:32.469118: step 33650, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 01:59:35.568215: step 33660, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 01:59:38.651483: step 33670, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 01:59:41.723062: step 33680, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 01:59:44.805647: step 33690, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 01:59:47.887456: step 33700, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 01:59:50.975547: step 33710, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 01:59:54.082501: step 33720, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-18 01:59:57.173482: step 33730, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:00:00.270530: step 33740, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:00:03.377773: step 33750, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:00:06.455016: step 33760, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:00:09.554791: step 33770, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:00:12.641420: step 33780, loss = nan (406.8 examples/sec; 0.315 sec/batch)
2017-10-18 02:00:15.719246: step 33790, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:00:18.820151: step 33800, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:00:21.905406: step 33810, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:00:24.988146: step 33820, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:00:28.078995: step 33830, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:00:31.168942: step 33840, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:00:34.251472: step 33850, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:00:37.340854: step 33860, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:00:40.542483: step 33870, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:00:43.628842: step 33880, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:00:46.704214: step 33890, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:00:49.803370: step 33900, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:00:52.890760: step 33910, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:00:55.961500: step 33920, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 02:00:59.038178: step 33930, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:01:02.114059: step 33940, loss = nan (422.9 examples/sec; 0.303 sec/batch)
2017-10-18 02:01:05.176418: step 33950, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 02:01:08.247916: step 33960, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:01:11.337044: step 33970, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:01:14.419414: step 33980, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:01:17.507950: step 33990, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:01:20.598825: step 34000, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:01:23.680524: step 34010, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:01:26.769466: step 34020, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:01:29.839611: step 34030, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:01:32.939575: step 34040, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:01:36.032282: step 34050, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:01:39.104176: step 34060, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:01:42.180893: step 34070, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 02:01:45.264989: step 34080, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:01:48.341724: step 34090, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:01:51.419772: step 34100, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:01:54.487841: step 34110, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:01:57.576735: step 34120, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:02:00.659964: step 34130, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:02:03.760647: step 34140, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:02:06.856661: step 34150, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:02:09.942795: step 34160, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:02:13.042184: step 34170, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 02:02:16.136252: step 34180, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:02:19.236266: step 34190, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:02:22.328447: step 34200, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:02:25.419995: step 34210, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:02:28.521346: step 34220, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 02:02:31.611819: step 34230, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:02:34.675629: step 34240, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:02:37.747223: step 34250, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:02:40.838779: step 34260, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:02:43.924237: step 34270, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:02:47.002795: step 34280, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:02:50.085507: step 34290, loss = nan (400.3 examples/sec; 0.320 sec/batch)
2017-10-18 02:02:53.164444: step 34300, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:02:56.239039: step 34310, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:02:59.317361: step 34320, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 02:03:02.422907: step 34330, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:03:05.532597: step 34340, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:03:08.627677: step 34350, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:03:11.733317: step 34360, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 02:03:14.824465: step 34370, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:03:17.919917: step 34380, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:03:21.003786: step 34390, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:03:24.088554: step 34400, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:03:27.177483: step 34410, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:03:30.265305: step 34420, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:03:33.321405: step 34430, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:03:36.412216: step 34440, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:03:39.518924: step 34450, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 02:03:42.589535: step 34460, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:03:45.687823: step 34470, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 02:03:48.782865: step 34480, loss = nan (406.7 examples/sec; 0.315 sec/batch)
2017-10-18 02:03:51.868734: step 34490, loss = nan (403.8 examples/sec; 0.317 sec/batch)
2017-10-18 02:03:55.045057: step 34500, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:03:58.129439: step 34510, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:04:01.226030: step 34520, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:04.311787: step 34530, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:04:07.397191: step 34540, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:10.473185: step 34550, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:04:13.567993: step 34560, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:16.659380: step 34570, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:19.741878: step 34580, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:04:22.815296: step 34590, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:25.906864: step 34600, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:04:28.982938: step 34610, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:32.065781: step 34620, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:04:35.156274: step 34630, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:04:38.236465: step 34640, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:04:41.322711: step 34650, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:04:44.401570: step 34660, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 02:04:47.500998: step 34670, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:04:50.585378: step 34680, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:04:53.672340: step 34690, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:04:56.764421: step 34700, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 02:04:59.841858: step 34710, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:05:02.925775: step 34720, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:05:06.112514: step 34730, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:05:09.212911: step 34740, loss = nan (407.0 examples/sec; 0.314 sec/batch)
2017-10-18 02:05:12.302326: step 34750, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:05:15.380442: step 34760, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:05:18.486186: step 34770, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:05:21.587414: step 34780, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:05:24.681804: step 34790, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:05:27.777954: step 34800, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:05:30.844474: step 34810, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:05:33.941003: step 34820, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:05:37.012284: step 34830, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:05:40.129749: step 34840, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:05:43.219270: step 34850, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:05:46.293662: step 34860, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:05:49.376325: step 34870, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:05:52.474328: step 34880, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:05:55.565362: step 34890, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:05:58.635143: step 34900, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:06:01.739129: step 34910, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:06:04.856654: step 34920, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 02:06:08.067411: step 34930, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:06:11.178169: step 34940, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:06:14.262458: step 34950, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:06:17.335230: step 34960, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 02:06:20.416574: step 34970, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:06:23.492171: step 34980, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:06:26.595629: step 34990, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:06:29.686089: step 35000, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-18 02:06:32.773909: step 35010, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:06:35.872988: step 35020, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 02:06:38.966249: step 35030, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:06:42.055250: step 35040, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:06:45.139719: step 35050, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:06:48.213554: step 35060, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:06:51.299421: step 35070, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:06:54.386239: step 35080, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:06:57.487721: step 35090, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 02:07:00.576700: step 35100, loss = nan (404.7 examples/sec; 0.316 sec/batch)
2017-10-18 02:07:03.675750: step 35110, loss = nan (398.9 examples/sec; 0.321 sec/batch)
2017-10-18 02:07:06.753552: step 35120, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:07:09.856509: step 35130, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:07:13.091269: step 35140, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:07:16.185571: step 35150, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:07:19.281085: step 35160, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:07:22.376486: step 35170, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:07:25.467608: step 35180, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:07:28.556517: step 35190, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:07:31.659760: step 35200, loss = nan (404.4 examples/sec; 0.317 sec/batch)
2017-10-18 02:07:34.762787: step 35210, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 02:07:37.867601: step 35220, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:07:40.950941: step 35230, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:07:44.011243: step 35240, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:07:47.082707: step 35250, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:07:50.164940: step 35260, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 02:07:53.247847: step 35270, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:07:56.324715: step 35280, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:07:59.420813: step 35290, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:08:02.496913: step 35300, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:08:05.582915: step 35310, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:08:08.661569: step 35320, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 02:08:11.729938: step 35330, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:08:14.829522: step 35340, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:08:17.902944: step 35350, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-18 02:08:20.994848: step 35360, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:08:24.105203: step 35370, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:08:27.193541: step 35380, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:08:30.278958: step 35390, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:08:33.373138: step 35400, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:08:36.457190: step 35410, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:08:39.542792: step 35420, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:08:42.649298: step 35430, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:08:45.765050: step 35440, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:08:48.849317: step 35450, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:08:51.924811: step 35460, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:08:55.017282: step 35470, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:08:58.097474: step 35480, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:01.187845: step 35490, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:09:04.280512: step 35500, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:09:07.402654: step 35510, loss = nan (407.3 examples/sec; 0.314 sec/batch)
2017-10-18 02:09:10.492105: step 35520, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:09:13.592630: step 35530, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:16.681173: step 35540, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:09:19.795073: step 35550, loss = nan (403.4 examples/sec; 0.317 sec/batch)
2017-10-18 02:09:22.874433: step 35560, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:09:25.975980: step 35570, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:29.075027: step 35580, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 02:09:32.157607: step 35590, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:09:35.250578: step 35600, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:38.362919: step 35610, loss = nan (406.7 examples/sec; 0.315 sec/batch)
2017-10-18 02:09:41.454113: step 35620, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:09:44.656165: step 35630, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:09:47.749109: step 35640, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:50.832062: step 35650, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:09:53.911635: step 35660, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:09:57.006073: step 35670, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:10:00.098049: step 35680, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:10:03.182930: step 35690, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:10:06.288180: step 35700, loss = nan (396.8 examples/sec; 0.323 sec/batch)
2017-10-18 02:10:09.367143: step 35710, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:10:12.461341: step 35720, loss = nan (405.6 examples/sec; 0.316 sec/batch)
2017-10-18 02:10:15.563315: step 35730, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:10:18.658930: step 35740, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 02:10:21.730208: step 35750, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:10:24.829087: step 35760, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:10:27.913595: step 35770, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:10:31.005909: step 35780, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:10:34.087484: step 35790, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:10:37.169290: step 35800, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:10:40.251437: step 35810, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:10:43.354821: step 35820, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 02:10:46.437334: step 35830, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:10:49.549296: step 35840, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:10:52.630877: step 35850, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:10:55.715233: step 35860, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:10:58.818789: step 35870, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:11:01.916165: step 35880, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:11:04.996186: step 35890, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:11:08.087387: step 35900, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:11:11.186608: step 35910, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:11:14.268794: step 35920, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:11:17.349406: step 35930, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:11:20.453544: step 35940, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 02:11:23.559453: step 35950, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 02:11:26.633279: step 35960, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:11:29.730990: step 35970, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:11:32.826584: step 35980, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 02:11:36.022638: step 35990, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 02:11:39.109385: step 36000, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:11:42.209452: step 36010, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:11:45.289472: step 36020, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:11:48.400964: step 36030, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 02:11:51.477115: step 36040, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:11:54.586230: step 36050, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:11:57.655930: step 36060, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 02:12:00.754278: step 36070, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:12:03.840388: step 36080, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:12:06.924423: step 36090, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:12:10.021932: step 36100, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:12:13.111761: step 36110, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:12:16.185457: step 36120, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:12:19.254036: step 36130, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:12:22.338579: step 36140, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:12:25.422525: step 36150, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:12:28.497360: step 36160, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:12:31.577142: step 36170, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:12:34.664066: step 36180, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:12:37.736396: step 36190, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:12:40.803753: step 36200, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:12:43.905998: step 36210, loss = nan (404.0 examples/sec; 0.317 sec/batch)
2017-10-18 02:12:46.982356: step 36220, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:12:50.082564: step 36230, loss = nan (405.7 examples/sec; 0.316 sec/batch)
2017-10-18 02:12:53.160016: step 36240, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:12:56.356204: step 36250, loss = nan (399.9 examples/sec; 0.320 sec/batch)
2017-10-18 02:12:59.426953: step 36260, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:13:02.522678: step 36270, loss = nan (395.7 examples/sec; 0.323 sec/batch)
2017-10-18 02:13:05.643875: step 36280, loss = nan (405.5 examples/sec; 0.316 sec/batch)
2017-10-18 02:13:08.730974: step 36290, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:13:11.831190: step 36300, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:13:14.917759: step 36310, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-18 02:13:18.023915: step 36320, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:13:21.124976: step 36330, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 02:13:24.194211: step 36340, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:13:27.289807: step 36350, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:13:30.388509: step 36360, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:13:33.487822: step 36370, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:13:36.581625: step 36380, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:13:39.678535: step 36390, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:13:42.777778: step 36400, loss = nan (403.4 examples/sec; 0.317 sec/batch)
2017-10-18 02:13:45.854214: step 36410, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:13:48.947644: step 36420, loss = nan (402.2 examples/sec; 0.318 sec/batch)
2017-10-18 02:13:52.026899: step 36430, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 02:13:55.108290: step 36440, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:13:58.184702: step 36450, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 02:14:01.270298: step 36460, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:14:04.362539: step 36470, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:14:07.439805: step 36480, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:14:10.520875: step 36490, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:14:13.618921: step 36500, loss = nan (407.0 examples/sec; 0.315 sec/batch)
2017-10-18 02:14:16.723468: step 36510, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:14:19.798603: step 36520, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:14:22.884363: step 36530, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:14:25.972442: step 36540, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 02:14:29.059286: step 36550, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:14:32.144931: step 36560, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:14:35.250254: step 36570, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:14:38.344728: step 36580, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:14:41.437891: step 36590, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:14:44.515115: step 36600, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:14:47.619974: step 36610, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:14:50.729025: step 36620, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:14:53.810902: step 36630, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:14:56.894901: step 36640, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:00.100600: step 36650, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:03.178263: step 36660, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:06.279746: step 36670, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 02:15:09.348339: step 36680, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:12.477324: step 36690, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 02:15:15.560032: step 36700, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 02:15:18.640803: step 36710, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:15:21.731902: step 36720, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:15:24.813089: step 36730, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:15:27.884455: step 36740, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:15:30.963561: step 36750, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:15:34.048004: step 36760, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:37.119982: step 36770, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:15:40.224739: step 36780, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:15:43.412645: step 36790, loss = nan (309.9 examples/sec; 0.413 sec/batch)
2017-10-18 02:15:46.511667: step 36800, loss = nan (421.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:15:49.599904: step 36810, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:15:52.688912: step 36820, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:15:55.778434: step 36830, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:15:58.862325: step 36840, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:16:02.072111: step 36850, loss = nan (404.0 examples/sec; 0.317 sec/batch)
2017-10-18 02:16:05.151540: step 36860, loss = nan (410.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:16:08.237642: step 36870, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:16:11.351557: step 36880, loss = nan (406.4 examples/sec; 0.315 sec/batch)
2017-10-18 02:16:14.428753: step 36890, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 02:16:17.503577: step 36900, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:16:20.648125: step 36910, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:16:23.736021: step 36920, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:16:26.831190: step 36930, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:16:29.932987: step 36940, loss = nan (404.4 examples/sec; 0.317 sec/batch)
2017-10-18 02:16:33.120485: step 36950, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 02:16:36.220241: step 36960, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:16:39.296779: step 36970, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:16:42.372198: step 36980, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:16:45.457389: step 36990, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:16:48.544164: step 37000, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:16:51.642703: step 37010, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 02:16:54.726580: step 37020, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:16:57.822088: step 37030, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:17:00.889378: step 37040, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:17:03.982960: step 37050, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:17:07.053565: step 37060, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:17:10.136457: step 37070, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:17:13.228318: step 37080, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:17:16.320376: step 37090, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:17:19.420135: step 37100, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-18 02:17:22.500485: step 37110, loss = nan (402.7 examples/sec; 0.318 sec/batch)
2017-10-18 02:17:25.585450: step 37120, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:17:28.660570: step 37130, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:17:31.744958: step 37140, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:17:34.821417: step 37150, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:17:37.915139: step 37160, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:17:40.998101: step 37170, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 02:17:44.086194: step 37180, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 02:17:47.159461: step 37190, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:17:50.250867: step 37200, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:17:53.335821: step 37210, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:17:56.421183: step 37220, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:17:59.623756: step 37230, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 02:18:02.712706: step 37240, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:18:05.789736: step 37250, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:18:08.877934: step 37260, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-18 02:18:11.955648: step 37270, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:18:15.036490: step 37280, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:18:18.132826: step 37290, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:18:21.221118: step 37300, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:18:24.317148: step 37310, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:18:27.398167: step 37320, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:18:30.476045: step 37330, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:18:33.588033: step 37340, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:18:36.679842: step 37350, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 02:18:39.781031: step 37360, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:18:42.862485: step 37370, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:18:45.960354: step 37380, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:18:49.091004: step 37390, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:18:52.157849: step 37400, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:18:55.243667: step 37410, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:18:58.330449: step 37420, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 02:19:01.415063: step 37430, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 02:19:04.486686: step 37440, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:19:07.561517: step 37450, loss = nan (401.4 examples/sec; 0.319 sec/batch)
2017-10-18 02:19:10.639018: step 37460, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:19:13.739155: step 37470, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:19:16.815201: step 37480, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 02:19:19.918108: step 37490, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:19:23.004470: step 37500, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:19:26.086122: step 37510, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:19:29.159330: step 37520, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:19:32.230307: step 37530, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:19:35.317939: step 37540, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:19:38.395983: step 37550, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:19:41.478407: step 37560, loss = nan (405.6 examples/sec; 0.316 sec/batch)
2017-10-18 02:19:44.571764: step 37570, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:19:47.652068: step 37580, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:19:50.743037: step 37590, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:19:53.815775: step 37600, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:19:56.889775: step 37610, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:19:59.967778: step 37620, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:20:03.064742: step 37630, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:20:06.145247: step 37640, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:20:09.221684: step 37650, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:20:12.301644: step 37660, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:20:15.406460: step 37670, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 02:20:18.485561: step 37680, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:20:21.580869: step 37690, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:20:24.651211: step 37700, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:20:27.725092: step 37710, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:20:30.811683: step 37720, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:20:33.899136: step 37730, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:20:37.044502: step 37740, loss = nan (350.0 examples/sec; 0.366 sec/batch)
2017-10-18 02:20:40.119399: step 37750, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:20:43.223073: step 37760, loss = nan (402.0 examples/sec; 0.318 sec/batch)
2017-10-18 02:20:46.308415: step 37770, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:20:49.398145: step 37780, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:20:52.493779: step 37790, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:20:55.573559: step 37800, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:20:58.651835: step 37810, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:21:01.736976: step 37820, loss = nan (404.8 examples/sec; 0.316 sec/batch)
2017-10-18 02:21:04.801401: step 37830, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:21:07.890455: step 37840, loss = nan (407.5 examples/sec; 0.314 sec/batch)
2017-10-18 02:21:10.962825: step 37850, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:21:14.040745: step 37860, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:21:17.112346: step 37870, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:21:20.205674: step 37880, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:21:23.283776: step 37890, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:21:26.368683: step 37900, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:21:29.446178: step 37910, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:21:32.521606: step 37920, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:21:35.607624: step 37930, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:21:38.692821: step 37940, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:21:41.776010: step 37950, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:21:44.850860: step 37960, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 02:21:47.930020: step 37970, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 02:21:51.007765: step 37980, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:21:54.089867: step 37990, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:21:57.166070: step 38000, loss = nan (402.0 examples/sec; 0.318 sec/batch)
2017-10-18 02:22:00.249541: step 38010, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:22:03.337323: step 38020, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:22:06.411075: step 38030, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:22:09.496859: step 38040, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:22:12.583899: step 38050, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:22:15.669700: step 38060, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:22:18.757894: step 38070, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 02:22:21.855076: step 38080, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:22:24.925719: step 38090, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:22:28.010146: step 38100, loss = nan (406.6 examples/sec; 0.315 sec/batch)
2017-10-18 02:22:31.099426: step 38110, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:22:34.173032: step 38120, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:22:37.259312: step 38130, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:22:40.334638: step 38140, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:22:43.464282: step 38150, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:22:46.567408: step 38160, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:22:49.759299: step 38170, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:22:52.842046: step 38180, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:22:56.058457: step 38190, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:22:59.140670: step 38200, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:23:02.246488: step 38210, loss = nan (398.1 examples/sec; 0.322 sec/batch)
2017-10-18 02:23:05.325422: step 38220, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:23:08.456668: step 38230, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:23:11.552784: step 38240, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:23:14.649722: step 38250, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:23:17.736970: step 38260, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:23:20.802040: step 38270, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:23:23.980229: step 38280, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:23:27.071031: step 38290, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:23:30.162768: step 38300, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:23:33.257115: step 38310, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:23:36.338160: step 38320, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:23:39.547851: step 38330, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:23:42.650063: step 38340, loss = nan (402.6 examples/sec; 0.318 sec/batch)
2017-10-18 02:23:45.735830: step 38350, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 02:23:48.817365: step 38360, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:23:51.893206: step 38370, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 02:23:54.973058: step 38380, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:23:58.046306: step 38390, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 02:24:01.128745: step 38400, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:24:04.229423: step 38410, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:24:07.295119: step 38420, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:24:10.381883: step 38430, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:24:13.454007: step 38440, loss = nan (420.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:24:16.533546: step 38450, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:24:19.612672: step 38460, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 02:24:22.704079: step 38470, loss = nan (386.9 examples/sec; 0.331 sec/batch)
2017-10-18 02:24:25.775519: step 38480, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:24:28.889895: step 38490, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:24:31.971540: step 38500, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 02:24:35.043441: step 38510, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:24:38.108421: step 38520, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:24:41.184072: step 38530, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:24:44.284859: step 38540, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 02:24:47.372075: step 38550, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:24:50.466954: step 38560, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:24:53.546900: step 38570, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:24:56.621601: step 38580, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:24:59.693619: step 38590, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:25:02.785863: step 38600, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:25:05.859694: step 38610, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:25:08.970818: step 38620, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:25:12.044678: step 38630, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:25:15.122406: step 38640, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:18.204779: step 38650, loss = nan (417.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:21.296670: step 38660, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:25:24.394061: step 38670, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:27.484854: step 38680, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:30.563970: step 38690, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:33.658099: step 38700, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-18 02:25:36.734312: step 38710, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:25:39.835117: step 38720, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:25:42.929062: step 38730, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:25:46.126564: step 38740, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:25:49.324614: step 38750, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:25:52.394006: step 38760, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:25:55.480140: step 38770, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:25:58.547509: step 38780, loss = nan (423.2 examples/sec; 0.302 sec/batch)
2017-10-18 02:26:01.630389: step 38790, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:26:04.716837: step 38800, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:26:07.804574: step 38810, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:26:10.894170: step 38820, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:26:14.128686: step 38830, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:26:17.234630: step 38840, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:26:20.310903: step 38850, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:26:23.387091: step 38860, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:26:26.473363: step 38870, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:26:29.546538: step 38880, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:26:32.628687: step 38890, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:26:35.704729: step 38900, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:26:38.781895: step 38910, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:26:41.906031: step 38920, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:26:44.979483: step 38930, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:26:48.064295: step 38940, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:26:51.140767: step 38950, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:26:54.242060: step 38960, loss = nan (405.2 examples/sec; 0.316 sec/batch)
2017-10-18 02:26:57.328611: step 38970, loss = nan (403.7 examples/sec; 0.317 sec/batch)
2017-10-18 02:27:00.417032: step 38980, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:27:03.525293: step 38990, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:27:06.605841: step 39000, loss = nan (413.6 examples/sec; 0.310 sec/batch)
2017-10-18 02:27:09.725543: step 39010, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:27:12.799383: step 39020, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:27:15.907011: step 39030, loss = nan (404.2 examples/sec; 0.317 sec/batch)
2017-10-18 02:27:18.996189: step 39040, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:27:22.093196: step 39050, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:27:25.178301: step 39060, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:27:28.266987: step 39070, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:27:31.367124: step 39080, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:27:34.491945: step 39090, loss = nan (405.0 examples/sec; 0.316 sec/batch)
2017-10-18 02:27:37.578804: step 39100, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:27:40.663078: step 39110, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:27:43.764367: step 39120, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:27:46.838387: step 39130, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:27:49.916066: step 39140, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:27:52.995645: step 39150, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:27:56.085896: step 39160, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:27:59.180106: step 39170, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:28:02.266565: step 39180, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:28:05.341861: step 39190, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:28:08.430793: step 39200, loss = nan (406.3 examples/sec; 0.315 sec/batch)
2017-10-18 02:28:11.522004: step 39210, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:28:14.600918: step 39220, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:28:17.681602: step 39230, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:28:20.752556: step 39240, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:28:23.849766: step 39250, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 02:28:26.945181: step 39260, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:28:30.027816: step 39270, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:28:33.112623: step 39280, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:28:36.216245: step 39290, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:28:39.300455: step 39300, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 02:28:42.385782: step 39310, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:28:45.467478: step 39320, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:28:48.546329: step 39330, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:28:51.636076: step 39340, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:28:54.729532: step 39350, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:28:57.812992: step 39360, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:29:00.891725: step 39370, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:29:03.983720: step 39380, loss = nan (422.3 examples/sec; 0.303 sec/batch)
2017-10-18 02:29:07.058198: step 39390, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:29:10.136012: step 39400, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:29:13.227678: step 39410, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:29:16.320198: step 39420, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:29:19.390496: step 39430, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:29:22.492511: step 39440, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:29:25.596227: step 39450, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:29:28.664309: step 39460, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:29:31.747182: step 39470, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:29:34.825504: step 39480, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:29:37.906980: step 39490, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:29:40.985747: step 39500, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:29:44.074277: step 39510, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:29:47.172783: step 39520, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:29:50.277062: step 39530, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 02:29:53.364233: step 39540, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:29:56.446477: step 39550, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:29:59.535742: step 39560, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:30:02.622405: step 39570, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:30:05.910215: step 39580, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:30:09.003911: step 39590, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:30:12.094688: step 39600, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:30:15.176335: step 39610, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:30:18.260567: step 39620, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:30:21.328773: step 39630, loss = nan (421.9 examples/sec; 0.303 sec/batch)
2017-10-18 02:30:24.414692: step 39640, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:30:27.491403: step 39650, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:30:30.576997: step 39660, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:30:33.659167: step 39670, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:30:36.746589: step 39680, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:30:39.826443: step 39690, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 02:30:42.926199: step 39700, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:30:46.019123: step 39710, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:30:49.099598: step 39720, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:30:52.191676: step 39730, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:30:55.275801: step 39740, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:30:58.361521: step 39750, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:01.448857: step 39760, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:04.543538: step 39770, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:07.650424: step 39780, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:10.725494: step 39790, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:31:13.805091: step 39800, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:31:16.877635: step 39810, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:19.967295: step 39820, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:23.042755: step 39830, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:31:26.129424: step 39840, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:31:29.215812: step 39850, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:31:32.304986: step 39860, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:31:35.367292: step 39870, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:31:38.456331: step 39880, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:41.563473: step 39890, loss = nan (399.8 examples/sec; 0.320 sec/batch)
2017-10-18 02:31:44.658990: step 39900, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:31:47.751483: step 39910, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:31:50.851465: step 39920, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:31:53.941701: step 39930, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:31:57.025423: step 39940, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:32:00.100491: step 39950, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:32:03.185057: step 39960, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:32:06.278666: step 39970, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:32:09.362434: step 39980, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:32:12.451922: step 39990, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:32:15.549839: step 40000, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:32:18.627619: step 40010, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-18 02:32:21.729713: step 40020, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:32:24.822711: step 40030, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:32:27.925923: step 40040, loss = nan (409.6 examples/sec; 0.313 sec/batch)
2017-10-18 02:32:31.032248: step 40050, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:32:34.116676: step 40060, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:32:37.225051: step 40070, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:32:40.308543: step 40080, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:32:43.370165: step 40090, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:32:46.465226: step 40100, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 02:32:49.539951: step 40110, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:32:52.614578: step 40120, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:32:55.696687: step 40130, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:32:58.798444: step 40140, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 02:33:01.886585: step 40150, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:33:04.977723: step 40160, loss = nan (403.3 examples/sec; 0.317 sec/batch)
2017-10-18 02:33:08.070839: step 40170, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:33:11.175054: step 40180, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:33:14.255288: step 40190, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 02:33:17.338907: step 40200, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:33:20.527484: step 40210, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:33:23.608948: step 40220, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:33:26.703034: step 40230, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 02:33:29.787772: step 40240, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:33:32.860422: step 40250, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:33:35.941119: step 40260, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 02:33:39.051059: step 40270, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:33:42.136126: step 40280, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:33:45.212713: step 40290, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:33:48.321350: step 40300, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:33:51.428918: step 40310, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:33:54.512047: step 40320, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:33:57.595954: step 40330, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:34:00.706971: step 40340, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:34:03.802210: step 40350, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:34:06.871625: step 40360, loss = nan (422.7 examples/sec; 0.303 sec/batch)
2017-10-18 02:34:09.975164: step 40370, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-18 02:34:13.074222: step 40380, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:34:16.179452: step 40390, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:34:19.258004: step 40400, loss = nan (413.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:34:22.351213: step 40410, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:34:25.433846: step 40420, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:34:28.508203: step 40430, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:34:31.601091: step 40440, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:34:34.680461: step 40450, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:34:37.788082: step 40460, loss = nan (395.1 examples/sec; 0.324 sec/batch)
2017-10-18 02:34:40.979286: step 40470, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:34:44.064618: step 40480, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:34:47.157318: step 40490, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:34:50.256944: step 40500, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:34:53.337368: step 40510, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:34:56.424576: step 40520, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:34:59.512324: step 40530, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:35:02.610303: step 40540, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:35:05.678890: step 40550, loss = nan (419.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:35:08.757232: step 40560, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:35:11.844632: step 40570, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 02:35:14.950306: step 40580, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:35:18.040802: step 40590, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:35:21.101628: step 40600, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 02:35:24.174595: step 40610, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:35:27.244111: step 40620, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 02:35:30.338092: step 40630, loss = nan (406.5 examples/sec; 0.315 sec/batch)
2017-10-18 02:35:33.460847: step 40640, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 02:35:36.536952: step 40650, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:35:39.612166: step 40660, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:35:42.693400: step 40670, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:35:45.788214: step 40680, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:35:48.868739: step 40690, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:35:51.950184: step 40700, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:35:55.038421: step 40710, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:35:58.133730: step 40720, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:36:01.229316: step 40730, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 02:36:04.326528: step 40740, loss = nan (397.4 examples/sec; 0.322 sec/batch)
2017-10-18 02:36:07.401852: step 40750, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:36:10.493710: step 40760, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:36:13.584522: step 40770, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:36:16.683146: step 40780, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:36:19.759344: step 40790, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:36:22.860852: step 40800, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 02:36:25.971901: step 40810, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:36:29.044276: step 40820, loss = nan (422.7 examples/sec; 0.303 sec/batch)
2017-10-18 02:36:32.138402: step 40830, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:36:35.428247: step 40840, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:36:38.507704: step 40850, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:36:41.590268: step 40860, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:36:44.804746: step 40870, loss = nan (307.1 examples/sec; 0.417 sec/batch)
2017-10-18 02:36:47.899707: step 40880, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 02:36:50.980965: step 40890, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:36:54.068299: step 40900, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:36:57.150384: step 40910, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:37:00.230440: step 40920, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 02:37:03.342045: step 40930, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:37:06.447630: step 40940, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 02:37:09.574655: step 40950, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:37:12.670647: step 40960, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:37:15.750520: step 40970, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:37:18.834508: step 40980, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:37:21.921503: step 40990, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 02:37:25.007080: step 41000, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:37:28.090987: step 41010, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:37:31.180458: step 41020, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:37:34.267173: step 41030, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:37:37.358626: step 41040, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:37:40.439940: step 41050, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:37:43.518054: step 41060, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:37:46.612907: step 41070, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:37:49.709262: step 41080, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:37:52.789618: step 41090, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:37:55.868076: step 41100, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:37:58.954618: step 41110, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:38:02.069992: step 41120, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:38:05.176718: step 41130, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:38:08.258429: step 41140, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:38:11.359351: step 41150, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:38:14.448276: step 41160, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:38:17.552097: step 41170, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:38:20.652657: step 41180, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:38:23.738383: step 41190, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:38:26.822461: step 41200, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:38:29.912438: step 41210, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 02:38:33.089856: step 41220, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:38:36.164708: step 41230, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 02:38:39.257092: step 41240, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:38:42.363073: step 41250, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 02:38:45.455310: step 41260, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:38:48.535902: step 41270, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:38:51.621860: step 41280, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:38:54.719064: step 41290, loss = nan (423.0 examples/sec; 0.303 sec/batch)
2017-10-18 02:38:57.940986: step 41300, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:39:01.024861: step 41310, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:39:04.132178: step 41320, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:07.242528: step 41330, loss = nan (406.1 examples/sec; 0.315 sec/batch)
2017-10-18 02:39:10.337272: step 41340, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:39:13.442791: step 41350, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:39:16.535592: step 41360, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:19.625605: step 41370, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:22.702694: step 41380, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:39:25.794544: step 41390, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:39:28.878086: step 41400, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:39:31.992811: step 41410, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:39:35.071127: step 41420, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:38.177301: step 41430, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:41.258897: step 41440, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:44.336988: step 41450, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:39:47.418745: step 41460, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:39:50.508066: step 41470, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:39:53.586006: step 41480, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:39:56.674640: step 41490, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:39:59.757395: step 41500, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:40:02.847007: step 41510, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 02:40:05.921688: step 41520, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:40:08.998341: step 41530, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:40:12.079256: step 41540, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:40:15.159654: step 41550, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:40:18.239145: step 41560, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:40:21.314367: step 41570, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:40:24.389088: step 41580, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:40:27.472915: step 41590, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 02:40:30.557938: step 41600, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:40:33.667325: step 41610, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:40:36.740259: step 41620, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:40:39.815436: step 41630, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:40:42.915103: step 41640, loss = nan (408.3 examples/sec; 0.314 sec/batch)
2017-10-18 02:40:46.122927: step 41650, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:40:49.229929: step 41660, loss = nan (405.5 examples/sec; 0.316 sec/batch)
2017-10-18 02:40:52.320835: step 41670, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:40:55.406686: step 41680, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:40:58.481740: step 41690, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:41:01.574662: step 41700, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:04.664459: step 41710, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:07.748676: step 41720, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:10.831127: step 41730, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:41:13.916170: step 41740, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:16.994965: step 41750, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:41:20.069067: step 41760, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:23.163328: step 41770, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:41:26.231621: step 41780, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:41:29.318072: step 41790, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 02:41:32.414781: step 41800, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:41:35.512693: step 41810, loss = nan (401.0 examples/sec; 0.319 sec/batch)
2017-10-18 02:41:38.590822: step 41820, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:41:41.780925: step 41830, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:41:44.880237: step 41840, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:41:47.978617: step 41850, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:41:51.058060: step 41860, loss = nan (402.1 examples/sec; 0.318 sec/batch)
2017-10-18 02:41:54.168668: step 41870, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:41:57.264244: step 41880, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:42:00.347824: step 41890, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:42:03.436523: step 41900, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:42:06.528062: step 41910, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 02:42:09.708845: step 41920, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:42:12.927200: step 41930, loss = nan (422.9 examples/sec; 0.303 sec/batch)
2017-10-18 02:42:16.016001: step 41940, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:42:19.095190: step 41950, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 02:42:22.204364: step 41960, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:42:25.305936: step 41970, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:42:28.545934: step 41980, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:42:31.624392: step 41990, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 02:42:34.712934: step 42000, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 02:42:37.807585: step 42010, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:42:40.887090: step 42020, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:42:43.977095: step 42030, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:42:47.055854: step 42040, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:42:50.125706: step 42050, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:42:53.218437: step 42060, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:42:56.334854: step 42070, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:42:59.414001: step 42080, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:43:02.520429: step 42090, loss = nan (402.9 examples/sec; 0.318 sec/batch)
2017-10-18 02:43:05.628846: step 42100, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:43:08.722103: step 42110, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:43:11.809924: step 42120, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:43:14.900310: step 42130, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:43:17.968648: step 42140, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:43:21.056820: step 42150, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:43:24.147794: step 42160, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:43:27.228492: step 42170, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:43:30.307139: step 42180, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:43:33.380127: step 42190, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:43:36.454639: step 42200, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:43:39.596827: step 42210, loss = nan (407.8 examples/sec; 0.314 sec/batch)
2017-10-18 02:43:42.672001: step 42220, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:43:45.759245: step 42230, loss = nan (407.0 examples/sec; 0.315 sec/batch)
2017-10-18 02:43:48.821832: step 42240, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:43:51.913048: step 42250, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:43:54.996714: step 42260, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 02:43:58.088971: step 42270, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 02:44:01.171742: step 42280, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 02:44:04.249770: step 42290, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:44:07.330605: step 42300, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:44:10.420668: step 42310, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:44:13.497013: step 42320, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:44:16.566822: step 42330, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:44:19.635770: step 42340, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:44:22.710350: step 42350, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:44:25.794437: step 42360, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:44:28.885028: step 42370, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:44:31.968785: step 42380, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:44:35.077426: step 42390, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:44:38.151795: step 42400, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:44:41.237904: step 42410, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:44:44.320686: step 42420, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:44:47.397908: step 42430, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:44:50.499908: step 42440, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:44:53.577021: step 42450, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:44:56.639129: step 42460, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:44:59.703693: step 42470, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:45:02.794155: step 42480, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:45:05.875552: step 42490, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 02:45:08.969569: step 42500, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 02:45:12.056505: step 42510, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:45:15.142802: step 42520, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 02:45:18.229894: step 42530, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:45:21.320613: step 42540, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:45:24.409041: step 42550, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:45:27.497977: step 42560, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:45:30.582738: step 42570, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:45:33.674549: step 42580, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:45:36.775926: step 42590, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:45:39.859321: step 42600, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:45:42.935325: step 42610, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 02:45:46.026412: step 42620, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:45:49.101290: step 42630, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 02:45:52.189375: step 42640, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:45:55.279585: step 42650, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 02:45:58.394976: step 42660, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 02:46:01.483456: step 42670, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:46:04.562338: step 42680, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:46:07.633650: step 42690, loss = nan (413.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:46:10.723801: step 42700, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 02:46:13.822986: step 42710, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:46:16.905658: step 42720, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:46:20.008539: step 42730, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:46:23.097768: step 42740, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:46:26.168138: step 42750, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:46:29.252395: step 42760, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:46:32.342679: step 42770, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:46:35.429589: step 42780, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:46:38.512169: step 42790, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:46:41.597487: step 42800, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:46:44.679116: step 42810, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:46:47.743954: step 42820, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:46:50.812567: step 42830, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:46:53.901540: step 42840, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:46:56.975983: step 42850, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:47:00.156292: step 42860, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 02:47:03.243048: step 42870, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:47:06.322039: step 42880, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:47:09.393770: step 42890, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:47:12.463172: step 42900, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:47:15.545484: step 42910, loss = nan (422.2 examples/sec; 0.303 sec/batch)
2017-10-18 02:47:18.621763: step 42920, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:47:21.696540: step 42930, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:47:24.808439: step 42940, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 02:47:27.896163: step 42950, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:47:31.111106: step 42960, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:47:34.208407: step 42970, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:47:37.301134: step 42980, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:47:40.388528: step 42990, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:47:43.476806: step 43000, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:47:46.557895: step 43010, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:47:49.642796: step 43020, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:47:52.732831: step 43030, loss = nan (409.2 examples/sec; 0.313 sec/batch)
2017-10-18 02:47:55.823869: step 43040, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-18 02:47:58.919578: step 43050, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:48:02.026777: step 43060, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:48:05.103604: step 43070, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:48:08.195614: step 43080, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:48:11.294517: step 43090, loss = nan (402.6 examples/sec; 0.318 sec/batch)
2017-10-18 02:48:14.363490: step 43100, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:48:17.444531: step 43110, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:48:20.532606: step 43120, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:48:23.628162: step 43130, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:48:26.719464: step 43140, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:48:29.798780: step 43150, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:48:32.887866: step 43160, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 02:48:35.990587: step 43170, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 02:48:39.059692: step 43180, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:48:42.157067: step 43190, loss = nan (400.7 examples/sec; 0.319 sec/batch)
2017-10-18 02:48:45.254023: step 43200, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:48:48.342760: step 43210, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:48:51.446662: step 43220, loss = nan (399.3 examples/sec; 0.321 sec/batch)
2017-10-18 02:48:54.657726: step 43230, loss = nan (304.9 examples/sec; 0.420 sec/batch)
2017-10-18 02:48:57.745959: step 43240, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 02:49:00.819995: step 43250, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 02:49:03.908112: step 43260, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:49:06.975824: step 43270, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:49:10.064497: step 43280, loss = nan (408.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:49:13.162540: step 43290, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:49:16.257168: step 43300, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:49:19.338926: step 43310, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:49:22.419950: step 43320, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:49:25.494250: step 43330, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:49:28.582737: step 43340, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:49:31.678912: step 43350, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:49:34.779916: step 43360, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:49:37.886181: step 43370, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:49:40.967985: step 43380, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:49:44.062092: step 43390, loss = nan (397.3 examples/sec; 0.322 sec/batch)
2017-10-18 02:49:47.128174: step 43400, loss = nan (423.9 examples/sec; 0.302 sec/batch)
2017-10-18 02:49:50.213423: step 43410, loss = nan (421.8 examples/sec; 0.303 sec/batch)
2017-10-18 02:49:53.302318: step 43420, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 02:49:56.380344: step 43430, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:49:59.457162: step 43440, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:50:02.543196: step 43450, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:50:05.632265: step 43460, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 02:50:08.719765: step 43470, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:50:11.823299: step 43480, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:50:14.924857: step 43490, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:50:17.999463: step 43500, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:50:21.094842: step 43510, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:50:24.201966: step 43520, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:50:27.277170: step 43530, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:50:30.363842: step 43540, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:50:33.441745: step 43550, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:50:36.514825: step 43560, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:50:39.603180: step 43570, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:50:42.695419: step 43580, loss = nan (406.4 examples/sec; 0.315 sec/batch)
2017-10-18 02:50:45.779617: step 43590, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:50:48.859531: step 43600, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:50:51.955519: step 43610, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 02:50:55.047004: step 43620, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:50:58.121442: step 43630, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:51:01.201399: step 43640, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:51:04.280291: step 43650, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:07.358691: step 43660, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 02:51:10.440965: step 43670, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:13.528130: step 43680, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:16.617992: step 43690, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:19.674353: step 43700, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:22.744437: step 43710, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:51:25.819638: step 43720, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:51:28.898291: step 43730, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:31.988280: step 43740, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:51:35.063964: step 43750, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:38.141728: step 43760, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:41.331366: step 43770, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:44.426944: step 43780, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:51:47.519762: step 43790, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:50.605318: step 43800, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:51:53.690337: step 43810, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:51:56.778033: step 43820, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:51:59.869039: step 43830, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 02:52:02.950130: step 43840, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 02:52:06.047207: step 43850, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:52:09.140146: step 43860, loss = nan (410.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:52:12.227457: step 43870, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 02:52:15.316853: step 43880, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:52:18.401712: step 43890, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:52:21.504681: step 43900, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:52:24.604114: step 43910, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:52:27.685207: step 43920, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:52:30.775300: step 43930, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:52:33.871571: step 43940, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 02:52:36.952599: step 43950, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:52:40.038078: step 43960, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 02:52:43.135062: step 43970, loss = nan (397.4 examples/sec; 0.322 sec/batch)
2017-10-18 02:52:46.210785: step 43980, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 02:52:49.288771: step 43990, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:52:52.382898: step 44000, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 02:52:55.461465: step 44010, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:52:58.551129: step 44020, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:53:01.641449: step 44030, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:53:04.719256: step 44040, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:53:07.797686: step 44050, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:53:10.877765: step 44060, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:53:13.961489: step 44070, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 02:53:17.039663: step 44080, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 02:53:20.132078: step 44090, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 02:53:23.215584: step 44100, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:53:26.296588: step 44110, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:53:29.411738: step 44120, loss = nan (402.8 examples/sec; 0.318 sec/batch)
2017-10-18 02:53:32.522849: step 44130, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 02:53:35.599044: step 44140, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:53:38.661305: step 44150, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:53:41.741552: step 44160, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 02:53:44.943213: step 44170, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 02:53:48.031400: step 44180, loss = nan (408.3 examples/sec; 0.314 sec/batch)
2017-10-18 02:53:51.110400: step 44190, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:53:54.189643: step 44200, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:53:57.280640: step 44210, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 02:54:00.386467: step 44220, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 02:54:03.470443: step 44230, loss = nan (414.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:06.553856: step 44240, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 02:54:09.626159: step 44250, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:12.714118: step 44260, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:15.788033: step 44270, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:18.874817: step 44280, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:54:22.096971: step 44290, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:25.197816: step 44300, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:54:28.297522: step 44310, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 02:54:31.378684: step 44320, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:54:34.562985: step 44330, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:54:37.652009: step 44340, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:54:40.727643: step 44350, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 02:54:43.819135: step 44360, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:54:46.932379: step 44370, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:54:50.032226: step 44380, loss = nan (407.7 examples/sec; 0.314 sec/batch)
2017-10-18 02:54:53.128413: step 44390, loss = nan (408.2 examples/sec; 0.314 sec/batch)
2017-10-18 02:54:56.204000: step 44400, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:54:59.286914: step 44410, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:55:02.391036: step 44420, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 02:55:05.512314: step 44430, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 02:55:08.608448: step 44440, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:55:11.703084: step 44450, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:55:14.911911: step 44460, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 02:55:17.996016: step 44470, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 02:55:21.072117: step 44480, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:55:24.159332: step 44490, loss = nan (406.0 examples/sec; 0.315 sec/batch)
2017-10-18 02:55:27.242751: step 44500, loss = nan (406.6 examples/sec; 0.315 sec/batch)
2017-10-18 02:55:30.324304: step 44510, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:55:33.425372: step 44520, loss = nan (408.0 examples/sec; 0.314 sec/batch)
2017-10-18 02:55:36.501076: step 44530, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 02:55:39.604128: step 44540, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:55:42.711185: step 44550, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:55:45.773716: step 44560, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:55:48.979865: step 44570, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:55:52.077834: step 44580, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:55:55.140640: step 44590, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:55:58.234700: step 44600, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:56:01.317258: step 44610, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:56:04.396676: step 44620, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 02:56:07.496618: step 44630, loss = nan (404.9 examples/sec; 0.316 sec/batch)
2017-10-18 02:56:10.582886: step 44640, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:56:13.682221: step 44650, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 02:56:16.864360: step 44660, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:56:19.946670: step 44670, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:56:23.026352: step 44680, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:56:26.231235: step 44690, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 02:56:29.334155: step 44700, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 02:56:32.432396: step 44710, loss = nan (407.0 examples/sec; 0.315 sec/batch)
2017-10-18 02:56:35.531082: step 44720, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 02:56:38.605908: step 44730, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:56:41.686631: step 44740, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:56:44.775132: step 44750, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:56:47.864998: step 44760, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 02:56:50.945000: step 44770, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:56:54.029154: step 44780, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:56:57.213518: step 44790, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:00.295896: step 44800, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:03.378056: step 44810, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 02:57:06.489214: step 44820, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 02:57:09.591919: step 44830, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 02:57:12.666948: step 44840, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 02:57:15.750937: step 44850, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:57:18.833302: step 44860, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:57:21.918938: step 44870, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:25.005457: step 44880, loss = nan (418.0 examples/sec; 0.306 sec/batch)
2017-10-18 02:57:28.178812: step 44890, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 02:57:31.281477: step 44900, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:34.366320: step 44910, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:57:37.444107: step 44920, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 02:57:40.526939: step 44930, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:43.609710: step 44940, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 02:57:46.677573: step 44950, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:57:49.754364: step 44960, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 02:57:52.836627: step 44970, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 02:57:55.916582: step 44980, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 02:57:58.998452: step 44990, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 02:58:02.092421: step 45000, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 02:58:05.183591: step 45010, loss = nan (406.7 examples/sec; 0.315 sec/batch)
2017-10-18 02:58:08.395584: step 45020, loss = nan (409.3 examples/sec; 0.313 sec/batch)
2017-10-18 02:58:11.495946: step 45030, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 02:58:14.569586: step 45040, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 02:58:17.660013: step 45050, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 02:58:20.741093: step 45060, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:58:23.815747: step 45070, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 02:58:26.895545: step 45080, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 02:58:29.988540: step 45090, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:58:33.089908: step 45100, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 02:58:36.172721: step 45110, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 02:58:39.275852: step 45120, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 02:58:42.354728: step 45130, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 02:58:45.426882: step 45140, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 02:58:48.494252: step 45150, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 02:58:51.590384: step 45160, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 02:58:54.665359: step 45170, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 02:58:57.766668: step 45180, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:59:00.840692: step 45190, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 02:59:03.924928: step 45200, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 02:59:07.002618: step 45210, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 02:59:10.080893: step 45220, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 02:59:13.164570: step 45230, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 02:59:16.240454: step 45240, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 02:59:19.324199: step 45250, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 02:59:22.403339: step 45260, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 02:59:25.486134: step 45270, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 02:59:28.553613: step 45280, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 02:59:31.643153: step 45290, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 02:59:34.741867: step 45300, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:59:37.830249: step 45310, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 02:59:40.911121: step 45320, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 02:59:43.994951: step 45330, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 02:59:47.080880: step 45340, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 02:59:50.162456: step 45350, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:59:53.238953: step 45360, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 02:59:56.331158: step 45370, loss = nan (418.7 examples/sec; 0.306 sec/batch)
2017-10-18 02:59:59.411580: step 45380, loss = nan (407.6 examples/sec; 0.314 sec/batch)
2017-10-18 03:00:02.557202: step 45390, loss = nan (411.7 examples/sec; 0.311 sec/batch)
2017-10-18 03:00:05.641510: step 45400, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 03:00:08.729932: step 45410, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 03:00:11.814968: step 45420, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 03:00:14.894367: step 45430, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 03:00:17.999143: step 45440, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 03:00:21.069872: step 45450, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:00:24.156374: step 45460, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:00:27.245436: step 45470, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 03:00:30.341004: step 45480, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 03:00:33.423916: step 45490, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 03:00:36.669939: step 45500, loss = nan (409.7 examples/sec; 0.312 sec/batch)
2017-10-18 03:00:39.753278: step 45510, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 03:00:42.848055: step 45520, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 03:00:45.939029: step 45530, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:00:49.033953: step 45540, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 03:00:52.103421: step 45550, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 03:00:55.194124: step 45560, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 03:00:58.277454: step 45570, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:01:01.371687: step 45580, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 03:01:04.441652: step 45590, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 03:01:07.520996: step 45600, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:01:10.592288: step 45610, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 03:01:13.663274: step 45620, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:01:16.736384: step 45630, loss = nan (402.6 examples/sec; 0.318 sec/batch)
2017-10-18 03:01:19.839366: step 45640, loss = nan (403.6 examples/sec; 0.317 sec/batch)
2017-10-18 03:01:22.917508: step 45650, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 03:01:25.991746: step 45660, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 03:01:29.076862: step 45670, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:01:32.169908: step 45680, loss = nan (423.6 examples/sec; 0.302 sec/batch)
2017-10-18 03:01:35.311290: step 45690, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:01:38.385895: step 45700, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 03:01:41.470985: step 45710, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 03:01:44.550831: step 45720, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:01:47.636236: step 45730, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:01:50.717982: step 45740, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:01:53.854002: step 45750, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 03:01:56.919493: step 45760, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 03:02:00.003586: step 45770, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:02:03.107754: step 45780, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 03:02:06.215439: step 45790, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 03:02:09.313773: step 45800, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 03:02:12.407861: step 45810, loss = nan (413.8 examples/sec; 0.309 sec/batch)
2017-10-18 03:02:15.487521: step 45820, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 03:02:18.581393: step 45830, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:02:21.682183: step 45840, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:02:24.768048: step 45850, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 03:02:27.855514: step 45860, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 03:02:30.949158: step 45870, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 03:02:34.037308: step 45880, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:02:37.133020: step 45890, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 03:02:40.205477: step 45900, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:02:43.276473: step 45910, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 03:02:46.363484: step 45920, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:02:49.459694: step 45930, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 03:02:52.523056: step 45940, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 03:02:55.605683: step 45950, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:02:58.703563: step 45960, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 03:03:01.775623: step 45970, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:03:04.865094: step 45980, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 03:03:07.958879: step 45990, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 03:03:11.033591: step 46000, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:03:14.128239: step 46010, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:03:17.213799: step 46020, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 03:03:20.297305: step 46030, loss = nan (403.5 examples/sec; 0.317 sec/batch)
2017-10-18 03:03:23.391092: step 46040, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 03:03:26.477865: step 46050, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:03:29.580649: step 46060, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:03:32.678107: step 46070, loss = nan (405.1 examples/sec; 0.316 sec/batch)
2017-10-18 03:03:35.773807: step 46080, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 03:03:38.872239: step 46090, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 03:03:41.976820: step 46100, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 03:03:45.047300: step 46110, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 03:03:48.147371: step 46120, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 03:03:51.249668: step 46130, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:03:54.337197: step 46140, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 03:03:57.408533: step 46150, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:00.519308: step 46160, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:04:03.608727: step 46170, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:04:06.699736: step 46180, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:09.787929: step 46190, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:12.884086: step 46200, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:04:15.964418: step 46210, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:19.050650: step 46220, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:22.133732: step 46230, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:25.220719: step 46240, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:28.303589: step 46250, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:04:31.380449: step 46260, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 03:04:34.470344: step 46270, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:04:37.559857: step 46280, loss = nan (416.9 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:40.646552: step 46290, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 03:04:43.745968: step 46300, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 03:04:46.822166: step 46310, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:49.906566: step 46320, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 03:04:52.991317: step 46330, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:04:56.078561: step 46340, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:04:59.189535: step 46350, loss = nan (404.2 examples/sec; 0.317 sec/batch)
2017-10-18 03:05:02.279878: step 46360, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 03:05:05.389134: step 46370, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:05:08.482475: step 46380, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 03:05:11.565667: step 46390, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 03:05:14.661743: step 46400, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:05:17.756556: step 46410, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 03:05:20.841547: step 46420, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:05:23.942056: step 46430, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 03:05:27.143041: step 46440, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:05:30.222616: step 46450, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:05:33.302632: step 46460, loss = nan (402.1 examples/sec; 0.318 sec/batch)
2017-10-18 03:05:36.385516: step 46470, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 03:05:39.466097: step 46480, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 03:05:42.574628: step 46490, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:05:45.658581: step 46500, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 03:05:48.731837: step 46510, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:05:51.818814: step 46520, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:05:54.894157: step 46530, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:05:57.974308: step 46540, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 03:06:01.068187: step 46550, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 03:06:04.149161: step 46560, loss = nan (405.2 examples/sec; 0.316 sec/batch)
2017-10-18 03:06:07.252399: step 46570, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 03:06:10.355694: step 46580, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 03:06:13.436672: step 46590, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:06:16.524733: step 46600, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:06:19.626929: step 46610, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:06:22.716651: step 46620, loss = nan (421.9 examples/sec; 0.303 sec/batch)
2017-10-18 03:06:25.803078: step 46630, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:06:28.897548: step 46640, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:06:31.982016: step 46650, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 03:06:35.082305: step 46660, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:06:38.187524: step 46670, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:06:41.476003: step 46680, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:06:44.678861: step 46690, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:06:47.788667: step 46700, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:06:50.868972: step 46710, loss = nan (412.8 examples/sec; 0.310 sec/batch)
2017-10-18 03:06:53.956424: step 46720, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:06:57.028738: step 46730, loss = nan (422.1 examples/sec; 0.303 sec/batch)
2017-10-18 03:07:00.101266: step 46740, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:07:03.194375: step 46750, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:07:06.285822: step 46760, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 03:07:09.361156: step 46770, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:07:12.451969: step 46780, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 03:07:15.533713: step 46790, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:07:18.645610: step 46800, loss = nan (409.6 examples/sec; 0.312 sec/batch)
2017-10-18 03:07:21.743962: step 46810, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 03:07:24.822246: step 46820, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:07:27.901701: step 46830, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:07:30.988706: step 46840, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 03:07:34.089904: step 46850, loss = nan (406.9 examples/sec; 0.315 sec/batch)
2017-10-18 03:07:37.172187: step 46860, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 03:07:40.240120: step 46870, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:07:43.331372: step 46880, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 03:07:46.410552: step 46890, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:07:49.502247: step 46900, loss = nan (419.7 examples/sec; 0.305 sec/batch)
2017-10-18 03:07:52.572067: step 46910, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:07:55.658548: step 46920, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:07:58.742691: step 46930, loss = nan (414.3 examples/sec; 0.309 sec/batch)
2017-10-18 03:08:01.835643: step 46940, loss = nan (414.9 examples/sec; 0.309 sec/batch)
2017-10-18 03:08:04.914039: step 46950, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 03:08:08.002798: step 46960, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:08:11.106001: step 46970, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:08:14.205246: step 46980, loss = nan (400.1 examples/sec; 0.320 sec/batch)
2017-10-18 03:08:17.319113: step 46990, loss = nan (404.3 examples/sec; 0.317 sec/batch)
2017-10-18 03:08:20.422073: step 47000, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 03:08:23.497130: step 47010, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 03:08:26.577604: step 47020, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 03:08:29.661810: step 47030, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:08:32.741285: step 47040, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 03:08:35.821926: step 47050, loss = nan (417.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:08:38.900702: step 47060, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:08:41.974427: step 47070, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:08:45.061503: step 47080, loss = nan (413.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:08:48.153423: step 47090, loss = nan (410.5 examples/sec; 0.312 sec/batch)
2017-10-18 03:08:51.250433: step 47100, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 03:08:54.337560: step 47110, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 03:08:57.423137: step 47120, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:09:00.518977: step 47130, loss = nan (412.1 examples/sec; 0.311 sec/batch)
2017-10-18 03:09:03.603506: step 47140, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 03:09:06.692637: step 47150, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:09:09.765941: step 47160, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:09:12.857138: step 47170, loss = nan (416.3 examples/sec; 0.308 sec/batch)
2017-10-18 03:09:15.925173: step 47180, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 03:09:19.009386: step 47190, loss = nan (420.7 examples/sec; 0.304 sec/batch)
2017-10-18 03:09:22.092816: step 47200, loss = nan (404.7 examples/sec; 0.316 sec/batch)
2017-10-18 03:09:25.169263: step 47210, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:09:28.364369: step 47220, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 03:09:31.441348: step 47230, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:09:34.510705: step 47240, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 03:09:37.588612: step 47250, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 03:09:40.679759: step 47260, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:09:43.770475: step 47270, loss = nan (411.4 examples/sec; 0.311 sec/batch)
2017-10-18 03:09:46.848616: step 47280, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:09:49.936197: step 47290, loss = nan (408.1 examples/sec; 0.314 sec/batch)
2017-10-18 03:09:53.017862: step 47300, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:09:56.124727: step 47310, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 03:09:59.317284: step 47320, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 03:10:02.418556: step 47330, loss = nan (410.1 examples/sec; 0.312 sec/batch)
2017-10-18 03:10:05.505705: step 47340, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:08.624079: step 47350, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:10:11.695101: step 47360, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:10:14.779281: step 47370, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:10:17.886005: step 47380, loss = nan (410.9 examples/sec; 0.312 sec/batch)
2017-10-18 03:10:20.976986: step 47390, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:24.073571: step 47400, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 03:10:27.155805: step 47410, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:30.240768: step 47420, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 03:10:33.330249: step 47430, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:36.417385: step 47440, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:10:39.508315: step 47450, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:10:42.594938: step 47460, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:45.697109: step 47470, loss = nan (410.0 examples/sec; 0.312 sec/batch)
2017-10-18 03:10:48.790989: step 47480, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 03:10:51.878050: step 47490, loss = nan (416.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:54.952988: step 47500, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 03:10:58.110810: step 47510, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:11:01.248814: step 47520, loss = nan (380.3 examples/sec; 0.337 sec/batch)
2017-10-18 03:11:04.319601: step 47530, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:11:07.420377: step 47540, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:11:10.499271: step 47550, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:11:13.581966: step 47560, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 03:11:16.677727: step 47570, loss = nan (408.9 examples/sec; 0.313 sec/batch)
2017-10-18 03:11:19.760894: step 47580, loss = nan (408.7 examples/sec; 0.313 sec/batch)
2017-10-18 03:11:22.850380: step 47590, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:11:25.922754: step 47600, loss = nan (411.1 examples/sec; 0.311 sec/batch)
2017-10-18 03:11:29.016454: step 47610, loss = nan (401.8 examples/sec; 0.319 sec/batch)
2017-10-18 03:11:32.098310: step 47620, loss = nan (407.9 examples/sec; 0.314 sec/batch)
2017-10-18 03:11:35.183248: step 47630, loss = nan (408.8 examples/sec; 0.313 sec/batch)
2017-10-18 03:11:38.274443: step 47640, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 03:11:41.534550: step 47650, loss = nan (395.7 examples/sec; 0.323 sec/batch)
2017-10-18 03:11:44.619545: step 47660, loss = nan (413.0 examples/sec; 0.310 sec/batch)
2017-10-18 03:11:47.687306: step 47670, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 03:11:50.763559: step 47680, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 03:11:53.963371: step 47690, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 03:11:57.042836: step 47700, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 03:12:00.131513: step 47710, loss = nan (412.2 examples/sec; 0.311 sec/batch)
2017-10-18 03:12:03.236179: step 47720, loss = nan (418.6 examples/sec; 0.306 sec/batch)
2017-10-18 03:12:06.326800: step 47730, loss = nan (420.0 examples/sec; 0.305 sec/batch)
2017-10-18 03:12:09.437100: step 47740, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 03:12:12.532154: step 47750, loss = nan (421.2 examples/sec; 0.304 sec/batch)
2017-10-18 03:12:15.630316: step 47760, loss = nan (409.8 examples/sec; 0.312 sec/batch)
2017-10-18 03:12:18.721578: step 47770, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:12:21.802408: step 47780, loss = nan (413.2 examples/sec; 0.310 sec/batch)
2017-10-18 03:12:24.891228: step 47790, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:12:27.974748: step 47800, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 03:12:31.070953: step 47810, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 03:12:34.160494: step 47820, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:12:37.238631: step 47830, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:12:40.323071: step 47840, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:12:43.423052: step 47850, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:12:46.518613: step 47860, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:12:49.609603: step 47870, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 03:12:52.711199: step 47880, loss = nan (419.0 examples/sec; 0.306 sec/batch)
2017-10-18 03:12:55.798379: step 47890, loss = nan (416.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:12:58.880524: step 47900, loss = nan (417.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:13:01.990367: step 47910, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 03:13:05.079301: step 47920, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:13:08.170775: step 47930, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 03:13:11.259348: step 47940, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:13:14.342962: step 47950, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:13:17.428037: step 47960, loss = nan (403.2 examples/sec; 0.317 sec/batch)
2017-10-18 03:13:20.526103: step 47970, loss = nan (401.3 examples/sec; 0.319 sec/batch)
2017-10-18 03:13:23.608096: step 47980, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 03:13:26.699712: step 47990, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 03:13:29.792575: step 48000, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:13:32.868991: step 48010, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 03:13:35.947337: step 48020, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 03:13:39.041000: step 48030, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:13:42.120407: step 48040, loss = nan (410.7 examples/sec; 0.312 sec/batch)
2017-10-18 03:13:45.192892: step 48050, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:13:48.261298: step 48060, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:13:51.505476: step 48070, loss = nan (405.6 examples/sec; 0.316 sec/batch)
2017-10-18 03:13:54.594488: step 48080, loss = nan (412.0 examples/sec; 0.311 sec/batch)
2017-10-18 03:13:57.691217: step 48090, loss = nan (420.8 examples/sec; 0.304 sec/batch)
2017-10-18 03:14:00.791072: step 48100, loss = nan (412.7 examples/sec; 0.310 sec/batch)
2017-10-18 03:14:03.882998: step 48110, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 03:14:06.966959: step 48120, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:14:10.036801: step 48130, loss = nan (413.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:14:13.117458: step 48140, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:14:16.191655: step 48150, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 03:14:19.376646: step 48160, loss = nan (414.8 examples/sec; 0.309 sec/batch)
2017-10-18 03:14:22.450871: step 48170, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 03:14:25.540080: step 48180, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:14:28.626666: step 48190, loss = nan (409.4 examples/sec; 0.313 sec/batch)
2017-10-18 03:14:31.699540: step 48200, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 03:14:34.774201: step 48210, loss = nan (419.5 examples/sec; 0.305 sec/batch)
2017-10-18 03:14:37.849645: step 48220, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:14:40.920731: step 48230, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:14:43.991376: step 48240, loss = nan (421.0 examples/sec; 0.304 sec/batch)
2017-10-18 03:14:47.062970: step 48250, loss = nan (419.6 examples/sec; 0.305 sec/batch)
2017-10-18 03:14:50.136938: step 48260, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:14:53.205061: step 48270, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:14:56.284976: step 48280, loss = nan (419.4 examples/sec; 0.305 sec/batch)
2017-10-18 03:14:59.354503: step 48290, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:15:02.449035: step 48300, loss = nan (411.9 examples/sec; 0.311 sec/batch)
2017-10-18 03:15:05.515172: step 48310, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:15:08.587121: step 48320, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:15:11.671170: step 48330, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 03:15:14.758808: step 48340, loss = nan (419.3 examples/sec; 0.305 sec/batch)
2017-10-18 03:15:17.832719: step 48350, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:15:20.915960: step 48360, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:15:24.008206: step 48370, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 03:15:27.103225: step 48380, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:15:30.197317: step 48390, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 03:15:33.275589: step 48400, loss = nan (419.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:15:36.355710: step 48410, loss = nan (415.7 examples/sec; 0.308 sec/batch)
2017-10-18 03:15:39.439435: step 48420, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:15:42.525535: step 48430, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 03:15:45.609336: step 48440, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:15:48.688135: step 48450, loss = nan (411.6 examples/sec; 0.311 sec/batch)
2017-10-18 03:15:51.765095: step 48460, loss = nan (422.0 examples/sec; 0.303 sec/batch)
2017-10-18 03:15:54.840735: step 48470, loss = nan (414.7 examples/sec; 0.309 sec/batch)
2017-10-18 03:15:57.916313: step 48480, loss = nan (413.1 examples/sec; 0.310 sec/batch)
2017-10-18 03:16:00.996758: step 48490, loss = nan (415.1 examples/sec; 0.308 sec/batch)
2017-10-18 03:16:04.108370: step 48500, loss = nan (396.4 examples/sec; 0.323 sec/batch)
2017-10-18 03:16:07.179612: step 48510, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:16:10.460071: step 48520, loss = nan (399.5 examples/sec; 0.320 sec/batch)
2017-10-18 03:16:13.551014: step 48530, loss = nan (408.6 examples/sec; 0.313 sec/batch)
2017-10-18 03:16:16.620573: step 48540, loss = nan (420.6 examples/sec; 0.304 sec/batch)
2017-10-18 03:16:19.715593: step 48550, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 03:16:22.794074: step 48560, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 03:16:25.870897: step 48570, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:16:28.957949: step 48580, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:16:32.056508: step 48590, loss = nan (405.9 examples/sec; 0.315 sec/batch)
2017-10-18 03:16:35.158737: step 48600, loss = nan (409.5 examples/sec; 0.313 sec/batch)
2017-10-18 03:16:38.255954: step 48610, loss = nan (411.2 examples/sec; 0.311 sec/batch)
2017-10-18 03:16:41.350908: step 48620, loss = nan (409.1 examples/sec; 0.313 sec/batch)
2017-10-18 03:16:44.432169: step 48630, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 03:16:47.520087: step 48640, loss = nan (404.5 examples/sec; 0.316 sec/batch)
2017-10-18 03:16:50.590721: step 48650, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 03:16:53.663772: step 48660, loss = nan (418.2 examples/sec; 0.306 sec/batch)
2017-10-18 03:16:56.763943: step 48670, loss = nan (415.3 examples/sec; 0.308 sec/batch)
2017-10-18 03:16:59.845539: step 48680, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:17:02.936341: step 48690, loss = nan (413.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:17:06.026545: step 48700, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 03:17:09.107876: step 48710, loss = nan (422.5 examples/sec; 0.303 sec/batch)
2017-10-18 03:17:12.336441: step 48720, loss = nan (410.3 examples/sec; 0.312 sec/batch)
2017-10-18 03:17:15.421924: step 48730, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 03:17:18.517000: step 48740, loss = nan (417.4 examples/sec; 0.307 sec/batch)
2017-10-18 03:17:21.600660: step 48750, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 03:17:24.685739: step 48760, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:17:27.758823: step 48770, loss = nan (416.7 examples/sec; 0.307 sec/batch)
2017-10-18 03:17:30.873352: step 48780, loss = nan (420.4 examples/sec; 0.304 sec/batch)
2017-10-18 03:17:33.948270: step 48790, loss = nan (418.1 examples/sec; 0.306 sec/batch)
2017-10-18 03:17:37.010227: step 48800, loss = nan (417.7 examples/sec; 0.306 sec/batch)
2017-10-18 03:17:40.076324: step 48810, loss = nan (417.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:17:43.171275: step 48820, loss = nan (416.3 examples/sec; 0.307 sec/batch)
2017-10-18 03:17:46.259222: step 48830, loss = nan (420.1 examples/sec; 0.305 sec/batch)
2017-10-18 03:17:49.346864: step 48840, loss = nan (413.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:17:52.421964: step 48850, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:17:55.506377: step 48860, loss = nan (412.5 examples/sec; 0.310 sec/batch)
2017-10-18 03:17:58.582017: step 48870, loss = nan (416.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:18:01.677273: step 48880, loss = nan (417.2 examples/sec; 0.307 sec/batch)
2017-10-18 03:18:04.772723: step 48890, loss = nan (409.9 examples/sec; 0.312 sec/batch)
2017-10-18 03:18:07.845958: step 48900, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:18:10.947031: step 48910, loss = nan (405.8 examples/sec; 0.315 sec/batch)
2017-10-18 03:18:14.054847: step 48920, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:18:17.124790: step 48930, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 03:18:20.197307: step 48940, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:18:23.278360: step 48950, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:18:26.363995: step 48960, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:18:29.467644: step 48970, loss = nan (410.2 examples/sec; 0.312 sec/batch)
2017-10-18 03:18:32.552289: step 48980, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:18:35.638077: step 48990, loss = nan (418.4 examples/sec; 0.306 sec/batch)
2017-10-18 03:18:38.717977: step 49000, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:18:41.802194: step 49010, loss = nan (412.9 examples/sec; 0.310 sec/batch)
2017-10-18 03:18:44.884446: step 49020, loss = nan (421.5 examples/sec; 0.304 sec/batch)
2017-10-18 03:18:47.962383: step 49030, loss = nan (411.3 examples/sec; 0.311 sec/batch)
2017-10-18 03:18:51.046485: step 49040, loss = nan (417.1 examples/sec; 0.307 sec/batch)
2017-10-18 03:18:54.132391: step 49050, loss = nan (418.9 examples/sec; 0.306 sec/batch)
2017-10-18 03:18:57.221967: step 49060, loss = nan (414.2 examples/sec; 0.309 sec/batch)
2017-10-18 03:19:00.318787: step 49070, loss = nan (411.8 examples/sec; 0.311 sec/batch)
2017-10-18 03:19:03.401965: step 49080, loss = nan (418.8 examples/sec; 0.306 sec/batch)
2017-10-18 03:19:06.489867: step 49090, loss = nan (413.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:19:09.571693: step 49100, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 03:19:12.690842: step 49110, loss = nan (409.0 examples/sec; 0.313 sec/batch)
2017-10-18 03:19:15.782345: step 49120, loss = nan (416.8 examples/sec; 0.307 sec/batch)
2017-10-18 03:19:18.870967: step 49130, loss = nan (421.3 examples/sec; 0.304 sec/batch)
2017-10-18 03:19:21.956727: step 49140, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 03:19:25.037386: step 49150, loss = nan (417.9 examples/sec; 0.306 sec/batch)
2017-10-18 03:19:28.129388: step 49160, loss = nan (420.2 examples/sec; 0.305 sec/batch)
2017-10-18 03:19:31.224371: step 49170, loss = nan (414.6 examples/sec; 0.309 sec/batch)
2017-10-18 03:19:34.302435: step 49180, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 03:19:37.485340: step 49190, loss = nan (411.5 examples/sec; 0.311 sec/batch)
2017-10-18 03:19:40.737847: step 49200, loss = nan (404.9 examples/sec; 0.316 sec/batch)
2017-10-18 03:19:43.808539: step 49210, loss = nan (414.4 examples/sec; 0.309 sec/batch)
2017-10-18 03:19:47.010192: step 49220, loss = nan (415.9 examples/sec; 0.308 sec/batch)
2017-10-18 03:19:50.084116: step 49230, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:19:53.168357: step 49240, loss = nan (414.0 examples/sec; 0.309 sec/batch)
2017-10-18 03:19:56.266938: step 49250, loss = nan (407.1 examples/sec; 0.314 sec/batch)
2017-10-18 03:19:59.362230: step 49260, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:20:02.455153: step 49270, loss = nan (411.0 examples/sec; 0.311 sec/batch)
2017-10-18 03:20:05.543390: step 49280, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 03:20:08.750871: step 49290, loss = nan (403.4 examples/sec; 0.317 sec/batch)
2017-10-18 03:20:11.826198: step 49300, loss = nan (419.9 examples/sec; 0.305 sec/batch)
2017-10-18 03:20:14.921036: step 49310, loss = nan (403.3 examples/sec; 0.317 sec/batch)
2017-10-18 03:20:18.007085: step 49320, loss = nan (418.5 examples/sec; 0.306 sec/batch)
2017-10-18 03:20:21.108981: step 49330, loss = nan (417.0 examples/sec; 0.307 sec/batch)
2017-10-18 03:20:24.175711: step 49340, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 03:20:27.258509: step 49350, loss = nan (417.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:20:30.342011: step 49360, loss = nan (405.4 examples/sec; 0.316 sec/batch)
2017-10-18 03:20:33.448842: step 49370, loss = nan (410.4 examples/sec; 0.312 sec/batch)
2017-10-18 03:20:36.529400: step 49380, loss = nan (416.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:20:39.721201: step 49390, loss = nan (413.6 examples/sec; 0.309 sec/batch)
2017-10-18 03:20:42.932469: step 49400, loss = nan (412.4 examples/sec; 0.310 sec/batch)
2017-10-18 03:20:46.026770: step 49410, loss = nan (404.8 examples/sec; 0.316 sec/batch)
2017-10-18 03:20:49.136599: step 49420, loss = nan (415.0 examples/sec; 0.308 sec/batch)
2017-10-18 03:20:52.214437: step 49430, loss = nan (419.1 examples/sec; 0.305 sec/batch)
2017-10-18 03:20:55.301436: step 49440, loss = nan (420.9 examples/sec; 0.304 sec/batch)
2017-10-18 03:20:58.359242: step 49450, loss = nan (419.8 examples/sec; 0.305 sec/batch)
2017-10-18 03:21:01.453395: step 49460, loss = nan (410.6 examples/sec; 0.312 sec/batch)
2017-10-18 03:21:04.545273: step 49470, loss = nan (414.5 examples/sec; 0.309 sec/batch)
2017-10-18 03:21:07.742592: step 49480, loss = nan (421.6 examples/sec; 0.304 sec/batch)
2017-10-18 03:21:10.842716: step 49490, loss = nan (415.4 examples/sec; 0.308 sec/batch)
2017-10-18 03:21:13.926443: step 49500, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:21:17.004315: step 49510, loss = nan (416.6 examples/sec; 0.307 sec/batch)
2017-10-18 03:21:20.093412: step 49520, loss = nan (408.5 examples/sec; 0.313 sec/batch)
2017-10-18 03:21:23.175350: step 49530, loss = nan (421.7 examples/sec; 0.304 sec/batch)
2017-10-18 03:21:26.248786: step 49540, loss = nan (415.5 examples/sec; 0.308 sec/batch)
2017-10-18 03:21:29.322584: step 49550, loss = nan (418.3 examples/sec; 0.306 sec/batch)
2017-10-18 03:21:32.415959: step 49560, loss = nan (415.6 examples/sec; 0.308 sec/batch)
2017-10-18 03:21:35.496676: step 49570, loss = nan (414.1 examples/sec; 0.309 sec/batch)
2017-10-18 03:21:38.573502: step 49580, loss = nan (420.5 examples/sec; 0.304 sec/batch)
2017-10-18 03:21:41.674145: step 49590, loss = nan (412.3 examples/sec; 0.310 sec/batch)
2017-10-18 03:21:44.757883: step 49600, loss = nan (415.8 examples/sec; 0.308 sec/batch)
2017-10-18 03:21:47.844442: step 49610, loss = nan (393.4 examples/sec; 0.325 sec/batch)
2017-10-18 03:21:50.909779: step 49620, loss = nan (416.5 examples/sec; 0.307 sec/batch)
2017-10-18 03:21:53.986826: step 49630, loss = nan (415.2 examples/sec; 0.308 sec/batch)
2017-10-18 03:21:57.072742: step 49640, loss = nan (412.6 examples/sec; 0.310 sec/batch)
2017-10-18 03:22:00.161052: step 49650, loss = nan (419.5 examples/sec; 0.305 sec/batch)
